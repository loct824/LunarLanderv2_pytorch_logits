{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnAIDcDsikI7",
        "outputId": "90578ebc-62a9-489e-fce5-25925b0de18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.3.5)\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (4.1.1.post1)\n",
            "Installing collected packages: pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "#Install the necessary dependencies\n",
        "!sudo apt-get install swig >> /dev/null\n",
        "!pip install gymnasium[box2d] >> /dev/null\n",
        "!pip install gym[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"PyTorch is using the GPU:\", torch.cuda.get_device_name(0))\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"PyTorch is not using a GPU.\")\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ARuIOZj5wSG",
        "outputId": "fc40267f-6bf7-471e-cb55-c578cd16c3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is using the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxvECmzY2ZJJ",
        "outputId": "90328276-6937-4385-86e0-70c284317704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcGIS38JXFyU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk6s_3AZK-ca"
      },
      "outputs": [],
      "source": [
        "# Set up the environment\n",
        "env_name = \"LunarLander-v2\"\n",
        "\n",
        "# from tf_agents.environments import suite_gym\n",
        "# env = suite_gym.load(env_name)\n",
        "\n",
        "\n",
        "\n",
        "#Default settings\n",
        "# env = gym.make(\n",
        "#     env_name,\n",
        "#     continous = False,\n",
        "#     gravity = -10.0,\n",
        "#     enable_wind = False,\n",
        "#     wind_power = 15.0,\n",
        "#     turbulence_power = 1.5\n",
        "# )\n",
        "\n",
        "env = gym.make(\n",
        "    env_name,\n",
        "    continuous = False,  # We will use the LunarLander environment with discrete action space\n",
        "    gravity = -10.0,\n",
        "    enable_wind = False,\n",
        "    wind_power = 15.0,\n",
        "    turbulence_power = 1.5,\n",
        "    render_mode='rgb_array'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking if the implementation is correct\n",
        "# use another environment on which REINFORCE has already been tested successful\n",
        "###############################################################################\n",
        "\n",
        "env = gym.make(\"CartPole-v1\",render_mode=\"rgb_array\")"
      ],
      "metadata": {
        "id": "bZ-ka5jPnMWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbpHGB-CSEBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386be873-065f-4786-ab65-87674b5166da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_dim:2\n",
            "observation_space_dim:4\n"
          ]
        }
      ],
      "source": [
        "action_space_dim = env.action_space.n\n",
        "print(f\"action_space_dim:{action_space_dim}\")\n",
        "\n",
        "observation_space_dim = env.observation_space.shape[0]\n",
        "print(f\"observation_space_dim:{observation_space_dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg_2fFLLP6Em"
      },
      "outputs": [],
      "source": [
        "#simple REINFORCE 1\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PolicyNet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(observation_space_dim,256)\n",
        "        self.fc2 = nn.Linear(256,128)\n",
        "        self.fc3 = nn.Linear(128,64)\n",
        "        self.fc4 = nn.Linear(64,32)\n",
        "        self.logits_layer = nn.Linear(32,action_space_dim)\n",
        "        self.ln1 = nn.LayerNorm(256)\n",
        "        self.ln2 = nn.LayerNorm(128)\n",
        "        self.ln3 = nn.LayerNorm(64)\n",
        "        self.ln4 = nn.LayerNorm(32)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(self.ln1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = nn.ReLU()(self.ln2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = nn.ReLU()(self.ln3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = nn.ReLU()(self.ln4(x))\n",
        "        x = self.logits_layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93G4I04ZWxYD"
      },
      "outputs": [],
      "source": [
        "# Base classes : PolicyStep & TimeStep\n",
        "\n",
        "from typing import NamedTuple , Optional , Union\n",
        "\n",
        "ActionType = Union[torch.Tensor,np.ndarray]\n",
        "TensorOrArray = Union[torch.Tensor, np.ndarray, int, float, str, bool]\n",
        "\n",
        "class PolicyStep(NamedTuple):\n",
        "    action: ActionType\n",
        "\n",
        "class TimeStep(NamedTuple):\n",
        "    observation : TensorOrArray\n",
        "    reward : TensorOrArray\n",
        "    step_type : TensorOrArray\n",
        "    discount : TensorOrArray\n",
        "\n",
        "    def is_first(self):\n",
        "        return np.equal(self.step_type, np.asarray(0, dtype= np.int32))\n",
        "    def is_mid(self):\n",
        "        return np.equal(self.step_type, np.asarray(1, dtype= np.int32))\n",
        "    def is_last(self):\n",
        "        return np.equal(self.step_type, np.asarray(2, dtype= np.int32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRm0shvjE_h2",
        "outputId": "0bf52513-63aa-44ee-e254-e5fa5b9fa49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: tensor([[-0.1234,  0.4805]], grad_fn=<AddmmBackward0>)\n",
            "sampled_action: tensor([0])\n",
            "[0]\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Correct configuration of the neural network to intake the observation from the environment\n",
        "\n",
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "s_0, info_0 = env.reset()\n",
        "\n",
        "net1 = PolicyNet1()\n",
        "\n",
        "s_0_tensor = torch.from_numpy(s_0).reshape(1,-1)\n",
        "\n",
        "logits_0 = net1(s_0_tensor)\n",
        "\n",
        "print(\"logits:\",logits_0)\n",
        "\n",
        "distribution = Categorical(logits=logits_0)\n",
        "\n",
        "sampled_action = distribution.sample()\n",
        "\n",
        "print(\"sampled_action:\",sampled_action)\n",
        "\n",
        "print(np.array(sampled_action))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_np = np.array([[10, 0]], dtype = float)\n",
        "logits_tensor = torch.from_numpy(logits_np)\n",
        "\n",
        "distribution = Categorical(logits=logits_tensor)\n",
        "\n",
        "sampled_action = distribution.sample()\n",
        "\n",
        "print(\"sampled_action:\",sampled_action)\n",
        "\n",
        "print(np.array(sampled_action))\n",
        "\n",
        "print(sampled_action.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkntDtxof6ca",
        "outputId": "3da902fe-aa26-4a37-894e-68c25583f9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sampled_action: tensor([0])\n",
            "[0]\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBDXujsK2kdz"
      },
      "outputs": [],
      "source": [
        "# print(s_0)\n",
        "# print(type(s_0))\n",
        "# print(s_0.shape)\n",
        "\n",
        "# print(logits_0)\n",
        "# print(type(logits_0))\n",
        "# print(logits_0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rrxg8IDRlZd"
      },
      "outputs": [],
      "source": [
        "#Helper functions for discounting reward & computing mean & std for baseline in REINFORCE\n",
        "\n",
        "def discount_rewards(rewards, discount_factor):\n",
        "    '''\n",
        "        Converts the rewards sequence to the discounted return sequence\n",
        "    '''\n",
        "\n",
        "    discounted = np.array(rewards)\n",
        "    for step in range(len(rewards)-2, -1, -1):\n",
        "        discounted[step] += discounted[step + 1] * discount_factor\n",
        "    return discounted\n",
        "\n",
        "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
        "    all_discounted_rewards = [discount_rewards(rewards,discount_factor) for rewards in all_rewards]\n",
        "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
        "    # return all_discounted_rewards\n",
        "    reward_mean = flat_rewards.mean()\n",
        "    reward_std = flat_rewards.std()\n",
        "    return [(discounted_rewards - reward_mean)/ reward_std for discounted_rewards in all_discounted_rewards]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPRqic3Z3UXT"
      },
      "outputs": [],
      "source": [
        "#function: create lists of batched obs, batched action and batched rewards\n",
        "\n",
        "# input: nested lists of obs, action , rewards\n",
        "# output: list of batched obs tensors, list of batched action tensors, list of batched rewards tensor\n",
        "\n",
        "import random\n",
        "\n",
        "def create_batches(obs_all, action_all, reward_all, batch_size):\n",
        "    # Shuffle the data to ensure each batch is a random sample\n",
        "    combined = list(zip(obs_all, action_all, reward_all))\n",
        "    random.shuffle(combined)\n",
        "    obs_all[:], action_all[:], reward_all[:] = zip(*combined)\n",
        "\n",
        "    # Calculate the total number of full batches\n",
        "    total_full_batches = len(obs_all) // batch_size\n",
        "    if total_full_batches == 0:\n",
        "        end_index = 0\n",
        "\n",
        "    # Create batched arrays\n",
        "    batched_obs = []\n",
        "    batched_actions = []\n",
        "    batched_rewards = []\n",
        "\n",
        "    for i in range(total_full_batches):\n",
        "        # Create a batch\n",
        "        start_index = i * batch_size\n",
        "        end_index = start_index + batch_size\n",
        "        obs_batch = torch.from_numpy(np.concatenate(obs_all[start_index:end_index], dtype=np.float32))\n",
        "        actions_batch = torch.tensor(action_all[start_index:end_index], dtype=torch.long)\n",
        "        rewards_batch = torch.tensor(reward_all[start_index:end_index], dtype=torch.float32)\n",
        "\n",
        "        # Append the batch to our list\n",
        "\n",
        "        obs_batch=obs_batch.to(device=device)\n",
        "        actions_batch=actions_batch.to(device=device)\n",
        "        rewards_batch=rewards_batch.to(device=device)\n",
        "\n",
        "        batched_obs.append(obs_batch)\n",
        "        # batched_actions.append(actions_batch[:, np.newaxis])  # Add a new axis for consistency\n",
        "        batched_actions.append(actions_batch) # in the `collect` method of the agent, the appended action is in shape (1,1), so actions_batch is in shape\n",
        "        batched_rewards.append(rewards_batch)\n",
        "\n",
        "    # Handle the last batch which might not be the full batch size\n",
        "    if len(obs_all) % batch_size != 0:\n",
        "        obs_batch = torch.from_numpy(np.concatenate(obs_all[end_index:], dtype=np.float32))\n",
        "        actions_batch = torch.tensor(action_all[end_index:], dtype=torch.long)\n",
        "        rewards_batch = torch.tensor(reward_all[end_index:], dtype=torch.float32)\n",
        "\n",
        "        obs_batch=obs_batch.to(device=device)\n",
        "        actions_batch=actions_batch.to(device=device)\n",
        "        rewards_batch=rewards_batch.to(device=device)\n",
        "\n",
        "        # Append the batch to our list\n",
        "        batched_obs.append(obs_batch)\n",
        "        # batched_actions.append(actions_batch[:, np.newaxis])\n",
        "        batched_actions.append(actions_batch)\n",
        "        batched_rewards.append(rewards_batch)\n",
        "\n",
        "    # print(\"Created batches\")\n",
        "    # print(f\"batch_obs shape:{batched_obs[0].shape}\")\n",
        "    # print(f\"batch_action shape:{batched_actions[0].shape}\")\n",
        "    # print(f\"batch_reward shape:{batched_rewards[0].shape}\")\n",
        "\n",
        "    return batched_obs, batched_actions, batched_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD1Pat9jqnm4"
      },
      "outputs": [],
      "source": [
        "#To create a REINFORCE algorithm for the LunarLander environment, we need to have the following:\n",
        "\n",
        "#1. A REINFORCE agent class, responsible for learning the policy through REINFORCE\n",
        "#2. A REINFORCE policy class, responsible for producing the PolicyStep that interacts with the environment\n",
        "\n",
        "class NeuralNetPolicy():\n",
        "    def __init__(self,Model_Class):\n",
        "        '''\n",
        "        Model Class is a neural network class, that an object instantiated of this class can take the state and output an action/prob logits\n",
        "        '''\n",
        "        self.net = Model_Class().cuda()\n",
        "\n",
        "\n",
        "    def action(self,time_step):\n",
        "        action_fn = self._action\n",
        "        policy_step = action_fn(time_step)\n",
        "\n",
        "        return policy_step\n",
        "\n",
        "    def _action(self,time_step):\n",
        "        '''\n",
        "        `_action` is for private use, same as all methods of which name starts with an underscore,\n",
        "\n",
        "        here the `_action` method calls the `_distribution` method to get the logits, then it\n",
        "        makes use of `tf.random.categorical` to sample an action from the given logits, finally\n",
        "        it embeds the sampled action in the PolicyStep object , which is to be returned\n",
        "        '''\n",
        "        distribution_step = self._distribution(time_step)\n",
        "        distribution = distribution_step.action\n",
        "\n",
        "        num_samples = 1\n",
        "\n",
        "        sampled_action = distribution.sample()\n",
        "\n",
        "        return PolicyStep(action = sampled_action)\n",
        "\n",
        "    def _distribution(self,time_step):\n",
        "        '''\n",
        "        _distribution is for private use, same as all methods of which name starts with an underscore\n",
        "\n",
        "        here it just passes the state (which in our case is identical to the observation) to the net\n",
        "        and returns the logits\n",
        "        '''\n",
        "\n",
        "        policy_logits = self.net(time_step.observation)\n",
        "\n",
        "        distribution = Categorical(logits=policy_logits)\n",
        "\n",
        "        return PolicyStep(action = distribution)\n",
        "\n",
        "\n",
        "\n",
        "class REINFORCEAgent():\n",
        "    def __init__(self):\n",
        "        # self._policy = NeuralNetPolicy(SimplePolicyNet)\n",
        "        self._policy = NeuralNetPolicy(PolicyNet1)\n",
        "        self._collect_policy = self._policy\n",
        "\n",
        "    def train(self,optimizer,obs,action,reward):\n",
        "        \"\"\" method for training self.policy\n",
        "\n",
        "        experience is a tuple consisting of 3 lists: obs, action, reward\n",
        "\n",
        "        this `train` is designed to train on a single batch, as aligned with common ML API design\n",
        "        \"\"\"\n",
        "\n",
        "        #REINFORCE learning algorithm\n",
        "        #1. input the obs to the net first, and get the logits as output\n",
        "        #2. set up the loss function correctly such that its gradient aligns with the policy gradient;\n",
        "        #   in REINFORCE (with baseline), the gradient is proportional to the return, inversely proportional to the probability\n",
        "        #   del J(theta) = (R_t - baseline)/P(A_t) * del P(A_t)\n",
        "        #   or : del J(theta) = (R_t - baseline) * del ln(P(A_t))\n",
        "        #   Hence, the loss function would be the cross entropy of actual action log action probabilities\n",
        "        #   multiplied by (R_t - baseline)\n",
        "        #3. backpropagation\n",
        "\n",
        "        #####################################################################################################################################\n",
        "        #\n",
        "        # PyTorch : Calculating Cross Entropy from logits, Method 1: F.cross_entropy(logits, one_hot_label)\n",
        "        #\n",
        "        #####################################################################################################################################\n",
        "\n",
        "        # logits = self._policy.net(obs)\n",
        "        # action_one_hot = F.one_hot(action,num_classes=action_space_dim).to(dtype=torch.float32)\n",
        "\n",
        "        # # both logits and action_one_hot should be of the same shape and data type : (n,d)\n",
        "        # cross_entropy_vector = F.cross_entropy(logits,action_one_hot,reduction='none')\n",
        "\n",
        "        # loss_vector = reward * cross_entropy_vector\n",
        "\n",
        "        # loss = torch.mean(loss_vector)\n",
        "\n",
        "        #####################################################################################################################################\n",
        "        #\n",
        "        # PyTorch : Calculating Cross Entropy from logits, Method 2: Categorical log_probs\n",
        "        #\n",
        "        # Input the batched_action as argument in log_prob, then multiply by -1 to get the Cross entropy vector\n",
        "        # Multiply the CE vector with reward vector to get the batched negative objective function\n",
        "        # whose negative gradients are in the same direction as gradients to increase expected return\n",
        "        #\n",
        "        #####################################################################################################################################\n",
        "\n",
        "        logits = self._policy.net(obs)\n",
        "        m = Categorical(logits=logits)\n",
        "        CE_vector = -1 * m.log_prob(batched_action)\n",
        "        loss_vector = CE_vector * batched_reward\n",
        "\n",
        "        loss = torch.mean(loss_vector)\n",
        "\n",
        "        # Values checking:\n",
        "        # print(\"batched_obs\", batched_obs)\n",
        "        # print(\"logits\", logits)\n",
        "        # print(\"batched_actions\", batched_actions)\n",
        "        # print(\"action_one_hot\", action_one_hot)\n",
        "        # print(\"cross entropy vector\",cross_entropy_vector)\n",
        "        # print(\"rewards vector\", batched_rewards)\n",
        "        # print(\"loss vector\",loss_vector)\n",
        "        # print(\"loss\",loss)\n",
        "\n",
        "        # Shape checking:\n",
        "\n",
        "        # print(f\"batched obs shape,{batched_obs[j].shape}\")\n",
        "        # print(f\"batched_actions shape, {batched_actions[j].shape}\")\n",
        "        # print(f\"logits shape:{logits.shape}, action_one_hot shape:{action_one_hot.shape}\")\n",
        "        # print(f\"loss vector shape:{loss_vector.shape}\")\n",
        "        # print(f\"loss shape:{loss.shape}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def collect(self,env,n_episodes):\n",
        "        all_obs_collect = []\n",
        "        all_action_collect = []\n",
        "        all_reward_collect = []\n",
        "\n",
        "        for i in range(n_episodes):\n",
        "            # Initialize the collection variables\n",
        "            obs_collect = []\n",
        "            action_collect = []\n",
        "            reward_collect = []\n",
        "            total_reward = 0\n",
        "            done, truncate = False, False\n",
        "\n",
        "            obs, info = env.reset()\n",
        "            obs = obs.reshape(1,-1)\n",
        "            obs_tensor = torch.from_numpy(obs).cuda()\n",
        "            reward = np.asarray(0, dtype= np.float32)\n",
        "            step_type = np.asarray(0, dtype= np.float32) # step type with content value of 0 means a FIRST step type\n",
        "            discount_factor = 1\n",
        "\n",
        "            time_step = TimeStep(obs_tensor,reward,step_type,discount_factor)\n",
        "            total_reward += reward\n",
        "\n",
        "            while not (done or truncate):\n",
        "                policy_step = self.policy.action(time_step)\n",
        "                action_int = policy_step.action.reshape(-1).item() # has to convert the tensor to int since the environment accepts the action as int\n",
        "                action_int = int(action_int)\n",
        "\n",
        "                #Collect experience: observation and action are collected before step()\n",
        "                obs_collect.append(obs) # (obs_dim,)\n",
        "                action_collect.append(action_int) # 0-dim scalar\n",
        "\n",
        "                obs, reward, done, truncate, info = env.step(action_int)\n",
        "                obs = obs.reshape(1,-1)\n",
        "                obs_tensor = torch.from_numpy(obs).cuda()\n",
        "\n",
        "                #Collect experience: reward is collected after step()\n",
        "                reward_collect.append(reward) # 0-dim scalar\n",
        "\n",
        "                if done or truncate:\n",
        "                    step_type = np.asarray(2,dtype=np.int32) # step type with content value of 2 means a LAST step type\n",
        "                else:\n",
        "                    step_type = np.asarray(1,dtype=np.int32) # step type with content value of 1 means a MID step type\n",
        "\n",
        "                time_step = TimeStep(obs_tensor,reward,step_type,discount_factor)\n",
        "                total_reward += reward\n",
        "\n",
        "            all_obs_collect.append(obs_collect)\n",
        "            all_action_collect.append(action_collect)\n",
        "            all_reward_collect.append(reward_collect)\n",
        "\n",
        "            print(f\" Episode return:{total_reward} \",end='')\n",
        "\n",
        "        #Discount and normalize rewards\n",
        "        returns_all = [discount_rewards(x,discount_factor=1) for x in all_reward_collect]\n",
        "        reward_all = [x for reward_episode in returns_all for x in reward_episode]\n",
        "        reward_mean = np.mean(reward_all)\n",
        "\n",
        "        print(f\"Mean reward:{reward_mean} \",end='')\n",
        "\n",
        "        all_reward_collect_discounted = discount_and_normalize_rewards(all_reward_collect,discount_factor)\n",
        "        return all_obs_collect, all_action_collect, all_reward_collect_discounted\n",
        "\n",
        "    @property\n",
        "    def policy(self):\n",
        "        \"\"\" Return the current policy of the agent.\n",
        "\n",
        "        Returns:\n",
        "            A `Policy` object\n",
        "        \"\"\"\n",
        "\n",
        "        return self._policy\n",
        "\n",
        "    @property\n",
        "    def collect_policy(self):\n",
        "        \"\"\" Return the environment exploration policy of the agent.\n",
        "\n",
        "        Returns:\n",
        "            A `Policy` object\n",
        "        \"\"\"\n",
        "        return self._collect_policy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_collected_data(episodes_obs_collect, episodes_action_collect, episodes_reward_collect):\n",
        "    # Check if all outer lists contain the same number of episodes\n",
        "    assert len(episodes_obs_collect) == len(episodes_action_collect) == len(episodes_reward_collect), \\\n",
        "        \"The number of episodes collected does not match across observations, actions, and rewards.\"\n",
        "\n",
        "    # Check if each episode contains the same number of observations, actions, and rewards\n",
        "    for episode_index in range(len(episodes_obs_collect)):\n",
        "        num_obs = len(episodes_obs_collect[episode_index])\n",
        "        num_actions = len(episodes_action_collect[episode_index])\n",
        "        num_rewards = len(episodes_reward_collect[episode_index])\n",
        "\n",
        "        assert num_obs == num_actions == num_rewards, \\\n",
        "            f\"Episode {episode_index} has mismatched lengths: \" \\\n",
        "            f\"Observations: {num_obs}, Actions: {num_actions}, Rewards: {num_rewards}\"\n",
        "\n",
        "    print(\"All tests passed - Data collection is consistent.\")"
      ],
      "metadata": {
        "id": "nZNK1P_NSoeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent1 = REINFORCEAgent()\n",
        "# optimizer = torch.optim.Adam(lr=0.001,eps=1e-8,params=agent1.policy.net.parameters())\n",
        "\n",
        "optimizer = torch.optim.SGD(lr=0.0001,params=agent1.policy.net.parameters())"
      ],
      "metadata": {
        "id": "jLxZojHlP5hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZVRgRtMhZdS",
        "outputId": "3bcf157f-df4c-49ba-e7ee-fada00004930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Episode return:18.0  Episode return:10.0  Episode return:9.0  Episode return:11.0  Episode return:15.0  Episode return:11.0  Episode return:15.0  Episode return:19.0  Episode return:30.0  Episode return:22.0 Mean reward:9.69375 <class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "All tests passed - Data collection is consistent.\n",
            "10\n",
            "18\n",
            "[array([[ 0.0109067 ,  0.04891024,  0.03626722, -0.04919273]],\n",
            "      dtype=float32), array([[ 0.01188491,  0.24349388,  0.03528336, -0.33021605]],\n",
            "      dtype=float32), array([[ 0.01675478,  0.43809628,  0.02867904, -0.6115668 ]],\n",
            "      dtype=float32), array([[ 0.02551671,  0.6328059 ,  0.01644771, -0.8950806 ]],\n",
            "      dtype=float32), array([[ 0.03817283,  0.82770103, -0.0014539 , -1.1825484 ]],\n",
            "      dtype=float32), array([[ 0.05472685,  0.632598  , -0.02510487, -0.89032155]],\n",
            "      dtype=float32), array([[ 0.0673788,  0.8280514, -0.0429113, -1.1907893]], dtype=float32), array([[ 0.08393984,  0.63351095, -0.06672709, -0.91185933]],\n",
            "      dtype=float32), array([[ 0.09661005,  0.43935218, -0.08496428, -0.64087254]],\n",
            "      dtype=float32), array([[ 0.1053971 ,  0.24551101, -0.09778173, -0.37610912]],\n",
            "      dtype=float32), array([[ 0.11030731,  0.44187596, -0.10530391, -0.6979516 ]],\n",
            "      dtype=float32), array([[ 0.11914483,  0.63828826, -0.11926294, -1.0218402 ]],\n",
            "      dtype=float32), array([[ 0.1319106 ,  0.4449396 , -0.13969974, -0.76885766]],\n",
            "      dtype=float32), array([[ 0.14080939,  0.25198862, -0.15507689, -0.52318907]],\n",
            "      dtype=float32), array([[ 0.14584917,  0.05935025, -0.16554068, -0.28310916]],\n",
            "      dtype=float32), array([[ 0.14703616,  0.25639877, -0.17120287, -0.62308824]],\n",
            "      dtype=float32), array([[ 0.15216415,  0.4534453 , -0.18366463, -0.9644251 ]],\n",
            "      dtype=float32), array([[ 0.16123305,  0.65049577, -0.20295313, -1.3087239 ]],\n",
            "      dtype=float32)]\n",
            "10\n",
            "18\n",
            "[1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "10\n",
            "18\n",
            "[ 1.25975299  1.10808973  0.95642646  0.8047632   0.65309993  0.50143667\n",
            "  0.3497734   0.19811014  0.04644687 -0.10521639 -0.25687965 -0.40854292\n",
            " -0.56020618 -0.71186945 -0.86353271 -1.01519598 -1.16685924 -1.31852251]\n"
          ]
        }
      ],
      "source": [
        "# Test agent's `collect`\n",
        "all_obs_collect, all_action_collect, all_reward_collect_discounted = agent1.collect(env,10)\n",
        "\n",
        "print(type(all_obs_collect))\n",
        "print(type(all_action_collect))\n",
        "print(type(all_reward_collect_discounted))\n",
        "\n",
        "print(type(all_obs_collect[0]))\n",
        "print(type(all_action_collect[0]))\n",
        "print(type(all_reward_collect_discounted[0]))\n",
        "\n",
        "test_collected_data(all_obs_collect,all_action_collect,all_reward_collect_discounted)\n",
        "\n",
        "print(len(all_obs_collect))\n",
        "print(len(all_obs_collect[0]))\n",
        "print(all_obs_collect[0])\n",
        "\n",
        "print(len(all_action_collect))\n",
        "print(len(all_action_collect[0]))\n",
        "print(all_action_collect[0])\n",
        "\n",
        "print(len(all_reward_collect_discounted))\n",
        "print(len(all_reward_collect_discounted[0]))\n",
        "\n",
        "print(all_reward_collect_discounted[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test create batches\n",
        "\n",
        "obs,action,reward = agent1.collect(env,10)\n",
        "\n",
        "obs_merged = [x for obs_episode in obs for x in obs_episode]\n",
        "action_merged = [x for action_episode in action for x in action_episode]\n",
        "reward_merged = [x for reward_episode in reward for x in reward_episode]\n",
        "\n",
        "batches_obs, batches_action, batches_reward = create_batches(obs_merged,action_merged,reward_merged,batch_size=16)\n",
        "\n",
        "print(len(batches_obs))\n",
        "print(len(batches_action))\n",
        "print(len(batches_reward))\n",
        "\n",
        "print(type(batches_obs[0]))\n",
        "print(type(batches_action[0]))\n",
        "print(type(batches_reward[0]))\n",
        "\n",
        "print(batches_obs[0].shape)\n",
        "print(batches_action[0].shape)\n",
        "print(batches_reward[0].shape)\n",
        "\n",
        "print(batches_obs[0].device)\n",
        "print(batches_action[0].device)\n",
        "print(batches_reward[0].device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5krrsb-PwXUr",
        "outputId": "61370820-e929-4006-adb5-046226deb6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Episode return:15.0  Episode return:17.0  Episode return:13.0  Episode return:47.0  Episode return:14.0  Episode return:14.0  Episode return:13.0  Episode return:14.0  Episode return:14.0  Episode return:17.0 Mean reward:1.0 12\n",
            "12\n",
            "12\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 4])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zGOFa5i3u9yO",
        "outputId": "76b08b77-3b4a-48b2-e3b3-5f178ac586e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Episode return:14.0  Episode return:20.0 Mean reward:9.264705882352942  i:0, n batches:1 \n",
            "loss:0.015016906894743443\n",
            " Episode return:18.0  Episode return:10.0 Mean reward:8.071428571428571  i:1, n batches:1 \n",
            " Episode return:19.0  Episode return:20.0 Mean reward:10.256410256410257  i:2, n batches:1 \n",
            " Episode return:25.0  Episode return:19.0 Mean reward:11.704545454545455  i:3, n batches:1 \n",
            " Episode return:12.0  Episode return:22.0 Mean reward:9.735294117647058  i:4, n batches:1 \n",
            " Episode return:19.0  Episode return:23.0 Mean reward:11.095238095238095  i:5, n batches:1 \n",
            " Episode return:44.0  Episode return:13.0 Mean reward:18.964912280701753  i:6, n batches:1 \n",
            " Episode return:14.0  Episode return:16.0 Mean reward:8.033333333333333  i:7, n batches:1 \n",
            " Episode return:9.0  Episode return:21.0 Mean reward:9.2  i:8, n batches:1 \n",
            " Episode return:13.0  Episode return:24.0 Mean reward:10.567567567567568  i:9, n batches:1 \n",
            " Episode return:11.0  Episode return:11.0 Mean reward:6.0  i:10, n batches:1 \n",
            " Episode return:22.0  Episode return:16.0 Mean reward:10.236842105263158  i:11, n batches:1 \n",
            " Episode return:17.0  Episode return:12.0 Mean reward:7.9655172413793105  i:12, n batches:1 \n",
            " Episode return:10.0  Episode return:28.0 Mean reward:12.131578947368421  i:13, n batches:1 \n",
            " Episode return:12.0  Episode return:21.0 Mean reward:9.363636363636363  i:14, n batches:1 \n",
            " Episode return:11.0  Episode return:9.0 Mean reward:5.55  i:15, n batches:1 \n",
            " Episode return:26.0  Episode return:25.0 Mean reward:13.254901960784315  i:16, n batches:1 \n",
            " Episode return:26.0  Episode return:22.0 Mean reward:12.583333333333334  i:17, n batches:1 \n",
            " Episode return:16.0  Episode return:28.0 Mean reward:12.318181818181818  i:18, n batches:1 \n",
            " Episode return:21.0  Episode return:13.0 Mean reward:9.470588235294118  i:19, n batches:1 \n",
            " Episode return:27.0  Episode return:12.0 Mean reward:11.692307692307692  i:20, n batches:1 \n",
            " Episode return:9.0  Episode return:12.0 Mean reward:5.857142857142857  i:21, n batches:1 \n",
            " Episode return:15.0  Episode return:19.0 Mean reward:9.117647058823529  i:22, n batches:1 \n",
            " Episode return:12.0  Episode return:15.0 Mean reward:7.333333333333333  i:23, n batches:1 \n",
            " Episode return:15.0  Episode return:13.0 Mean reward:7.535714285714286  i:24, n batches:1 \n",
            " Episode return:25.0  Episode return:18.0 Mean reward:11.534883720930232  i:25, n batches:1 \n",
            " Episode return:23.0  Episode return:9.0 Mean reward:10.03125  i:26, n batches:1 \n",
            " Episode return:12.0  Episode return:11.0 Mean reward:6.260869565217392  i:27, n batches:1 \n",
            " Episode return:29.0  Episode return:13.0 Mean reward:12.523809523809524  i:28, n batches:1 \n",
            " Episode return:39.0  Episode return:13.0 Mean reward:16.75  i:29, n batches:1 \n",
            " Episode return:37.0  Episode return:15.0 Mean reward:15.826923076923077  i:30, n batches:1 \n",
            " Episode return:23.0  Episode return:17.0 Mean reward:10.725  i:31, n batches:1 \n",
            " Episode return:16.0  Episode return:27.0 Mean reward:11.953488372093023  i:32, n batches:1 \n",
            " Episode return:21.0  Episode return:16.0 Mean reward:9.91891891891892  i:33, n batches:1 \n",
            " Episode return:35.0  Episode return:39.0 Mean reward:19.054054054054053  i:34, n batches:1 \n",
            " Episode return:26.0  Episode return:27.0 Mean reward:13.754716981132075  i:35, n batches:1 \n",
            " Episode return:18.0  Episode return:27.0 Mean reward:12.2  i:36, n batches:1 \n",
            " Episode return:16.0  Episode return:14.0 Mean reward:8.033333333333333  i:37, n batches:1 \n",
            " Episode return:20.0  Episode return:56.0 Mean reward:23.763157894736842  i:38, n batches:1 \n",
            " Episode return:14.0  Episode return:39.0 Mean reward:16.69811320754717  i:39, n batches:1 \n",
            " Episode return:22.0  Episode return:20.0 Mean reward:11.023809523809524  i:40, n batches:1 \n",
            " Episode return:11.0  Episode return:26.0 Mean reward:11.27027027027027  i:41, n batches:1 \n",
            " Episode return:24.0  Episode return:14.0 Mean reward:10.657894736842104  i:42, n batches:1 \n",
            " Episode return:16.0  Episode return:18.0 Mean reward:9.029411764705882  i:43, n batches:1 \n",
            " Episode return:18.0  Episode return:9.0 Mean reward:8.0  i:44, n batches:1 \n",
            " Episode return:27.0  Episode return:23.0 Mean reward:13.08  i:45, n batches:1 \n",
            " Episode return:11.0  Episode return:20.0 Mean reward:8.903225806451612  i:46, n batches:1 \n",
            " Episode return:29.0  Episode return:40.0 Mean reward:18.18840579710145  i:47, n batches:1 \n",
            " Episode return:9.0  Episode return:13.0 Mean reward:6.181818181818182  i:48, n batches:1 \n",
            " Episode return:13.0  Episode return:16.0 Mean reward:7.827586206896552  i:49, n batches:1 \n",
            " Episode return:13.0  Episode return:9.0 Mean reward:6.181818181818182  i:50, n batches:1 \n",
            " Episode return:9.0  Episode return:20.0 Mean reward:8.793103448275861  i:51, n batches:1 \n",
            " Episode return:15.0  Episode return:24.0 Mean reward:10.76923076923077  i:52, n batches:1 \n",
            " Episode return:24.0  Episode return:22.0 Mean reward:12.021739130434783  i:53, n batches:1 \n",
            " Episode return:34.0  Episode return:17.0 Mean reward:14.666666666666666  i:54, n batches:1 \n",
            " Episode return:26.0  Episode return:10.0 Mean reward:11.277777777777779  i:55, n batches:1 \n",
            " Episode return:21.0  Episode return:10.0 Mean reward:9.225806451612904  i:56, n batches:1 \n",
            " Episode return:15.0  Episode return:24.0 Mean reward:10.76923076923077  i:57, n batches:1 \n",
            " Episode return:11.0  Episode return:16.0 Mean reward:7.481481481481482  i:58, n batches:1 \n",
            " Episode return:22.0  Episode return:15.0 Mean reward:10.08108108108108  i:59, n batches:1 \n",
            " Episode return:23.0  Episode return:17.0 Mean reward:10.725  i:60, n batches:1 \n",
            " Episode return:16.0  Episode return:18.0 Mean reward:9.029411764705882  i:61, n batches:1 \n",
            " Episode return:16.0  Episode return:31.0 Mean reward:13.446808510638299  i:62, n batches:1 \n",
            " Episode return:13.0  Episode return:17.0 Mean reward:8.133333333333333  i:63, n batches:1 \n",
            " Episode return:20.0  Episode return:12.0 Mean reward:9.0  i:64, n batches:1 \n",
            " Episode return:20.0  Episode return:11.0 Mean reward:8.903225806451612  i:65, n batches:1 \n",
            " Episode return:14.0  Episode return:30.0 Mean reward:12.954545454545455  i:66, n batches:1 \n",
            " Episode return:15.0  Episode return:12.0 Mean reward:7.333333333333333  i:67, n batches:1 \n",
            " Episode return:19.0  Episode return:26.0 Mean reward:12.022222222222222  i:68, n batches:1 \n",
            " Episode return:18.0  Episode return:38.0 Mean reward:16.285714285714285  i:69, n batches:1 \n",
            " Episode return:17.0  Episode return:22.0 Mean reward:10.41025641025641  i:70, n batches:1 \n",
            " Episode return:13.0  Episode return:26.0 Mean reward:11.333333333333334  i:71, n batches:1 \n",
            " Episode return:19.0  Episode return:22.0 Mean reward:10.804878048780488  i:72, n batches:1 \n",
            " Episode return:14.0  Episode return:16.0 Mean reward:8.033333333333333  i:73, n batches:1 \n",
            " Episode return:10.0  Episode return:25.0 Mean reward:10.857142857142858  i:74, n batches:1 \n",
            " Episode return:20.0  Episode return:28.0 Mean reward:12.833333333333334  i:75, n batches:1 \n",
            " Episode return:11.0  Episode return:18.0 Mean reward:8.172413793103448  i:76, n batches:1 \n",
            " Episode return:42.0  Episode return:9.0 Mean reward:18.58823529411765  i:77, n batches:1 \n",
            " Episode return:23.0  Episode return:21.0 Mean reward:11.522727272727273  i:78, n batches:1 \n",
            " Episode return:17.0  Episode return:24.0 Mean reward:11.048780487804878  i:79, n batches:1 \n",
            " Episode return:13.0  Episode return:18.0 Mean reward:8.451612903225806  i:80, n batches:1 \n",
            " Episode return:16.0  Episode return:20.0 Mean reward:9.61111111111111  i:81, n batches:1 \n",
            " Episode return:14.0  Episode return:19.0 Mean reward:8.93939393939394  i:82, n batches:1 \n",
            " Episode return:16.0  Episode return:16.0 Mean reward:8.5  i:83, n batches:1 \n",
            " Episode return:36.0  Episode return:12.0 Mean reward:15.5  i:84, n batches:1 \n",
            " Episode return:23.0  Episode return:15.0 Mean reward:10.421052631578947  i:85, n batches:1 \n",
            " Episode return:10.0  Episode return:15.0 Mean reward:7.0  i:86, n batches:1 \n",
            " Episode return:13.0  Episode return:11.0 Mean reward:6.541666666666667  i:87, n batches:1 \n",
            " Episode return:13.0  Episode return:25.0 Mean reward:10.947368421052632  i:88, n batches:1 \n",
            " Episode return:10.0  Episode return:17.0 Mean reward:7.703703703703703  i:89, n batches:1 \n",
            " Episode return:33.0  Episode return:15.0 Mean reward:14.1875  i:90, n batches:1 \n",
            " Episode return:24.0  Episode return:27.0 Mean reward:13.294117647058824  i:91, n batches:1 \n",
            " Episode return:22.0  Episode return:35.0 Mean reward:15.491228070175438  i:92, n batches:1 \n",
            " Episode return:26.0  Episode return:11.0 Mean reward:11.27027027027027  i:93, n batches:1 \n",
            " Episode return:19.0  Episode return:13.0 Mean reward:8.78125  i:94, n batches:1 \n",
            " Episode return:22.0  Episode return:29.0 Mean reward:13.490196078431373  i:95, n batches:1 \n",
            " Episode return:17.0  Episode return:12.0 Mean reward:7.9655172413793105  i:96, n batches:1 \n",
            " Episode return:43.0  Episode return:16.0 Mean reward:18.338983050847457  i:97, n batches:1 \n",
            " Episode return:20.0  Episode return:33.0 Mean reward:14.547169811320755  i:98, n batches:1 \n",
            " Episode return:13.0  Episode return:61.0 Mean reward:26.783783783783782  i:99, n batches:1 \n",
            " Episode return:12.0  Episode return:12.0 Mean reward:6.5  i:100, n batches:1 \n",
            "loss:-0.028389647603034973\n",
            " Episode return:19.0  Episode return:59.0 Mean reward:25.128205128205128  i:101, n batches:1 \n",
            " Episode return:56.0  Episode return:53.0 Mean reward:27.770642201834864  i:102, n batches:1 \n",
            " Episode return:31.0  Episode return:50.0 Mean reward:21.864197530864196  i:103, n batches:1 \n",
            " Episode return:14.0  Episode return:30.0 Mean reward:12.954545454545455  i:104, n batches:1 \n",
            " Episode return:50.0  Episode return:12.0 Mean reward:21.822580645161292  i:105, n batches:1 \n",
            " Episode return:13.0  Episode return:15.0 Mean reward:7.535714285714286  i:106, n batches:1 \n",
            " Episode return:18.0  Episode return:21.0 Mean reward:10.307692307692308  i:107, n batches:1 \n",
            " Episode return:14.0  Episode return:14.0 Mean reward:7.5  i:108, n batches:1 \n",
            " Episode return:14.0  Episode return:23.0 Mean reward:10.297297297297296  i:109, n batches:1 \n",
            " Episode return:25.0  Episode return:24.0 Mean reward:12.755102040816327  i:110, n batches:1 \n",
            " Episode return:17.0  Episode return:17.0 Mean reward:9.0  i:111, n batches:1 \n",
            " Episode return:34.0  Episode return:12.0 Mean reward:14.630434782608695  i:112, n batches:1 \n",
            " Episode return:12.0  Episode return:31.0 Mean reward:13.348837209302326  i:113, n batches:1 \n",
            " Episode return:13.0  Episode return:13.0 Mean reward:7.0  i:114, n batches:1 \n",
            " Episode return:37.0  Episode return:15.0 Mean reward:15.826923076923077  i:115, n batches:1 \n",
            " Episode return:10.0  Episode return:19.0 Mean reward:8.448275862068966  i:116, n batches:1 \n",
            " Episode return:21.0  Episode return:18.0 Mean reward:10.307692307692308  i:117, n batches:1 \n",
            " Episode return:26.0  Episode return:16.0 Mean reward:11.595238095238095  i:118, n batches:1 \n",
            " Episode return:17.0  Episode return:11.0 Mean reward:7.821428571428571  i:119, n batches:1 \n",
            " Episode return:23.0  Episode return:23.0 Mean reward:12.0  i:120, n batches:1 \n",
            " Episode return:13.0  Episode return:15.0 Mean reward:7.535714285714286  i:121, n batches:1 \n",
            " Episode return:30.0  Episode return:13.0 Mean reward:12.930232558139535  i:122, n batches:1 \n",
            " Episode return:21.0  Episode return:14.0 Mean reward:9.6  i:123, n batches:1 \n",
            " Episode return:28.0  Episode return:13.0 Mean reward:12.121951219512194  i:124, n batches:1 \n",
            " Episode return:15.0  Episode return:21.0 Mean reward:9.75  i:125, n batches:1 \n",
            " Episode return:17.0  Episode return:23.0 Mean reward:10.725  i:126, n batches:1 \n",
            " Episode return:32.0  Episode return:16.0 Mean reward:13.833333333333334  i:127, n batches:1 \n",
            " Episode return:10.0  Episode return:25.0 Mean reward:10.857142857142858  i:128, n batches:1 \n",
            " Episode return:11.0  Episode return:19.0 Mean reward:8.533333333333333  i:129, n batches:1 \n",
            " Episode return:11.0  Episode return:23.0 Mean reward:10.058823529411764  i:130, n batches:1 \n",
            " Episode return:15.0  Episode return:27.0 Mean reward:11.857142857142858  i:131, n batches:1 \n",
            " Episode return:22.0  Episode return:17.0 Mean reward:10.41025641025641  i:132, n batches:1 \n",
            " Episode return:38.0  Episode return:26.0 Mean reward:17.0625  i:133, n batches:1 \n",
            " Episode return:50.0  Episode return:26.0 Mean reward:21.394736842105264  i:134, n batches:1 \n",
            " Episode return:30.0  Episode return:13.0 Mean reward:12.930232558139535  i:135, n batches:1 \n",
            " Episode return:38.0  Episode return:21.0 Mean reward:16.47457627118644  i:136, n batches:1 \n",
            " Episode return:16.0  Episode return:44.0 Mean reward:18.766666666666666  i:137, n batches:1 \n",
            " Episode return:11.0  Episode return:26.0 Mean reward:11.27027027027027  i:138, n batches:1 \n",
            " Episode return:20.0  Episode return:28.0 Mean reward:12.833333333333334  i:139, n batches:1 \n",
            " Episode return:27.0  Episode return:34.0 Mean reward:15.950819672131148  i:140, n batches:1 \n",
            " Episode return:28.0  Episode return:19.0 Mean reward:12.680851063829786  i:141, n batches:1 \n",
            " Episode return:22.0  Episode return:51.0 Mean reward:21.63013698630137  i:142, n batches:1 \n",
            " Episode return:21.0  Episode return:37.0 Mean reward:16.103448275862068  i:143, n batches:1 \n",
            " Episode return:15.0  Episode return:18.0 Mean reward:8.818181818181818  i:144, n batches:1 \n",
            " Episode return:9.0  Episode return:24.0 Mean reward:10.454545454545455  i:145, n batches:1 \n",
            " Episode return:18.0  Episode return:26.0 Mean reward:11.863636363636363  i:146, n batches:1 \n",
            " Episode return:12.0  Episode return:24.0 Mean reward:10.5  i:147, n batches:1 \n",
            " Episode return:32.0  Episode return:12.0 Mean reward:13.772727272727273  i:148, n batches:1 \n",
            " Episode return:12.0  Episode return:23.0 Mean reward:10.114285714285714  i:149, n batches:1 \n",
            " Episode return:36.0  Episode return:29.0 Mean reward:16.93846153846154  i:150, n batches:1 \n",
            " Episode return:14.0  Episode return:14.0 Mean reward:7.5  i:151, n batches:1 \n",
            " Episode return:13.0  Episode return:13.0 Mean reward:7.0  i:152, n batches:1 \n",
            " Episode return:19.0  Episode return:14.0 Mean reward:8.93939393939394  i:153, n batches:1 \n",
            " Episode return:26.0  Episode return:15.0 Mean reward:11.487804878048781  i:154, n batches:1 \n",
            " Episode return:30.0  Episode return:12.0 Mean reward:12.928571428571429  i:155, n batches:1 \n",
            " Episode return:16.0  Episode return:13.0 Mean reward:7.827586206896552  i:156, n batches:1 \n",
            " Episode return:20.0  Episode return:31.0 Mean reward:13.843137254901961  i:157, n batches:1 \n",
            " Episode return:23.0  Episode return:11.0 Mean reward:10.058823529411764  i:158, n batches:1 \n",
            " Episode return:29.0  Episode return:13.0 Mean reward:12.523809523809524  i:159, n batches:1 \n",
            " Episode return:34.0  Episode return:43.0 Mean reward:20.01298701298701  i:160, n batches:1 \n",
            " Episode return:18.0  Episode return:27.0 Mean reward:12.2  i:161, n batches:1 \n",
            " Episode return:51.0  Episode return:19.0 Mean reward:21.65714285714286  i:162, n batches:1 \n",
            " Episode return:14.0  Episode return:12.0 Mean reward:7.038461538461538  i:163, n batches:1 \n",
            " Episode return:15.0  Episode return:22.0 Mean reward:10.08108108108108  i:164, n batches:1 \n",
            " Episode return:29.0  Episode return:10.0 Mean reward:12.564102564102564  i:165, n batches:1 \n",
            " Episode return:14.0  Episode return:12.0 Mean reward:7.038461538461538  i:166, n batches:1 \n",
            " Episode return:12.0  Episode return:21.0 Mean reward:9.363636363636363  i:167, n batches:1 \n",
            " Episode return:23.0  Episode return:49.0 Mean reward:20.84722222222222  i:168, n batches:1 \n",
            " Episode return:32.0  Episode return:34.0 Mean reward:17.015151515151516  i:169, n batches:1 \n",
            " Episode return:24.0  Episode return:21.0 Mean reward:11.8  i:170, n batches:1 \n",
            " Episode return:22.0  Episode return:59.0 Mean reward:24.97530864197531  i:171, n batches:1 \n",
            " Episode return:10.0  Episode return:31.0 Mean reward:13.439024390243903  i:172, n batches:1 \n",
            " Episode return:18.0  Episode return:11.0 Mean reward:8.172413793103448  i:173, n batches:1 \n",
            " Episode return:32.0  Episode return:20.0 Mean reward:14.192307692307692  i:174, n batches:1 \n",
            " Episode return:14.0  Episode return:31.0 Mean reward:13.355555555555556  i:175, n batches:1 \n",
            " Episode return:21.0  Episode return:13.0 Mean reward:9.470588235294118  i:176, n batches:1 \n",
            " Episode return:41.0  Episode return:41.0 Mean reward:21.0  i:177, n batches:1 \n",
            " Episode return:19.0  Episode return:32.0 Mean reward:14.07843137254902  i:178, n batches:1 \n",
            " Episode return:25.0  Episode return:81.0 Mean reward:34.39622641509434  i:179, n batches:1 \n",
            " Episode return:18.0  Episode return:43.0 Mean reward:18.311475409836067  i:180, n batches:1 \n",
            " Episode return:15.0  Episode return:16.0 Mean reward:8.258064516129032  i:181, n batches:1 \n",
            " Episode return:28.0  Episode return:18.0 Mean reward:12.543478260869565  i:182, n batches:1 \n",
            " Episode return:17.0  Episode return:20.0 Mean reward:9.81081081081081  i:183, n batches:1 \n",
            " Episode return:17.0  Episode return:34.0 Mean reward:14.666666666666666  i:184, n batches:1 \n",
            " Episode return:17.0  Episode return:19.0 Mean reward:9.527777777777779  i:185, n batches:1 \n",
            " Episode return:13.0  Episode return:13.0 Mean reward:7.0  i:186, n batches:1 \n",
            " Episode return:18.0  Episode return:26.0 Mean reward:11.863636363636363  i:187, n batches:1 \n",
            " Episode return:16.0  Episode return:10.0 Mean reward:7.346153846153846  i:188, n batches:1 \n",
            " Episode return:11.0  Episode return:12.0 Mean reward:6.260869565217392  i:189, n batches:1 \n",
            " Episode return:20.0  Episode return:18.0 Mean reward:10.026315789473685  i:190, n batches:1 \n",
            " Episode return:52.0  Episode return:35.0 Mean reward:23.080459770114942  i:191, n batches:1 \n",
            " Episode return:12.0  Episode return:17.0 Mean reward:7.9655172413793105  i:192, n batches:1 \n",
            " Episode return:25.0  Episode return:40.0 Mean reward:17.615384615384617  i:193, n batches:1 \n",
            " Episode return:21.0  Episode return:28.0 Mean reward:13.0  i:194, n batches:1 \n",
            " Episode return:27.0  Episode return:20.0 Mean reward:12.51063829787234  i:195, n batches:1 \n",
            " Episode return:30.0  Episode return:12.0 Mean reward:12.928571428571429  i:196, n batches:1 \n",
            " Episode return:23.0  Episode return:23.0 Mean reward:12.0  i:197, n batches:1 \n",
            " Episode return:11.0  Episode return:11.0 Mean reward:6.0  i:198, n batches:1 \n",
            " Episode return:30.0  Episode return:14.0 Mean reward:12.954545454545455  i:199, n batches:1 \n",
            " Episode return:31.0  Episode return:40.0 Mean reward:18.535211267605632  i:200, n batches:1 \n",
            "loss:-0.005985256750136614\n",
            " Episode return:15.0  Episode return:39.0 Mean reward:16.666666666666668  i:201, n batches:1 \n",
            " Episode return:51.0  Episode return:31.0 Mean reward:22.21951219512195  i:202, n batches:1 \n",
            " Episode return:22.0  Episode return:36.0 Mean reward:15.844827586206897  i:203, n batches:1 \n",
            " Episode return:14.0  Episode return:26.0 Mean reward:11.4  i:204, n batches:1 \n",
            " Episode return:19.0  Episode return:27.0 Mean reward:12.347826086956522  i:205, n batches:1 \n",
            " Episode return:33.0  Episode return:12.0 Mean reward:14.2  i:206, n batches:1 \n",
            " Episode return:32.0  Episode return:30.0 Mean reward:16.016129032258064  i:207, n batches:1 \n",
            " Episode return:24.0  Episode return:40.0 Mean reward:17.5  i:208, n batches:1 \n",
            " Episode return:35.0  Episode return:22.0 Mean reward:15.491228070175438  i:209, n batches:1 \n",
            " Episode return:23.0  Episode return:32.0 Mean reward:14.618181818181819  i:210, n batches:1 \n",
            " Episode return:20.0  Episode return:32.0 Mean reward:14.192307692307692  i:211, n batches:1 \n",
            " Episode return:20.0  Episode return:20.0 Mean reward:10.5  i:212, n batches:1 \n",
            " Episode return:11.0  Episode return:16.0 Mean reward:7.481481481481482  i:213, n batches:1 \n",
            " Episode return:16.0  Episode return:20.0 Mean reward:9.61111111111111  i:214, n batches:1 \n",
            " Episode return:21.0  Episode return:23.0 Mean reward:11.522727272727273  i:215, n batches:1 \n",
            " Episode return:14.0  Episode return:63.0 Mean reward:27.545454545454547  i:216, n batches:1 \n",
            " Episode return:17.0  Episode return:10.0 Mean reward:7.703703703703703  i:217, n batches:1 \n",
            " Episode return:16.0  Episode return:25.0 Mean reward:11.24390243902439  i:218, n batches:1 \n",
            " Episode return:55.0  Episode return:18.0 Mean reward:23.438356164383563  i:219, n batches:1 \n",
            " Episode return:34.0  Episode return:56.0 Mean reward:24.344444444444445  i:220, n batches:1 \n",
            " Episode return:21.0  Episode return:31.0 Mean reward:13.98076923076923  i:221, n batches:1 \n",
            " Episode return:18.0  Episode return:56.0 Mean reward:23.87837837837838  i:222, n batches:1 \n",
            " Episode return:20.0  Episode return:11.0 Mean reward:8.903225806451612  i:223, n batches:1 \n",
            " Episode return:10.0  Episode return:56.0 Mean reward:25.015151515151516  i:224, n batches:1 \n",
            " Episode return:19.0  Episode return:14.0 Mean reward:8.93939393939394  i:225, n batches:1 \n",
            " Episode return:24.0  Episode return:32.0 Mean reward:14.785714285714286  i:226, n batches:1 \n",
            " Episode return:10.0  Episode return:17.0 Mean reward:7.703703703703703  i:227, n batches:1 \n",
            " Episode return:19.0  Episode return:29.0 Mean reward:13.020833333333334  i:228, n batches:1 \n",
            " Episode return:32.0  Episode return:12.0 Mean reward:13.772727272727273  i:229, n batches:1 \n",
            " Episode return:19.0  Episode return:32.0 Mean reward:14.07843137254902  i:230, n batches:1 \n",
            " Episode return:33.0  Episode return:40.0 Mean reward:18.91780821917808  i:231, n batches:1 \n",
            " Episode return:54.0  Episode return:40.0 Mean reward:24.52127659574468  i:232, n batches:1 \n",
            " Episode return:15.0  Episode return:25.0 Mean reward:11.125  i:233, n batches:1 \n",
            " Episode return:38.0  Episode return:13.0 Mean reward:16.313725490196077  i:234, n batches:1 \n",
            " Episode return:51.0  Episode return:48.0 Mean reward:25.272727272727273  i:235, n batches:1 \n",
            " Episode return:12.0  Episode return:46.0 Mean reward:19.982758620689655  i:236, n batches:1 \n",
            " Episode return:20.0  Episode return:28.0 Mean reward:12.833333333333334  i:237, n batches:1 \n",
            " Episode return:34.0  Episode return:10.0 Mean reward:14.772727272727273  i:238, n batches:1 \n",
            " Episode return:15.0  Episode return:15.0 Mean reward:8.0  i:239, n batches:1 \n",
            " Episode return:48.0  Episode return:14.0 Mean reward:20.661290322580644  i:240, n batches:1 \n",
            " Episode return:17.0  Episode return:13.0 Mean reward:8.133333333333333  i:241, n batches:1 \n",
            " Episode return:23.0  Episode return:14.0 Mean reward:10.297297297297296  i:242, n batches:1 \n",
            " Episode return:16.0  Episode return:19.0 Mean reward:9.314285714285715  i:243, n batches:1 \n",
            " Episode return:18.0  Episode return:21.0 Mean reward:10.307692307692308  i:244, n batches:1 \n",
            " Episode return:54.0  Episode return:25.0 Mean reward:22.911392405063292  i:245, n batches:1 \n",
            " Episode return:16.0  Episode return:12.0 Mean reward:7.642857142857143  i:246, n batches:1 \n",
            " Episode return:24.0  Episode return:17.0 Mean reward:11.048780487804878  i:247, n batches:1 \n",
            " Episode return:27.0  Episode return:46.0 Mean reward:19.986301369863014  i:248, n batches:1 \n",
            " Episode return:14.0  Episode return:15.0 Mean reward:7.758620689655173  i:249, n batches:1 \n",
            " Episode return:20.0  Episode return:34.0 Mean reward:14.907407407407407  i:250, n batches:1 \n",
            " Episode return:29.0  Episode return:50.0 Mean reward:21.645569620253166  i:251, n batches:1 \n",
            " Episode return:24.0  Episode return:27.0 Mean reward:13.294117647058824  i:252, n batches:1 \n",
            " Episode return:23.0  Episode return:45.0 Mean reward:19.279411764705884  i:253, n batches:1 \n",
            " Episode return:38.0  Episode return:10.0 Mean reward:16.583333333333332  i:254, n batches:1 \n",
            " Episode return:22.0  Episode return:42.0 Mean reward:18.0625  i:255, n batches:1 \n",
            " Episode return:30.0  Episode return:14.0 Mean reward:12.954545454545455  i:256, n batches:1 \n",
            " Episode return:53.0  Episode return:28.0 Mean reward:22.679012345679013  i:257, n batches:1 \n",
            " Episode return:36.0  Episode return:18.0 Mean reward:15.5  i:258, n batches:1 \n",
            " Episode return:41.0  Episode return:74.0 Mean reward:31.617391304347827  i:259, n batches:1 \n",
            " Episode return:10.0  Episode return:31.0 Mean reward:13.439024390243903  i:260, n batches:1 \n",
            " Episode return:16.0  Episode return:17.0 Mean reward:8.757575757575758  i:261, n batches:1 \n",
            " Episode return:18.0  Episode return:18.0 Mean reward:9.5  i:262, n batches:1 \n",
            " Episode return:25.0  Episode return:22.0 Mean reward:12.297872340425531  i:263, n batches:1 \n",
            " Episode return:11.0  Episode return:14.0 Mean reward:6.84  i:264, n batches:1 \n",
            " Episode return:24.0  Episode return:23.0 Mean reward:12.25531914893617  i:265, n batches:1 \n",
            " Episode return:31.0  Episode return:19.0 Mean reward:13.72  i:266, n batches:1 \n",
            " Episode return:38.0  Episode return:21.0 Mean reward:16.47457627118644  i:267, n batches:1 \n",
            " Episode return:17.0  Episode return:21.0 Mean reward:10.105263157894736  i:268, n batches:1 \n",
            " Episode return:21.0  Episode return:22.0 Mean reward:11.255813953488373  i:269, n batches:1 \n",
            " Episode return:31.0  Episode return:14.0 Mean reward:13.355555555555556  i:270, n batches:1 \n",
            " Episode return:20.0  Episode return:45.0 Mean reward:19.153846153846153  i:271, n batches:1 \n",
            " Episode return:19.0  Episode return:12.0 Mean reward:8.64516129032258  i:272, n batches:1 \n",
            " Episode return:24.0  Episode return:14.0 Mean reward:10.657894736842104  i:273, n batches:1 \n",
            " Episode return:24.0  Episode return:13.0 Mean reward:10.567567567567568  i:274, n batches:1 \n",
            " Episode return:28.0  Episode return:45.0 Mean reward:19.73972602739726  i:275, n batches:1 \n",
            " Episode return:13.0  Episode return:19.0 Mean reward:8.78125  i:276, n batches:1 \n",
            " Episode return:14.0  Episode return:49.0 Mean reward:21.11111111111111  i:277, n batches:1 \n",
            " Episode return:12.0  Episode return:11.0 Mean reward:6.260869565217392  i:278, n batches:1 \n",
            " Episode return:19.0  Episode return:8.0 Mean reward:8.37037037037037  i:279, n batches:1 \n",
            " Episode return:15.0  Episode return:36.0 Mean reward:15.411764705882353  i:280, n batches:1 \n",
            " Episode return:20.0  Episode return:55.0 Mean reward:23.333333333333332  i:281, n batches:1 \n",
            " Episode return:15.0  Episode return:20.0 Mean reward:9.428571428571429  i:282, n batches:1 \n",
            " Episode return:12.0  Episode return:20.0 Mean reward:9.0  i:283, n batches:1 \n",
            " Episode return:36.0  Episode return:14.0 Mean reward:15.42  i:284, n batches:1 \n",
            " Episode return:21.0  Episode return:40.0 Mean reward:17.229508196721312  i:285, n batches:1 \n",
            " Episode return:36.0  Episode return:26.0 Mean reward:16.403225806451612  i:286, n batches:1 \n",
            " Episode return:25.0  Episode return:17.0 Mean reward:11.380952380952381  i:287, n batches:1 \n",
            " Episode return:15.0  Episode return:44.0 Mean reward:18.8135593220339  i:288, n batches:1 \n",
            " Episode return:23.0  Episode return:32.0 Mean reward:14.618181818181819  i:289, n batches:1 \n",
            " Episode return:26.0  Episode return:49.0 Mean reward:21.013333333333332  i:290, n batches:1 \n",
            " Episode return:78.0  Episode return:45.0 Mean reward:33.46341463414634  i:291, n batches:1 \n",
            " Episode return:32.0  Episode return:20.0 Mean reward:14.192307692307692  i:292, n batches:1 \n",
            " Episode return:29.0  Episode return:24.0 Mean reward:13.867924528301886  i:293, n batches:1 \n",
            " Episode return:38.0  Episode return:58.0 Mean reward:25.541666666666668  i:294, n batches:1 \n",
            " Episode return:33.0  Episode return:20.0 Mean reward:14.547169811320755  i:295, n batches:1 \n",
            " Episode return:13.0  Episode return:13.0 Mean reward:7.0  i:296, n batches:1 \n",
            " Episode return:14.0  Episode return:25.0 Mean reward:11.025641025641026  i:297, n batches:1 \n",
            " Episode return:21.0  Episode return:45.0 Mean reward:19.181818181818183  i:298, n batches:1 \n",
            " Episode return:43.0  Episode return:16.0 Mean reward:18.338983050847457  i:299, n batches:1 \n",
            " Episode return:18.0  Episode return:24.0 Mean reward:11.214285714285714  i:300, n batches:1 \n",
            "loss:0.006411148235201836\n",
            " Episode return:26.0  Episode return:24.0 Mean reward:13.02  i:301, n batches:1 \n",
            " Episode return:14.0  Episode return:21.0 Mean reward:9.6  i:302, n batches:1 \n",
            " Episode return:24.0  Episode return:56.0 Mean reward:23.7  i:303, n batches:1 \n",
            " Episode return:37.0  Episode return:27.0 Mean reward:16.890625  i:304, n batches:1 \n",
            " Episode return:49.0  Episode return:16.0 Mean reward:20.93846153846154  i:305, n batches:1 \n",
            " Episode return:55.0  Episode return:11.0 Mean reward:24.333333333333332  i:306, n batches:1 \n",
            " Episode return:21.0  Episode return:43.0 Mean reward:18.390625  i:307, n batches:1 \n",
            " Episode return:77.0  Episode return:19.0 Mean reward:33.260416666666664  i:308, n batches:1 \n",
            " Episode return:35.0  Episode return:40.0 Mean reward:19.333333333333332  i:309, n batches:1 \n",
            " Episode return:17.0  Episode return:17.0 Mean reward:9.0  i:310, n batches:1 \n",
            " Episode return:24.0  Episode return:12.0 Mean reward:10.5  i:311, n batches:1 \n",
            " Episode return:54.0  Episode return:19.0 Mean reward:22.945205479452056  i:312, n batches:1 \n",
            " Episode return:17.0  Episode return:25.0 Mean reward:11.380952380952381  i:313, n batches:1 \n",
            " Episode return:28.0  Episode return:14.0 Mean reward:12.166666666666666  i:314, n batches:1 \n",
            " Episode return:29.0  Episode return:17.0 Mean reward:12.782608695652174  i:315, n batches:1 \n",
            " Episode return:56.0  Episode return:29.0 Mean reward:23.894117647058824  i:316, n batches:1 \n",
            " Episode return:52.0  Episode return:12.0 Mean reward:22.75  i:317, n batches:1 \n",
            " Episode return:60.0  Episode return:22.0 Mean reward:25.402439024390244  i:318, n batches:1 \n",
            " Episode return:49.0  Episode return:14.0 Mean reward:21.11111111111111  i:319, n batches:1 \n",
            " Episode return:30.0  Episode return:66.0 Mean reward:27.875  i:320, n batches:1 \n",
            " Episode return:14.0  Episode return:19.0 Mean reward:8.93939393939394  i:321, n batches:1 \n",
            " Episode return:14.0  Episode return:19.0 Mean reward:8.93939393939394  i:322, n batches:1 \n",
            " Episode return:33.0  Episode return:39.0 Mean reward:18.625  i:323, n batches:1 \n",
            " Episode return:24.0  Episode return:55.0 Mean reward:23.29113924050633  i:324, n batches:1 \n",
            " Episode return:22.0  Episode return:28.0 Mean reward:13.18  i:325, n batches:1 \n",
            " Episode return:20.0  Episode return:17.0 Mean reward:9.81081081081081  i:326, n batches:1 \n",
            " Episode return:23.0  Episode return:16.0 Mean reward:10.564102564102564  i:327, n batches:1 \n",
            " Episode return:19.0  Episode return:34.0 Mean reward:14.81132075471698  i:328, n batches:1 \n",
            " Episode return:11.0  Episode return:22.0 Mean reward:9.666666666666666  i:329, n batches:1 \n",
            " Episode return:17.0  Episode return:19.0 Mean reward:9.527777777777779  i:330, n batches:1 \n",
            " Episode return:33.0  Episode return:52.0 Mean reward:22.811764705882354  i:331, n batches:1 \n",
            " Episode return:22.0  Episode return:24.0 Mean reward:12.021739130434783  i:332, n batches:1 \n",
            " Episode return:33.0  Episode return:16.0 Mean reward:14.224489795918368  i:333, n batches:1 \n",
            " Episode return:50.0  Episode return:15.0 Mean reward:21.46153846153846  i:334, n batches:1 \n",
            " Episode return:18.0  Episode return:29.0 Mean reward:12.893617021276595  i:335, n batches:1 \n",
            " Episode return:9.0  Episode return:13.0 Mean reward:6.181818181818182  i:336, n batches:1 \n",
            " Episode return:28.0  Episode return:15.0 Mean reward:12.232558139534884  i:337, n batches:1 \n",
            " Episode return:27.0  Episode return:42.0 Mean reward:18.565217391304348  i:338, n batches:1 \n",
            " Episode return:20.0  Episode return:43.0 Mean reward:18.349206349206348  i:339, n batches:1 \n",
            " Episode return:24.0  Episode return:52.0 Mean reward:22.07894736842105  i:340, n batches:1 \n",
            " Episode return:24.0  Episode return:87.0 Mean reward:37.189189189189186  i:341, n batches:1 \n",
            " Episode return:26.0  Episode return:31.0 Mean reward:14.859649122807017  i:342, n batches:1 \n",
            " Episode return:23.0  Episode return:62.0 Mean reward:26.223529411764705  i:343, n batches:1 \n",
            " Episode return:32.0  Episode return:29.0 Mean reward:15.78688524590164  i:344, n batches:1 \n",
            " Episode return:28.0  Episode return:68.0 Mean reward:28.666666666666668  i:345, n batches:1 \n",
            " Episode return:23.0  Episode return:18.0 Mean reward:10.902439024390244  i:346, n batches:1 \n",
            " Episode return:42.0  Episode return:58.0 Mean reward:26.14  i:347, n batches:1 \n",
            " Episode return:32.0  Episode return:20.0 Mean reward:14.192307692307692  i:348, n batches:1 \n",
            " Episode return:52.0  Episode return:10.0 Mean reward:23.112903225806452  i:349, n batches:1 \n",
            " Episode return:11.0  Episode return:29.0 Mean reward:12.525  i:350, n batches:1 \n",
            " Episode return:30.0  Episode return:27.0 Mean reward:14.789473684210526  i:351, n batches:1 \n",
            " Episode return:28.0  Episode return:47.0 Mean reward:20.453333333333333  i:352, n batches:1 \n",
            " Episode return:24.0  Episode return:15.0 Mean reward:10.76923076923077  i:353, n batches:1 \n",
            " Episode return:45.0  Episode return:12.0 Mean reward:19.526315789473685  i:354, n batches:1 \n",
            " Episode return:16.0  Episode return:59.0 Mean reward:25.413333333333334  i:355, n batches:1 \n",
            " Episode return:23.0  Episode return:23.0 Mean reward:12.0  i:356, n batches:1 \n",
            " Episode return:14.0  Episode return:15.0 Mean reward:7.758620689655173  i:357, n batches:1 \n",
            " Episode return:12.0  Episode return:21.0 Mean reward:9.363636363636363  i:358, n batches:1 \n",
            " Episode return:17.0  Episode return:53.0 Mean reward:22.62857142857143  i:359, n batches:1 \n",
            " Episode return:38.0  Episode return:56.0 Mean reward:24.861702127659573  i:360, n batches:1 \n",
            " Episode return:52.0  Episode return:18.0 Mean reward:22.12857142857143  i:361, n batches:1 \n",
            " Episode return:28.0  Episode return:14.0 Mean reward:12.166666666666666  i:362, n batches:1 \n",
            " Episode return:18.0  Episode return:34.0 Mean reward:14.73076923076923  i:363, n batches:1 \n",
            " Episode return:20.0  Episode return:33.0 Mean reward:14.547169811320755  i:364, n batches:1 \n",
            " Episode return:17.0  Episode return:30.0 Mean reward:13.148936170212766  i:365, n batches:1 \n",
            " Episode return:17.0  Episode return:11.0 Mean reward:7.821428571428571  i:366, n batches:1 \n",
            " Episode return:36.0  Episode return:29.0 Mean reward:16.93846153846154  i:367, n batches:1 \n",
            " Episode return:16.0  Episode return:40.0 Mean reward:17.071428571428573  i:368, n batches:1 \n",
            " Episode return:37.0  Episode return:11.0 Mean reward:16.020833333333332  i:369, n batches:1 \n",
            " Episode return:22.0  Episode return:63.0 Mean reward:26.694117647058825  i:370, n batches:1 \n",
            " Episode return:34.0  Episode return:16.0 Mean reward:14.62  i:371, n batches:1 \n",
            " Episode return:43.0  Episode return:28.0 Mean reward:19.04225352112676  i:372, n batches:1 \n",
            " Episode return:20.0  Episode return:15.0 Mean reward:9.428571428571429  i:373, n batches:1 \n",
            " Episode return:22.0  Episode return:13.0 Mean reward:9.82857142857143  i:374, n batches:1 \n",
            " Episode return:21.0  Episode return:50.0 Mean reward:21.211267605633804  i:375, n batches:1 \n",
            " Episode return:23.0  Episode return:25.0 Mean reward:12.520833333333334  i:376, n batches:1 \n",
            " Episode return:14.0  Episode return:47.0 Mean reward:20.21311475409836  i:377, n batches:1 \n",
            " Episode return:22.0  Episode return:43.0 Mean reward:18.446153846153845  i:378, n batches:1 \n",
            " Episode return:20.0  Episode return:31.0 Mean reward:13.843137254901961  i:379, n batches:1 \n",
            " Episode return:54.0  Episode return:13.0 Mean reward:23.52238805970149  i:380, n batches:1 \n",
            " Episode return:100.0  Episode return:34.0 Mean reward:42.12686567164179  i:381, n batches:2 \n",
            " Episode return:35.0  Episode return:20.0 Mean reward:15.272727272727273  i:382, n batches:1 \n",
            " Episode return:20.0  Episode return:20.0 Mean reward:10.5  i:383, n batches:1 \n",
            " Episode return:36.0  Episode return:70.0 Mean reward:29.72641509433962  i:384, n batches:1 \n",
            " Episode return:49.0  Episode return:12.0 Mean reward:21.360655737704917  i:385, n batches:1 \n",
            " Episode return:14.0  Episode return:38.0 Mean reward:16.26923076923077  i:386, n batches:1 \n",
            " Episode return:26.0  Episode return:32.0 Mean reward:15.155172413793103  i:387, n batches:1 \n",
            " Episode return:18.0  Episode return:24.0 Mean reward:11.214285714285714  i:388, n batches:1 \n",
            " Episode return:22.0  Episode return:79.0 Mean reward:33.79207920792079  i:389, n batches:1 \n",
            " Episode return:21.0  Episode return:14.0 Mean reward:9.6  i:390, n batches:1 \n",
            " Episode return:36.0  Episode return:48.0 Mean reward:21.928571428571427  i:391, n batches:1 \n",
            " Episode return:13.0  Episode return:21.0 Mean reward:9.470588235294118  i:392, n batches:1 \n",
            " Episode return:35.0  Episode return:75.0 Mean reward:31.636363636363637  i:393, n batches:1 \n",
            " Episode return:52.0  Episode return:10.0 Mean reward:23.112903225806452  i:394, n batches:1 \n",
            " Episode return:29.0  Episode return:39.0 Mean reward:17.86764705882353  i:395, n batches:1 \n",
            " Episode return:20.0  Episode return:16.0 Mean reward:9.61111111111111  i:396, n batches:1 \n",
            " Episode return:16.0  Episode return:52.0 Mean reward:22.264705882352942  i:397, n batches:1 \n",
            " Episode return:21.0  Episode return:46.0 Mean reward:19.582089552238806  i:398, n batches:1 \n",
            " Episode return:24.0  Episode return:13.0 Mean reward:10.567567567567568  i:399, n batches:1 \n",
            " Episode return:46.0  Episode return:31.0 Mean reward:20.48051948051948  i:400, n batches:1 \n",
            "loss:-0.028485340997576714\n",
            " Episode return:43.0  Episode return:11.0 Mean reward:18.74074074074074  i:401, n batches:1 \n",
            " Episode return:23.0  Episode return:44.0 Mean reward:18.895522388059703  i:402, n batches:1 \n",
            " Episode return:37.0  Episode return:17.0 Mean reward:15.851851851851851  i:403, n batches:1 \n",
            " Episode return:24.0  Episode return:21.0 Mean reward:11.8  i:404, n batches:1 \n",
            " Episode return:12.0  Episode return:22.0 Mean reward:9.735294117647058  i:405, n batches:1 \n",
            " Episode return:19.0  Episode return:37.0 Mean reward:15.946428571428571  i:406, n batches:1 \n",
            " Episode return:14.0  Episode return:23.0 Mean reward:10.297297297297296  i:407, n batches:1 \n",
            " Episode return:50.0  Episode return:17.0 Mean reward:21.313432835820894  i:408, n batches:1 \n",
            " Episode return:14.0  Episode return:78.0 Mean reward:34.630434782608695  i:409, n batches:1 \n",
            " Episode return:23.0  Episode return:45.0 Mean reward:19.279411764705884  i:410, n batches:1 \n",
            " Episode return:45.0  Episode return:21.0 Mean reward:19.181818181818183  i:411, n batches:1 \n",
            " Episode return:25.0  Episode return:19.0 Mean reward:11.704545454545455  i:412, n batches:1 \n",
            " Episode return:37.0  Episode return:16.0 Mean reward:15.830188679245284  i:413, n batches:1 \n",
            " Episode return:79.0  Episode return:17.0 Mean reward:34.510416666666664  i:414, n batches:1 \n",
            " Episode return:53.0  Episode return:28.0 Mean reward:22.679012345679013  i:415, n batches:1 \n",
            " Episode return:31.0  Episode return:21.0 Mean reward:13.98076923076923  i:416, n batches:1 \n",
            " Episode return:32.0  Episode return:35.0 Mean reward:17.28358208955224  i:417, n batches:1 \n",
            " Episode return:41.0  Episode return:20.0 Mean reward:17.557377049180328  i:418, n batches:1 \n",
            " Episode return:25.0  Episode return:15.0 Mean reward:11.125  i:419, n batches:1 \n",
            " Episode return:36.0  Episode return:14.0 Mean reward:15.42  i:420, n batches:1 \n",
            " Episode return:11.0  Episode return:30.0 Mean reward:12.951219512195122  i:421, n batches:1 \n",
            " Episode return:70.0  Episode return:17.0 Mean reward:30.32183908045977  i:422, n batches:1 \n",
            " Episode return:85.0  Episode return:16.0 Mean reward:37.53465346534654  i:423, n batches:1 \n",
            " Episode return:20.0  Episode return:33.0 Mean reward:14.547169811320755  i:424, n batches:1 \n",
            " Episode return:17.0  Episode return:20.0 Mean reward:9.81081081081081  i:425, n batches:1 \n",
            " Episode return:20.0  Episode return:40.0 Mean reward:17.166666666666668  i:426, n batches:1 \n",
            " Episode return:12.0  Episode return:50.0 Mean reward:21.822580645161292  i:427, n batches:1 \n",
            " Episode return:28.0  Episode return:26.0 Mean reward:14.018518518518519  i:428, n batches:1 \n",
            " Episode return:10.0  Episode return:39.0 Mean reward:17.040816326530614  i:429, n batches:1 \n",
            " Episode return:15.0  Episode return:48.0 Mean reward:20.571428571428573  i:430, n batches:1 \n",
            " Episode return:19.0  Episode return:35.0 Mean reward:15.185185185185185  i:431, n batches:1 \n",
            " Episode return:49.0  Episode return:16.0 Mean reward:20.93846153846154  i:432, n batches:1 \n",
            " Episode return:12.0  Episode return:49.0 Mean reward:21.360655737704917  i:433, n batches:1 \n",
            " Episode return:16.0  Episode return:10.0 Mean reward:7.346153846153846  i:434, n batches:1 \n",
            " Episode return:88.0  Episode return:53.0 Mean reward:37.92198581560284  i:435, n batches:2 \n",
            " Episode return:16.0  Episode return:44.0 Mean reward:18.766666666666666  i:436, n batches:1 \n",
            " Episode return:33.0  Episode return:48.0 Mean reward:21.444444444444443  i:437, n batches:1 \n",
            " Episode return:24.0  Episode return:25.0 Mean reward:12.755102040816327  i:438, n batches:1 \n",
            " Episode return:14.0  Episode return:13.0 Mean reward:7.2592592592592595  i:439, n batches:1 \n",
            " Episode return:45.0  Episode return:26.0 Mean reward:19.52112676056338  i:440, n batches:1 \n",
            " Episode return:33.0  Episode return:30.0 Mean reward:16.285714285714285  i:441, n batches:1 \n",
            " Episode return:13.0  Episode return:51.0 Mean reward:22.140625  i:442, n batches:1 \n",
            " Episode return:38.0  Episode return:25.0 Mean reward:16.92063492063492  i:443, n batches:1 \n",
            " Episode return:54.0  Episode return:25.0 Mean reward:22.911392405063292  i:444, n batches:1 \n",
            " Episode return:33.0  Episode return:16.0 Mean reward:14.224489795918368  i:445, n batches:1 \n",
            " Episode return:67.0  Episode return:27.0 Mean reward:28.25531914893617  i:446, n batches:1 \n",
            " Episode return:13.0  Episode return:39.0 Mean reward:16.75  i:447, n batches:1 \n",
            " Episode return:12.0  Episode return:14.0 Mean reward:7.038461538461538  i:448, n batches:1 \n",
            " Episode return:47.0  Episode return:28.0 Mean reward:20.453333333333333  i:449, n batches:1 \n",
            " Episode return:34.0  Episode return:32.0 Mean reward:17.015151515151516  i:450, n batches:1 \n",
            " Episode return:17.0  Episode return:48.0 Mean reward:20.446153846153845  i:451, n batches:1 \n",
            " Episode return:16.0  Episode return:31.0 Mean reward:13.446808510638299  i:452, n batches:1 \n",
            " Episode return:26.0  Episode return:36.0 Mean reward:16.403225806451612  i:453, n batches:1 \n",
            " Episode return:10.0  Episode return:19.0 Mean reward:8.448275862068966  i:454, n batches:1 \n",
            " Episode return:30.0  Episode return:25.0 Mean reward:14.363636363636363  i:455, n batches:1 \n",
            " Episode return:26.0  Episode return:9.0 Mean reward:11.314285714285715  i:456, n batches:1 \n",
            " Episode return:14.0  Episode return:35.0 Mean reward:15.0  i:457, n batches:1 \n",
            " Episode return:68.0  Episode return:31.0 Mean reward:28.707070707070706  i:458, n batches:1 \n",
            " Episode return:62.0  Episode return:25.0 Mean reward:26.183908045977013  i:459, n batches:1 \n",
            " Episode return:23.0  Episode return:35.0 Mean reward:15.620689655172415  i:460, n batches:1 \n",
            " Episode return:31.0  Episode return:16.0 Mean reward:13.446808510638299  i:461, n batches:1 \n",
            " Episode return:16.0  Episode return:37.0 Mean reward:15.830188679245284  i:462, n batches:1 \n",
            " Episode return:18.0  Episode return:61.0 Mean reward:26.10126582278481  i:463, n batches:1 \n",
            " Episode return:38.0  Episode return:20.0 Mean reward:16.396551724137932  i:464, n batches:1 \n",
            " Episode return:34.0  Episode return:16.0 Mean reward:14.62  i:465, n batches:1 \n",
            " Episode return:25.0  Episode return:31.0 Mean reward:14.660714285714286  i:466, n batches:1 \n",
            " Episode return:71.0  Episode return:45.0 Mean reward:30.95689655172414  i:467, n batches:1 \n",
            " Episode return:34.0  Episode return:11.0 Mean reward:14.688888888888888  i:468, n batches:1 \n",
            " Episode return:15.0  Episode return:46.0 Mean reward:19.688524590163933  i:469, n batches:1 \n",
            " Episode return:23.0  Episode return:46.0 Mean reward:19.666666666666668  i:470, n batches:1 \n",
            " Episode return:29.0  Episode return:29.0 Mean reward:15.0  i:471, n batches:1 \n",
            " Episode return:22.0  Episode return:44.0 Mean reward:18.833333333333332  i:472, n batches:1 \n",
            " Episode return:14.0  Episode return:50.0 Mean reward:21.5625  i:473, n batches:1 \n",
            " Episode return:16.0  Episode return:11.0 Mean reward:7.481481481481482  i:474, n batches:1 \n",
            " Episode return:52.0  Episode return:62.0 Mean reward:29.219298245614034  i:475, n batches:1 \n",
            " Episode return:40.0  Episode return:41.0 Mean reward:20.753086419753085  i:476, n batches:1 \n",
            " Episode return:36.0  Episode return:24.0 Mean reward:16.1  i:477, n batches:1 \n",
            " Episode return:30.0  Episode return:61.0 Mean reward:25.89010989010989  i:478, n batches:1 \n",
            " Episode return:29.0  Episode return:17.0 Mean reward:12.782608695652174  i:479, n batches:1 \n",
            " Episode return:79.0  Episode return:41.0 Mean reward:33.50833333333333  i:480, n batches:1 \n",
            " Episode return:18.0  Episode return:25.0 Mean reward:11.534883720930232  i:481, n batches:1 \n",
            " Episode return:15.0  Episode return:31.0 Mean reward:13.391304347826088  i:482, n batches:1 \n",
            " Episode return:22.0  Episode return:49.0 Mean reward:20.816901408450704  i:483, n batches:1 \n",
            " Episode return:42.0  Episode return:11.0 Mean reward:18.28301886792453  i:484, n batches:1 \n",
            " Episode return:14.0  Episode return:25.0 Mean reward:11.025641025641026  i:485, n batches:1 \n",
            " Episode return:83.0  Episode return:32.0 Mean reward:34.904347826086955  i:486, n batches:1 \n",
            " Episode return:10.0  Episode return:20.0 Mean reward:8.833333333333334  i:487, n batches:1 \n",
            " Episode return:62.0  Episode return:47.0 Mean reward:28.26605504587156  i:488, n batches:1 \n",
            " Episode return:19.0  Episode return:56.0 Mean reward:23.813333333333333  i:489, n batches:1 \n",
            " Episode return:21.0  Episode return:26.0 Mean reward:12.382978723404255  i:490, n batches:1 \n",
            " Episode return:24.0  Episode return:59.0 Mean reward:24.93975903614458  i:491, n batches:1 \n",
            " Episode return:44.0  Episode return:23.0 Mean reward:18.895522388059703  i:492, n batches:1 \n",
            " Episode return:34.0  Episode return:27.0 Mean reward:15.950819672131148  i:493, n batches:1 \n",
            " Episode return:18.0  Episode return:53.0 Mean reward:22.56338028169014  i:494, n batches:1 \n",
            " Episode return:47.0  Episode return:94.0 Mean reward:39.666666666666664  i:495, n batches:2 \n",
            " Episode return:72.0  Episode return:37.0 Mean reward:30.559633027522935  i:496, n batches:1 \n",
            " Episode return:29.0  Episode return:18.0 Mean reward:12.893617021276595  i:497, n batches:1 \n",
            " Episode return:26.0  Episode return:34.0 Mean reward:15.766666666666667  i:498, n batches:1 \n",
            " Episode return:13.0  Episode return:12.0 Mean reward:6.76  i:499, n batches:1 \n",
            " Episode return:45.0  Episode return:8.0 Mean reward:20.20754716981132  i:500, n batches:1 \n",
            "loss:-0.02970513328909874\n",
            " Episode return:10.0  Episode return:40.0 Mean reward:17.5  i:501, n batches:1 \n",
            " Episode return:46.0  Episode return:64.0 Mean reward:28.736363636363638  i:502, n batches:1 \n",
            " Episode return:13.0  Episode return:26.0 Mean reward:11.333333333333334  i:503, n batches:1 \n",
            " Episode return:38.0  Episode return:80.0 Mean reward:33.73728813559322  i:504, n batches:1 \n",
            " Episode return:22.0  Episode return:50.0 Mean reward:21.22222222222222  i:505, n batches:1 \n",
            " Episode return:19.0  Episode return:11.0 Mean reward:8.533333333333333  i:506, n batches:1 \n",
            " Episode return:79.0  Episode return:27.0 Mean reward:33.37735849056604  i:507, n batches:1 \n",
            " Episode return:32.0  Episode return:20.0 Mean reward:14.192307692307692  i:508, n batches:1 \n",
            " Episode return:15.0  Episode return:68.0 Mean reward:29.710843373493976  i:509, n batches:1 \n",
            " Episode return:21.0  Episode return:83.0 Mean reward:35.74038461538461  i:510, n batches:1 \n",
            " Episode return:14.0  Episode return:17.0 Mean reward:8.32258064516129  i:511, n batches:1 \n",
            " Episode return:40.0  Episode return:24.0 Mean reward:17.5  i:512, n batches:1 \n",
            " Episode return:37.0  Episode return:12.0 Mean reward:15.938775510204081  i:513, n batches:1 \n",
            " Episode return:19.0  Episode return:18.0 Mean reward:9.756756756756756  i:514, n batches:1 \n",
            " Episode return:30.0  Episode return:18.0 Mean reward:13.25  i:515, n batches:1 \n",
            " Episode return:30.0  Episode return:15.0 Mean reward:13.0  i:516, n batches:1 \n",
            " Episode return:49.0  Episode return:37.0 Mean reward:22.41860465116279  i:517, n batches:1 \n",
            " Episode return:53.0  Episode return:16.0 Mean reward:22.71014492753623  i:518, n batches:1 \n",
            " Episode return:18.0  Episode return:20.0 Mean reward:10.026315789473685  i:519, n batches:1 \n",
            " Episode return:32.0  Episode return:19.0 Mean reward:14.07843137254902  i:520, n batches:1 \n",
            " Episode return:80.0  Episode return:26.0 Mean reward:33.87735849056604  i:521, n batches:1 \n",
            " Episode return:64.0  Episode return:16.0 Mean reward:27.7  i:522, n batches:1 \n",
            " Episode return:50.0  Episode return:39.0 Mean reward:23.089887640449437  i:523, n batches:1 \n",
            " Episode return:26.0  Episode return:21.0 Mean reward:12.382978723404255  i:524, n batches:1 \n",
            " Episode return:21.0  Episode return:29.0 Mean reward:13.32  i:525, n batches:1 \n",
            " Episode return:12.0  Episode return:18.0 Mean reward:8.3  i:526, n batches:1 \n",
            " Episode return:28.0  Episode return:15.0 Mean reward:12.232558139534884  i:527, n batches:1 \n",
            " Episode return:61.0  Episode return:30.0 Mean reward:25.89010989010989  i:528, n batches:1 \n",
            " Episode return:36.0  Episode return:24.0 Mean reward:16.1  i:529, n batches:1 \n",
            " Episode return:81.0  Episode return:16.0 Mean reward:35.63917525773196  i:530, n batches:1 \n",
            " Episode return:14.0  Episode return:16.0 Mean reward:8.033333333333333  i:531, n batches:1 \n",
            " Episode return:24.0  Episode return:49.0 Mean reward:20.89041095890411  i:532, n batches:1 \n",
            " Episode return:31.0  Episode return:12.0 Mean reward:13.348837209302326  i:533, n batches:1 \n",
            " Episode return:35.0  Episode return:9.0 Mean reward:15.340909090909092  i:534, n batches:1 \n",
            " Episode return:77.0  Episode return:43.0 Mean reward:32.90833333333333  i:535, n batches:1 \n",
            " Episode return:63.0  Episode return:38.0 Mean reward:27.297029702970296  i:536, n batches:1 \n",
            " Episode return:16.0  Episode return:50.0 Mean reward:21.37878787878788  i:537, n batches:1 \n",
            " Episode return:23.0  Episode return:24.0 Mean reward:12.25531914893617  i:538, n batches:1 \n",
            " Episode return:48.0  Episode return:9.0 Mean reward:21.42105263157895  i:539, n batches:1 \n",
            " Episode return:16.0  Episode return:81.0 Mean reward:35.63917525773196  i:540, n batches:1 \n",
            " Episode return:30.0  Episode return:46.0 Mean reward:20.342105263157894  i:541, n batches:1 \n",
            " Episode return:14.0  Episode return:14.0 Mean reward:7.5  i:542, n batches:1 \n",
            " Episode return:23.0  Episode return:15.0 Mean reward:10.421052631578947  i:543, n batches:1 \n",
            " Episode return:17.0  Episode return:31.0 Mean reward:13.520833333333334  i:544, n batches:1 \n",
            " Episode return:14.0  Episode return:27.0 Mean reward:11.78048780487805  i:545, n batches:1 \n",
            " Episode return:49.0  Episode return:15.0 Mean reward:21.015625  i:546, n batches:1 \n",
            " Episode return:71.0  Episode return:36.0 Mean reward:30.11214953271028  i:547, n batches:1 \n",
            " Episode return:36.0  Episode return:16.0 Mean reward:15.423076923076923  i:548, n batches:1 \n",
            " Episode return:20.0  Episode return:43.0 Mean reward:18.349206349206348  i:549, n batches:1 \n",
            " Episode return:66.0  Episode return:36.0 Mean reward:28.205882352941178  i:550, n batches:1 \n",
            " Episode return:17.0  Episode return:45.0 Mean reward:19.161290322580644  i:551, n batches:1 \n",
            " Episode return:13.0  Episode return:10.0 Mean reward:6.3478260869565215  i:552, n batches:1 \n",
            " Episode return:48.0  Episode return:50.0 Mean reward:25.010204081632654  i:553, n batches:1 \n",
            " Episode return:19.0  Episode return:16.0 Mean reward:9.314285714285715  i:554, n batches:1 \n",
            " Episode return:47.0  Episode return:35.0 Mean reward:21.4390243902439  i:555, n batches:1 \n",
            " Episode return:27.0  Episode return:18.0 Mean reward:12.2  i:556, n batches:1 \n",
            " Episode return:16.0  Episode return:27.0 Mean reward:11.953488372093023  i:557, n batches:1 \n",
            " Episode return:16.0  Episode return:12.0 Mean reward:7.642857142857143  i:558, n batches:1 \n",
            " Episode return:12.0  Episode return:23.0 Mean reward:10.114285714285714  i:559, n batches:1 \n",
            " Episode return:38.0  Episode return:43.0 Mean reward:20.82716049382716  i:560, n batches:1 \n",
            " Episode return:63.0  Episode return:21.0 Mean reward:26.75  i:561, n batches:1 \n",
            " Episode return:26.0  Episode return:16.0 Mean reward:11.595238095238095  i:562, n batches:1 \n",
            " Episode return:14.0  Episode return:15.0 Mean reward:7.758620689655173  i:563, n batches:1 \n",
            " Episode return:70.0  Episode return:58.0 Mean reward:32.78125  i:564, n batches:1 \n",
            " Episode return:21.0  Episode return:33.0 Mean reward:14.666666666666666  i:565, n batches:1 \n",
            " Episode return:195.0  Episode return:13.0 Mean reward:92.3125  i:566, n batches:2 \n",
            " Episode return:24.0  Episode return:19.0 Mean reward:11.395348837209303  i:567, n batches:1 \n",
            " Episode return:24.0  Episode return:24.0 Mean reward:12.5  i:568, n batches:1 \n",
            " Episode return:27.0  Episode return:17.0 Mean reward:12.068181818181818  i:569, n batches:1 \n",
            " Episode return:50.0  Episode return:15.0 Mean reward:21.46153846153846  i:570, n batches:1 \n",
            " Episode return:37.0  Episode return:31.0 Mean reward:17.63235294117647  i:571, n batches:1 \n",
            " Episode return:23.0  Episode return:22.0 Mean reward:11.755555555555556  i:572, n batches:1 \n",
            " Episode return:49.0  Episode return:31.0 Mean reward:21.5125  i:573, n batches:1 \n",
            " Episode return:26.0  Episode return:33.0 Mean reward:15.457627118644067  i:574, n batches:1 \n",
            " Episode return:81.0  Episode return:37.0 Mean reward:34.101694915254235  i:575, n batches:1 \n",
            " Episode return:34.0  Episode return:50.0 Mean reward:22.261904761904763  i:576, n batches:1 \n",
            " Episode return:20.0  Episode return:16.0 Mean reward:9.61111111111111  i:577, n batches:1 \n",
            " Episode return:9.0  Episode return:24.0 Mean reward:10.454545454545455  i:578, n batches:1 \n",
            " Episode return:21.0  Episode return:42.0 Mean reward:18.0  i:579, n batches:1 \n",
            " Episode return:26.0  Episode return:15.0 Mean reward:11.487804878048781  i:580, n batches:1 \n",
            " Episode return:35.0  Episode return:103.0 Mean reward:43.3768115942029  i:581, n batches:2 \n",
            " Episode return:98.0  Episode return:23.0 Mean reward:42.37190082644628  i:582, n batches:1 \n",
            " Episode return:13.0  Episode return:21.0 Mean reward:9.470588235294118  i:583, n batches:1 \n",
            " Episode return:34.0  Episode return:63.0 Mean reward:26.917525773195877  i:584, n batches:1 \n",
            " Episode return:12.0  Episode return:39.0 Mean reward:16.823529411764707  i:585, n batches:1 \n",
            " Episode return:62.0  Episode return:19.0 Mean reward:26.45679012345679  i:586, n batches:1 \n",
            " Episode return:103.0  Episode return:60.0 Mean reward:44.08588957055215  i:587, n batches:2 \n",
            " Episode return:18.0  Episode return:11.0 Mean reward:8.172413793103448  i:588, n batches:1 \n",
            " Episode return:25.0  Episode return:46.0 Mean reward:19.802816901408452  i:589, n batches:1 \n",
            " Episode return:46.0  Episode return:75.0 Mean reward:32.48760330578512  i:590, n batches:1 \n",
            " Episode return:68.0  Episode return:70.0 Mean reward:35.007246376811594  i:591, n batches:2 \n",
            " Episode return:50.0  Episode return:19.0 Mean reward:21.231884057971016  i:592, n batches:1 \n",
            " Episode return:19.0  Episode return:35.0 Mean reward:15.185185185185185  i:593, n batches:1 \n",
            " Episode return:67.0  Episode return:34.0 Mean reward:28.445544554455445  i:594, n batches:1 \n",
            " Episode return:30.0  Episode return:33.0 Mean reward:16.285714285714285  i:595, n batches:1 \n",
            " Episode return:19.0  Episode return:19.0 Mean reward:10.0  i:596, n batches:1 \n",
            " Episode return:18.0  Episode return:28.0 Mean reward:12.543478260869565  i:597, n batches:1 \n",
            " Episode return:41.0  Episode return:11.0 Mean reward:17.826923076923077  i:598, n batches:1 \n",
            " Episode return:74.0  Episode return:73.0 Mean reward:37.25170068027211  i:599, n batches:2 \n",
            " Episode return:20.0  Episode return:31.0 Mean reward:13.843137254901961  i:600, n batches:1 \n",
            "loss:-0.009650269523262978\n",
            " Episode return:29.0  Episode return:89.0 Mean reward:37.6271186440678  i:601, n batches:1 \n",
            " Episode return:12.0  Episode return:19.0 Mean reward:8.64516129032258  i:602, n batches:1 \n",
            " Episode return:69.0  Episode return:13.0 Mean reward:30.5609756097561  i:603, n batches:1 \n",
            " Episode return:17.0  Episode return:17.0 Mean reward:9.0  i:604, n batches:1 \n",
            " Episode return:51.0  Episode return:41.0 Mean reward:23.77173913043478  i:605, n batches:1 \n",
            " Episode return:21.0  Episode return:43.0 Mean reward:18.390625  i:606, n batches:1 \n",
            " Episode return:10.0  Episode return:46.0 Mean reward:20.285714285714285  i:607, n batches:1 \n",
            " Episode return:35.0  Episode return:135.0 Mean reward:57.705882352941174  i:608, n batches:2 \n",
            " Episode return:41.0  Episode return:41.0 Mean reward:21.0  i:609, n batches:1 \n",
            " Episode return:57.0  Episode return:29.0 Mean reward:24.27906976744186  i:610, n batches:1 \n",
            " Episode return:39.0  Episode return:33.0 Mean reward:18.625  i:611, n batches:1 \n",
            " Episode return:32.0  Episode return:9.0 Mean reward:13.975609756097562  i:612, n batches:1 \n",
            " Episode return:25.0  Episode return:22.0 Mean reward:12.297872340425531  i:613, n batches:1 \n",
            " Episode return:31.0  Episode return:35.0 Mean reward:17.060606060606062  i:614, n batches:1 \n",
            " Episode return:13.0  Episode return:101.0 Mean reward:45.98245614035088  i:615, n batches:1 \n",
            " Episode return:24.0  Episode return:25.0 Mean reward:12.755102040816327  i:616, n batches:1 \n",
            " Episode return:46.0  Episode return:111.0 Mean reward:46.47770700636943  i:617, n batches:2 \n",
            " Episode return:78.0  Episode return:28.0 Mean reward:32.89622641509434  i:618, n batches:1 \n",
            " Episode return:77.0  Episode return:14.0 Mean reward:34.15384615384615  i:619, n batches:1 \n",
            " Episode return:52.0  Episode return:25.0 Mean reward:22.116883116883116  i:620, n batches:1 \n",
            " Episode return:12.0  Episode return:44.0 Mean reward:19.071428571428573  i:621, n batches:1 \n",
            " Episode return:19.0  Episode return:19.0 Mean reward:10.0  i:622, n batches:1 \n",
            " Episode return:30.0  Episode return:25.0 Mean reward:14.363636363636363  i:623, n batches:1 \n",
            " Episode return:29.0  Episode return:59.0 Mean reward:25.056818181818183  i:624, n batches:1 \n",
            " Episode return:16.0  Episode return:27.0 Mean reward:11.953488372093023  i:625, n batches:1 \n",
            " Episode return:51.0  Episode return:70.0 Mean reward:31.49586776859504  i:626, n batches:1 \n",
            " Episode return:31.0  Episode return:21.0 Mean reward:13.98076923076923  i:627, n batches:1 \n",
            " Episode return:16.0  Episode return:28.0 Mean reward:12.318181818181818  i:628, n batches:1 \n",
            " Episode return:33.0  Episode return:30.0 Mean reward:16.285714285714285  i:629, n batches:1 \n",
            " Episode return:80.0  Episode return:21.0 Mean reward:34.366336633663366  i:630, n batches:1 \n",
            " Episode return:25.0  Episode return:17.0 Mean reward:11.380952380952381  i:631, n batches:1 \n",
            " Episode return:28.0  Episode return:12.0 Mean reward:12.1  i:632, n batches:1 \n",
            " Episode return:17.0  Episode return:52.0 Mean reward:22.18840579710145  i:633, n batches:1 \n",
            " Episode return:75.0  Episode return:32.0 Mean reward:31.570093457943926  i:634, n batches:1 \n",
            " Episode return:10.0  Episode return:59.0 Mean reward:26.44927536231884  i:635, n batches:1 \n",
            " Episode return:29.0  Episode return:9.0 Mean reward:12.631578947368421  i:636, n batches:1 \n",
            " Episode return:21.0  Episode return:22.0 Mean reward:11.255813953488373  i:637, n batches:1 \n",
            " Episode return:41.0  Episode return:46.0 Mean reward:22.32183908045977  i:638, n batches:1 \n",
            " Episode return:43.0  Episode return:21.0 Mean reward:18.390625  i:639, n batches:1 \n",
            " Episode return:26.0  Episode return:48.0 Mean reward:20.635135135135137  i:640, n batches:1 \n",
            " Episode return:42.0  Episode return:19.0 Mean reward:17.918032786885245  i:641, n batches:1 \n",
            " Episode return:61.0  Episode return:66.0 Mean reward:32.2992125984252  i:642, n batches:1 \n",
            " Episode return:18.0  Episode return:26.0 Mean reward:11.863636363636363  i:643, n batches:1 \n",
            " Episode return:21.0  Episode return:28.0 Mean reward:13.0  i:644, n batches:1 \n",
            " Episode return:10.0  Episode return:12.0 Mean reward:6.045454545454546  i:645, n batches:1 \n",
            " Episode return:31.0  Episode return:25.0 Mean reward:14.660714285714286  i:646, n batches:1 \n",
            " Episode return:46.0  Episode return:20.0 Mean reward:19.560606060606062  i:647, n batches:1 \n",
            " Episode return:16.0  Episode return:24.0 Mean reward:10.9  i:648, n batches:1 \n",
            " Episode return:31.0  Episode return:16.0 Mean reward:13.446808510638299  i:649, n batches:1 \n",
            " Episode return:11.0  Episode return:27.0 Mean reward:11.68421052631579  i:650, n batches:1 \n",
            " Episode return:47.0  Episode return:40.0 Mean reward:22.39080459770115  i:651, n batches:1 \n",
            " Episode return:21.0  Episode return:43.0 Mean reward:18.390625  i:652, n batches:1 \n",
            " Episode return:94.0  Episode return:20.0 Mean reward:41.00877192982456  i:653, n batches:1 \n",
            " Episode return:15.0  Episode return:69.0 Mean reward:30.178571428571427  i:654, n batches:1 \n",
            " Episode return:27.0  Episode return:22.0 Mean reward:12.877551020408163  i:655, n batches:1 \n",
            " Episode return:47.0  Episode return:35.0 Mean reward:21.4390243902439  i:656, n batches:1 \n",
            " Episode return:13.0  Episode return:27.0 Mean reward:11.725  i:657, n batches:1 \n",
            " Episode return:24.0  Episode return:32.0 Mean reward:14.785714285714286  i:658, n batches:1 \n",
            " Episode return:19.0  Episode return:33.0 Mean reward:14.442307692307692  i:659, n batches:1 \n",
            " Episode return:29.0  Episode return:9.0 Mean reward:12.631578947368421  i:660, n batches:1 \n",
            " Episode return:62.0  Episode return:41.0 Mean reward:27.320388349514563  i:661, n batches:1 \n",
            " Episode return:39.0  Episode return:10.0 Mean reward:17.040816326530614  i:662, n batches:1 \n",
            " Episode return:30.0  Episode return:18.0 Mean reward:13.25  i:663, n batches:1 \n",
            " Episode return:38.0  Episode return:17.0 Mean reward:16.254545454545454  i:664, n batches:1 \n",
            " Episode return:14.0  Episode return:38.0 Mean reward:16.26923076923077  i:665, n batches:1 \n",
            " Episode return:42.0  Episode return:14.0 Mean reward:18.0  i:666, n batches:1 \n",
            " Episode return:33.0  Episode return:12.0 Mean reward:14.2  i:667, n batches:1 \n",
            " Episode return:57.0  Episode return:24.0 Mean reward:24.11111111111111  i:668, n batches:1 \n",
            " Episode return:26.0  Episode return:169.0 Mean reward:75.46666666666667  i:669, n batches:2 \n",
            " Episode return:42.0  Episode return:52.0 Mean reward:24.26595744680851  i:670, n batches:1 \n",
            " Episode return:18.0  Episode return:19.0 Mean reward:9.756756756756756  i:671, n batches:1 \n",
            " Episode return:8.0  Episode return:30.0 Mean reward:13.18421052631579  i:672, n batches:1 \n",
            " Episode return:17.0  Episode return:20.0 Mean reward:9.81081081081081  i:673, n batches:1 \n",
            " Episode return:39.0  Episode return:42.0 Mean reward:20.77777777777778  i:674, n batches:1 \n",
            " Episode return:37.0  Episode return:50.0 Mean reward:22.735632183908045  i:675, n batches:1 \n",
            " Episode return:14.0  Episode return:55.0 Mean reward:23.840579710144926  i:676, n batches:1 \n",
            " Episode return:30.0  Episode return:25.0 Mean reward:14.363636363636363  i:677, n batches:1 \n",
            " Episode return:28.0  Episode return:48.0 Mean reward:20.81578947368421  i:678, n batches:1 \n",
            " Episode return:26.0  Episode return:34.0 Mean reward:15.766666666666667  i:679, n batches:1 \n",
            " Episode return:51.0  Episode return:54.0 Mean reward:26.771428571428572  i:680, n batches:1 \n",
            " Episode return:15.0  Episode return:17.0 Mean reward:8.53125  i:681, n batches:1 \n",
            " Episode return:104.0  Episode return:34.0 Mean reward:43.8768115942029  i:682, n batches:2 \n",
            " Episode return:46.0  Episode return:25.0 Mean reward:19.802816901408452  i:683, n batches:1 \n",
            " Episode return:43.0  Episode return:53.0 Mean reward:24.760416666666668  i:684, n batches:1 \n",
            " Episode return:17.0  Episode return:49.0 Mean reward:20.87878787878788  i:685, n batches:1 \n",
            " Episode return:41.0  Episode return:18.0 Mean reward:17.491525423728813  i:686, n batches:1 \n",
            " Episode return:32.0  Episode return:13.0 Mean reward:13.755555555555556  i:687, n batches:1 \n",
            " Episode return:10.0  Episode return:60.0 Mean reward:26.928571428571427  i:688, n batches:1 \n",
            " Episode return:20.0  Episode return:162.0 Mean reward:73.6978021978022  i:689, n batches:2 \n",
            " Episode return:77.0  Episode return:42.0 Mean reward:32.8235294117647  i:690, n batches:1 \n",
            " Episode return:18.0  Episode return:34.0 Mean reward:14.73076923076923  i:691, n batches:1 \n",
            " Episode return:18.0  Episode return:19.0 Mean reward:9.756756756756756  i:692, n batches:1 \n",
            " Episode return:13.0  Episode return:18.0 Mean reward:8.451612903225806  i:693, n batches:1 \n",
            " Episode return:26.0  Episode return:59.0 Mean reward:24.95294117647059  i:694, n batches:1 \n",
            " Episode return:67.0  Episode return:22.0 Mean reward:28.43820224719101  i:695, n batches:1 \n",
            " Episode return:44.0  Episode return:39.0 Mean reward:21.325301204819276  i:696, n batches:1 \n",
            " Episode return:38.0  Episode return:43.0 Mean reward:20.82716049382716  i:697, n batches:1 \n",
            " Episode return:17.0  Episode return:62.0 Mean reward:26.658227848101266  i:698, n batches:1 \n",
            " Episode return:61.0  Episode return:63.0 Mean reward:31.508064516129032  i:699, n batches:1 \n",
            " Episode return:15.0  Episode return:30.0 Mean reward:13.0  i:700, n batches:1 \n",
            "loss:-0.03890746086835861\n",
            " Episode return:28.0  Episode return:12.0 Mean reward:12.1  i:701, n batches:1 \n",
            " Episode return:91.0  Episode return:34.0 Mean reward:38.248  i:702, n batches:1 \n",
            " Episode return:16.0  Episode return:69.0 Mean reward:30.011764705882353  i:703, n batches:1 \n",
            " Episode return:56.0  Episode return:48.0 Mean reward:26.653846153846153  i:704, n batches:1 \n",
            " Episode return:21.0  Episode return:29.0 Mean reward:13.32  i:705, n batches:1 \n",
            " Episode return:34.0  Episode return:49.0 Mean reward:21.927710843373493  i:706, n batches:1 \n",
            " Episode return:97.0  Episode return:20.0 Mean reward:42.41880341880342  i:707, n batches:1 \n",
            " Episode return:19.0  Episode return:64.0 Mean reward:27.349397590361445  i:708, n batches:1 \n",
            " Episode return:54.0  Episode return:30.0 Mean reward:23.214285714285715  i:709, n batches:1 \n",
            " Episode return:18.0  Episode return:12.0 Mean reward:8.3  i:710, n batches:1 \n",
            " Episode return:31.0  Episode return:76.0 Mean reward:31.981308411214954  i:711, n batches:1 \n",
            " Episode return:21.0  Episode return:33.0 Mean reward:14.666666666666666  i:712, n batches:1 \n",
            " Episode return:28.0  Episode return:31.0 Mean reward:15.288135593220339  i:713, n batches:1 \n",
            " Episode return:38.0  Episode return:35.0 Mean reward:18.78082191780822  i:714, n batches:1 \n",
            " Episode return:38.0  Episode return:51.0 Mean reward:23.224719101123597  i:715, n batches:1 \n",
            " Episode return:80.0  Episode return:13.0 Mean reward:35.81720430107527  i:716, n batches:1 \n",
            " Episode return:32.0  Episode return:24.0 Mean reward:14.785714285714286  i:717, n batches:1 \n",
            " Episode return:33.0  Episode return:32.0 Mean reward:16.753846153846155  i:718, n batches:1 \n",
            " Episode return:35.0  Episode return:52.0 Mean reward:23.080459770114942  i:719, n batches:1 \n",
            " Episode return:9.0  Episode return:37.0 Mean reward:16.26086956521739  i:720, n batches:1 \n",
            " Episode return:27.0  Episode return:28.0 Mean reward:14.254545454545454  i:721, n batches:1 \n",
            " Episode return:37.0  Episode return:61.0 Mean reward:26.46938775510204  i:722, n batches:1 \n",
            " Episode return:46.0  Episode return:32.0 Mean reward:20.628205128205128  i:723, n batches:1 \n",
            " Episode return:50.0  Episode return:45.0 Mean reward:24.31578947368421  i:724, n batches:1 \n",
            " Episode return:47.0  Episode return:12.0 Mean reward:20.440677966101696  i:725, n batches:1 \n",
            " Episode return:10.0  Episode return:64.0 Mean reward:28.85135135135135  i:726, n batches:1 \n",
            " Episode return:36.0  Episode return:38.0 Mean reward:19.013513513513512  i:727, n batches:1 \n",
            " Episode return:16.0  Episode return:43.0 Mean reward:18.338983050847457  i:728, n batches:1 \n",
            " Episode return:45.0  Episode return:34.0 Mean reward:20.632911392405063  i:729, n batches:1 \n",
            " Episode return:31.0  Episode return:70.0 Mean reward:29.514851485148515  i:730, n batches:1 \n",
            " Episode return:36.0  Episode return:13.0 Mean reward:15.448979591836734  i:731, n batches:1 \n",
            " Episode return:53.0  Episode return:10.0 Mean reward:23.58730158730159  i:732, n batches:1 \n",
            " Episode return:67.0  Episode return:27.0 Mean reward:28.25531914893617  i:733, n batches:1 \n",
            " Episode return:45.0  Episode return:55.0 Mean reward:25.75  i:734, n batches:1 \n",
            " Episode return:25.0  Episode return:53.0 Mean reward:22.512820512820515  i:735, n batches:1 \n",
            " Episode return:11.0  Episode return:85.0 Mean reward:38.760416666666664  i:736, n batches:1 \n",
            " Episode return:21.0  Episode return:50.0 Mean reward:21.211267605633804  i:737, n batches:1 \n",
            " Episode return:67.0  Episode return:31.0 Mean reward:28.306122448979593  i:738, n batches:1 \n",
            " Episode return:17.0  Episode return:25.0 Mean reward:11.380952380952381  i:739, n batches:1 \n",
            " Episode return:16.0  Episode return:16.0 Mean reward:8.5  i:740, n batches:1 \n",
            " Episode return:19.0  Episode return:52.0 Mean reward:22.08450704225352  i:741, n batches:1 \n",
            " Episode return:29.0  Episode return:26.0 Mean reward:14.290909090909091  i:742, n batches:1 \n",
            " Episode return:68.0  Episode return:27.0 Mean reward:28.673684210526314  i:743, n batches:1 \n",
            " Episode return:39.0  Episode return:78.0 Mean reward:33.0  i:744, n batches:1 \n",
            " Episode return:115.0  Episode return:10.0 Mean reward:53.8  i:745, n batches:1 \n",
            " Episode return:16.0  Episode return:36.0 Mean reward:15.423076923076923  i:746, n batches:1 \n",
            " Episode return:30.0  Episode return:62.0 Mean reward:26.282608695652176  i:747, n batches:1 \n",
            " Episode return:47.0  Episode return:47.0 Mean reward:24.0  i:748, n batches:1 \n",
            " Episode return:32.0  Episode return:39.0 Mean reward:18.422535211267604  i:749, n batches:1 \n",
            " Episode return:27.0  Episode return:22.0 Mean reward:12.877551020408163  i:750, n batches:1 \n",
            " Episode return:41.0  Episode return:14.0 Mean reward:17.563636363636363  i:751, n batches:1 \n",
            " Episode return:16.0  Episode return:55.0 Mean reward:23.6056338028169  i:752, n batches:1 \n",
            " Episode return:21.0  Episode return:22.0 Mean reward:11.255813953488373  i:753, n batches:1 \n",
            " Episode return:28.0  Episode return:56.0 Mean reward:23.833333333333332  i:754, n batches:1 \n",
            " Episode return:47.0  Episode return:19.0 Mean reward:19.96969696969697  i:755, n batches:1 \n",
            " Episode return:25.0  Episode return:36.0 Mean reward:16.24590163934426  i:756, n batches:1 \n",
            " Episode return:29.0  Episode return:31.0 Mean reward:15.516666666666667  i:757, n batches:1 \n",
            " Episode return:46.0  Episode return:58.0 Mean reward:26.846153846153847  i:758, n batches:1 \n",
            " Episode return:95.0  Episode return:54.0 Mean reward:40.57046979865772  i:759, n batches:2 \n",
            " Episode return:17.0  Episode return:14.0 Mean reward:8.32258064516129  i:760, n batches:1 \n",
            " Episode return:39.0  Episode return:46.0 Mean reward:21.894117647058824  i:761, n batches:1 \n",
            " Episode return:23.0  Episode return:16.0 Mean reward:10.564102564102564  i:762, n batches:1 \n",
            " Episode return:26.0  Episode return:20.0 Mean reward:12.195652173913043  i:763, n batches:1 \n",
            " Episode return:38.0  Episode return:102.0 Mean reward:42.81428571428572  i:764, n batches:2 \n",
            " Episode return:52.0  Episode return:22.0 Mean reward:22.04054054054054  i:765, n batches:1 \n",
            " Episode return:46.0  Episode return:19.0 Mean reward:19.553846153846155  i:766, n batches:1 \n",
            " Episode return:24.0  Episode return:86.0 Mean reward:36.736363636363635  i:767, n batches:1 \n",
            " Episode return:63.0  Episode return:34.0 Mean reward:26.917525773195877  i:768, n batches:1 \n",
            " Episode return:27.0  Episode return:90.0 Mean reward:38.23076923076923  i:769, n batches:1 \n",
            " Episode return:44.0  Episode return:88.0 Mean reward:37.166666666666664  i:770, n batches:2 \n",
            " Episode return:20.0  Episode return:48.0 Mean reward:20.38235294117647  i:771, n batches:1 \n",
            " Episode return:68.0  Episode return:20.0 Mean reward:29.045454545454547  i:772, n batches:1 \n",
            " Episode return:45.0  Episode return:44.0 Mean reward:22.752808988764045  i:773, n batches:1 \n",
            " Episode return:13.0  Episode return:66.0 Mean reward:29.139240506329113  i:774, n batches:1 \n",
            " Episode return:32.0  Episode return:18.0 Mean reward:13.98  i:775, n batches:1 \n",
            " Episode return:12.0  Episode return:17.0 Mean reward:7.9655172413793105  i:776, n batches:1 \n",
            " Episode return:49.0  Episode return:14.0 Mean reward:21.11111111111111  i:777, n batches:1 \n",
            " Episode return:18.0  Episode return:19.0 Mean reward:9.756756756756756  i:778, n batches:1 \n",
            " Episode return:24.0  Episode return:12.0 Mean reward:10.5  i:779, n batches:1 \n",
            " Episode return:29.0  Episode return:47.0 Mean reward:20.56578947368421  i:780, n batches:1 \n",
            " Episode return:39.0  Episode return:47.0 Mean reward:22.186046511627907  i:781, n batches:1 \n",
            " Episode return:39.0  Episode return:20.0 Mean reward:16.779661016949152  i:782, n batches:1 \n",
            " Episode return:84.0  Episode return:45.0 Mean reward:35.69767441860465  i:783, n batches:2 \n",
            " Episode return:23.0  Episode return:26.0 Mean reward:12.795918367346939  i:784, n batches:1 \n",
            " Episode return:87.0  Episode return:146.0 Mean reward:62.48497854077253  i:785, n batches:2 \n",
            " Episode return:68.0  Episode return:59.0 Mean reward:32.40944881889764  i:786, n batches:1 \n",
            " Episode return:23.0  Episode return:25.0 Mean reward:12.520833333333334  i:787, n batches:1 \n",
            " Episode return:27.0  Episode return:33.0 Mean reward:15.65  i:788, n batches:1 \n",
            " Episode return:44.0  Episode return:28.0 Mean reward:19.38888888888889  i:789, n batches:1 \n",
            " Episode return:57.0  Episode return:31.0 Mean reward:24.420454545454547  i:790, n batches:1 \n",
            " Episode return:50.0  Episode return:31.0 Mean reward:21.864197530864196  i:791, n batches:1 \n",
            " Episode return:101.0  Episode return:26.0 Mean reward:43.32283464566929  i:792, n batches:1 \n",
            " Episode return:56.0  Episode return:19.0 Mean reward:23.813333333333333  i:793, n batches:1 \n",
            " Episode return:15.0  Episode return:67.0 Mean reward:29.24390243902439  i:794, n batches:1 \n",
            " Episode return:31.0  Episode return:46.0 Mean reward:20.48051948051948  i:795, n batches:1 \n",
            " Episode return:23.0  Episode return:53.0 Mean reward:22.460526315789473  i:796, n batches:1 \n",
            " Episode return:101.0  Episode return:40.0 Mean reward:42.347517730496456  i:797, n batches:2 \n",
            " Episode return:63.0  Episode return:62.0 Mean reward:31.752  i:798, n batches:1 \n",
            " Episode return:14.0  Episode return:59.0 Mean reward:25.684931506849313  i:799, n batches:1 \n",
            " Episode return:20.0  Episode return:35.0 Mean reward:15.272727272727273  i:800, n batches:1 \n",
            "loss:-0.014469129033386707\n",
            " Episode return:63.0  Episode return:61.0 Mean reward:31.508064516129032  i:801, n batches:1 \n",
            " Episode return:36.0  Episode return:29.0 Mean reward:16.93846153846154  i:802, n batches:1 \n",
            " Episode return:76.0  Episode return:16.0 Mean reward:33.28260869565217  i:803, n batches:1 \n",
            " Episode return:24.0  Episode return:9.0 Mean reward:10.454545454545455  i:804, n batches:1 \n",
            " Episode return:21.0  Episode return:46.0 Mean reward:19.582089552238806  i:805, n batches:1 \n",
            " Episode return:30.0  Episode return:67.0 Mean reward:28.278350515463917  i:806, n batches:1 \n",
            " Episode return:36.0  Episode return:27.0 Mean reward:16.571428571428573  i:807, n batches:1 \n",
            " Episode return:14.0  Episode return:43.0 Mean reward:18.43859649122807  i:808, n batches:1 \n",
            " Episode return:19.0  Episode return:78.0 Mean reward:33.72164948453608  i:809, n batches:1 \n",
            " Episode return:36.0  Episode return:38.0 Mean reward:19.013513513513512  i:810, n batches:1 \n",
            " Episode return:65.0  Episode return:19.0 Mean reward:27.797619047619047  i:811, n batches:1 \n",
            " Episode return:67.0  Episode return:29.0 Mean reward:28.260416666666668  i:812, n batches:1 \n",
            " Episode return:31.0  Episode return:18.0 Mean reward:13.612244897959183  i:813, n batches:1 \n",
            " Episode return:53.0  Episode return:46.0 Mean reward:25.373737373737374  i:814, n batches:1 \n",
            " Episode return:39.0  Episode return:40.0 Mean reward:20.253164556962027  i:815, n batches:1 \n",
            " Episode return:44.0  Episode return:22.0 Mean reward:18.833333333333332  i:816, n batches:1 \n",
            " Episode return:47.0  Episode return:62.0 Mean reward:28.26605504587156  i:817, n batches:1 \n",
            " Episode return:39.0  Episode return:36.0 Mean reward:19.28  i:818, n batches:1 \n",
            " Episode return:41.0  Episode return:13.0 Mean reward:17.62962962962963  i:819, n batches:1 \n",
            " Episode return:19.0  Episode return:16.0 Mean reward:9.314285714285715  i:820, n batches:1 \n",
            " Episode return:29.0  Episode return:49.0 Mean reward:21.28205128205128  i:821, n batches:1 \n",
            " Episode return:98.0  Episode return:103.0 Mean reward:50.78109452736319  i:822, n batches:2 \n",
            " Episode return:9.0  Episode return:36.0 Mean reward:15.8  i:823, n batches:1 \n",
            " Episode return:20.0  Episode return:62.0 Mean reward:26.378048780487806  i:824, n batches:1 \n",
            " Episode return:55.0  Episode return:111.0 Mean reward:46.72289156626506  i:825, n batches:2 \n",
            " Episode return:30.0  Episode return:62.0 Mean reward:26.282608695652176  i:826, n batches:1 \n",
            " Episode return:38.0  Episode return:19.0 Mean reward:16.333333333333332  i:827, n batches:1 \n",
            " Episode return:53.0  Episode return:25.0 Mean reward:22.512820512820515  i:828, n batches:1 \n",
            " Episode return:26.0  Episode return:32.0 Mean reward:15.155172413793103  i:829, n batches:1 \n",
            " Episode return:23.0  Episode return:16.0 Mean reward:10.564102564102564  i:830, n batches:1 \n",
            " Episode return:44.0  Episode return:15.0 Mean reward:18.8135593220339  i:831, n batches:1 \n",
            " Episode return:68.0  Episode return:59.0 Mean reward:32.40944881889764  i:832, n batches:1 \n",
            " Episode return:70.0  Episode return:25.0 Mean reward:29.57894736842105  i:833, n batches:1 \n",
            " Episode return:45.0  Episode return:30.0 Mean reward:20.0  i:834, n batches:1 \n",
            " Episode return:85.0  Episode return:53.0 Mean reward:36.85507246376812  i:835, n batches:2 \n",
            " Episode return:61.0  Episode return:44.0 Mean reward:27.438095238095237  i:836, n batches:1 \n",
            " Episode return:26.0  Episode return:18.0 Mean reward:11.863636363636363  i:837, n batches:1 \n",
            " Episode return:21.0  Episode return:58.0 Mean reward:24.582278481012658  i:838, n batches:1 \n",
            " Episode return:101.0  Episode return:19.0 Mean reward:44.50833333333333  i:839, n batches:1 \n",
            " Episode return:27.0  Episode return:65.0 Mean reward:27.42391304347826  i:840, n batches:1 \n",
            " Episode return:53.0  Episode return:39.0 Mean reward:24.032608695652176  i:841, n batches:1 \n",
            " Episode return:28.0  Episode return:14.0 Mean reward:12.166666666666666  i:842, n batches:1 \n",
            " Episode return:61.0  Episode return:13.0 Mean reward:26.783783783783782  i:843, n batches:1 \n",
            " Episode return:15.0  Episode return:10.0 Mean reward:7.0  i:844, n batches:1 \n",
            " Episode return:23.0  Episode return:33.0 Mean reward:14.946428571428571  i:845, n batches:1 \n",
            " Episode return:29.0  Episode return:35.0 Mean reward:16.640625  i:846, n batches:1 \n",
            " Episode return:61.0  Episode return:28.0 Mean reward:25.808988764044944  i:847, n batches:1 \n",
            " Episode return:61.0  Episode return:126.0 Mean reward:52.898395721925134  i:848, n batches:2 \n",
            " Episode return:26.0  Episode return:31.0 Mean reward:14.859649122807017  i:849, n batches:1 \n",
            " Episode return:54.0  Episode return:21.0 Mean reward:22.88  i:850, n batches:1 \n",
            " Episode return:59.0  Episode return:16.0 Mean reward:25.413333333333334  i:851, n batches:1 \n",
            " Episode return:55.0  Episode return:35.0 Mean reward:24.11111111111111  i:852, n batches:1 \n",
            " Episode return:34.0  Episode return:13.0 Mean reward:14.595744680851064  i:853, n batches:1 \n",
            " Episode return:69.0  Episode return:49.0 Mean reward:30.847457627118644  i:854, n batches:1 \n",
            " Episode return:41.0  Episode return:12.0 Mean reward:17.71698113207547  i:855, n batches:1 \n",
            " Episode return:73.0  Episode return:44.0 Mean reward:31.54700854700855  i:856, n batches:1 \n",
            " Episode return:44.0  Episode return:41.0 Mean reward:21.776470588235295  i:857, n batches:1 \n",
            " Episode return:29.0  Episode return:31.0 Mean reward:15.516666666666667  i:858, n batches:1 \n",
            " Episode return:79.0  Episode return:67.0 Mean reward:37.24657534246575  i:859, n batches:2 \n",
            " Episode return:151.0  Episode return:17.0 Mean reward:69.2202380952381  i:860, n batches:2 \n",
            " Episode return:64.0  Episode return:38.0 Mean reward:27.65686274509804  i:861, n batches:1 \n",
            " Episode return:50.0  Episode return:72.0 Mean reward:31.991803278688526  i:862, n batches:1 \n",
            " Episode return:120.0  Episode return:70.0 Mean reward:51.28947368421053  i:863, n batches:2 \n",
            " Episode return:52.0  Episode return:18.0 Mean reward:22.12857142857143  i:864, n batches:1 \n",
            " Episode return:32.0  Episode return:48.0 Mean reward:21.3  i:865, n batches:1 \n",
            " Episode return:52.0  Episode return:22.0 Mean reward:22.04054054054054  i:866, n batches:1 \n",
            " Episode return:20.0  Episode return:24.0 Mean reward:11.590909090909092  i:867, n batches:1 \n",
            " Episode return:50.0  Episode return:32.0 Mean reward:21.98780487804878  i:868, n batches:1 \n",
            " Episode return:19.0  Episode return:30.0 Mean reward:13.36734693877551  i:869, n batches:1 \n",
            " Episode return:23.0  Episode return:39.0 Mean reward:17.032258064516128  i:870, n batches:1 \n",
            " Episode return:34.0  Episode return:46.0 Mean reward:20.95  i:871, n batches:1 \n",
            " Episode return:13.0  Episode return:98.0 Mean reward:44.52252252252252  i:872, n batches:1 \n",
            " Episode return:16.0  Episode return:45.0 Mean reward:19.19672131147541  i:873, n batches:1 \n",
            " Episode return:33.0  Episode return:81.0 Mean reward:34.05263157894737  i:874, n batches:1 \n",
            " Episode return:64.0  Episode return:77.0 Mean reward:36.04964539007092  i:875, n batches:2 \n",
            " Episode return:68.0  Episode return:35.0 Mean reward:28.893203883495147  i:876, n batches:1 \n",
            " Episode return:50.0  Episode return:48.0 Mean reward:25.010204081632654  i:877, n batches:1 \n",
            " Episode return:17.0  Episode return:57.0 Mean reward:24.405405405405407  i:878, n batches:1 \n",
            " Episode return:38.0  Episode return:45.0 Mean reward:21.397590361445783  i:879, n batches:1 \n",
            " Episode return:40.0  Episode return:44.0 Mean reward:21.547619047619047  i:880, n batches:1 \n",
            " Episode return:20.0  Episode return:34.0 Mean reward:14.907407407407407  i:881, n batches:1 \n",
            " Episode return:16.0  Episode return:78.0 Mean reward:34.223404255319146  i:882, n batches:1 \n",
            " Episode return:35.0  Episode return:51.0 Mean reward:22.74418604651163  i:883, n batches:1 \n",
            " Episode return:27.0  Episode return:19.0 Mean reward:12.347826086956522  i:884, n batches:1 \n",
            " Episode return:55.0  Episode return:36.0 Mean reward:24.24175824175824  i:885, n batches:1 \n",
            " Episode return:52.0  Episode return:68.0 Mean reward:31.033333333333335  i:886, n batches:1 \n",
            " Episode return:85.0  Episode return:18.0 Mean reward:37.14563106796116  i:887, n batches:1 \n",
            " Episode return:49.0  Episode return:29.0 Mean reward:21.28205128205128  i:888, n batches:1 \n",
            " Episode return:24.0  Episode return:54.0 Mean reward:22.884615384615383  i:889, n batches:1 \n",
            " Episode return:19.0  Episode return:53.0 Mean reward:22.51388888888889  i:890, n batches:1 \n",
            " Episode return:22.0  Episode return:91.0 Mean reward:39.283185840707965  i:891, n batches:1 \n",
            " Episode return:121.0  Episode return:41.0 Mean reward:50.876543209876544  i:892, n batches:2 \n",
            " Episode return:35.0  Episode return:89.0 Mean reward:37.37903225806452  i:893, n batches:1 \n",
            " Episode return:94.0  Episode return:12.0 Mean reward:42.85849056603774  i:894, n batches:1 \n",
            " Episode return:87.0  Episode return:53.0 Mean reward:37.56428571428572  i:895, n batches:2 \n",
            " Episode return:63.0  Episode return:51.0 Mean reward:29.31578947368421  i:896, n batches:1 \n",
            " Episode return:20.0  Episode return:99.0 Mean reward:43.36134453781513  i:897, n batches:1 \n",
            " Episode return:27.0  Episode return:9.0 Mean reward:11.75  i:898, n batches:1 \n",
            " Episode return:28.0  Episode return:15.0 Mean reward:12.232558139534884  i:899, n batches:1 \n",
            " Episode return:27.0  Episode return:47.0 Mean reward:20.35135135135135  i:900, n batches:1 \n",
            "loss:-0.027836497873067856\n",
            " Episode return:23.0  Episode return:13.0 Mean reward:10.194444444444445  i:901, n batches:1 \n",
            " Episode return:66.0  Episode return:134.0 Mean reward:56.28  i:902, n batches:2 \n",
            " Episode return:57.0  Episode return:48.0 Mean reward:26.942857142857143  i:903, n batches:1 \n",
            " Episode return:89.0  Episode return:44.0 Mean reward:37.556390977443606  i:904, n batches:2 \n",
            " Episode return:50.0  Episode return:77.0 Mean reward:33.68503937007874  i:905, n batches:1 \n",
            " Episode return:55.0  Episode return:28.0 Mean reward:23.44578313253012  i:906, n batches:1 \n",
            " Episode return:54.0  Episode return:15.0 Mean reward:23.26086956521739  i:907, n batches:1 \n",
            " Episode return:51.0  Episode return:114.0 Mean reward:47.763636363636365  i:908, n batches:2 \n",
            " Episode return:47.0  Episode return:61.0 Mean reward:27.953703703703702  i:909, n batches:1 \n",
            " Episode return:31.0  Episode return:48.0 Mean reward:21.164556962025316  i:910, n batches:1 \n",
            " Episode return:20.0  Episode return:42.0 Mean reward:17.951612903225808  i:911, n batches:1 \n",
            " Episode return:82.0  Episode return:61.0 Mean reward:37.02097902097902  i:912, n batches:2 \n",
            " Episode return:22.0  Episode return:46.0 Mean reward:19.61764705882353  i:913, n batches:1 \n",
            " Episode return:80.0  Episode return:21.0 Mean reward:34.366336633663366  i:914, n batches:1 \n",
            " Episode return:16.0  Episode return:36.0 Mean reward:15.423076923076923  i:915, n batches:1 \n",
            " Episode return:35.0  Episode return:56.0 Mean reward:24.46153846153846  i:916, n batches:1 \n",
            " Episode return:19.0  Episode return:39.0 Mean reward:16.724137931034484  i:917, n batches:1 \n",
            " Episode return:14.0  Episode return:106.0 Mean reward:48.13333333333333  i:918, n batches:1 \n",
            " Episode return:30.0  Episode return:23.0 Mean reward:13.981132075471699  i:919, n batches:1 \n",
            " Episode return:33.0  Episode return:21.0 Mean reward:14.666666666666666  i:920, n batches:1 \n",
            " Episode return:34.0  Episode return:33.0 Mean reward:17.253731343283583  i:921, n batches:1 \n",
            " Episode return:43.0  Episode return:42.0 Mean reward:21.75294117647059  i:922, n batches:1 \n",
            " Episode return:17.0  Episode return:35.0 Mean reward:15.057692307692308  i:923, n batches:1 \n",
            " Episode return:14.0  Episode return:9.0 Mean reward:6.521739130434782  i:924, n batches:1 \n",
            " Episode return:59.0  Episode return:30.0 Mean reward:25.1123595505618  i:925, n batches:1 \n",
            " Episode return:57.0  Episode return:49.0 Mean reward:27.150943396226417  i:926, n batches:1 \n",
            " Episode return:44.0  Episode return:36.0 Mean reward:20.7  i:927, n batches:1 \n",
            " Episode return:52.0  Episode return:28.0 Mean reward:22.3  i:928, n batches:1 \n",
            " Episode return:74.0  Episode return:52.0 Mean reward:32.96031746031746  i:929, n batches:1 \n",
            " Episode return:49.0  Episode return:28.0 Mean reward:21.181818181818183  i:930, n batches:1 \n",
            " Episode return:56.0  Episode return:38.0 Mean reward:24.861702127659573  i:931, n batches:1 \n",
            " Episode return:119.0  Episode return:18.0 Mean reward:53.36496350364963  i:932, n batches:2 \n",
            " Episode return:11.0  Episode return:32.0 Mean reward:13.813953488372093  i:933, n batches:1 \n",
            " Episode return:41.0  Episode return:43.0 Mean reward:21.511904761904763  i:934, n batches:1 \n",
            " Episode return:83.0  Episode return:37.0 Mean reward:34.90833333333333  i:935, n batches:1 \n",
            " Episode return:41.0  Episode return:29.0 Mean reward:18.514285714285716  i:936, n batches:1 \n",
            " Episode return:25.0  Episode return:87.0 Mean reward:37.080357142857146  i:937, n batches:1 \n",
            " Episode return:33.0  Episode return:34.0 Mean reward:17.253731343283583  i:938, n batches:1 \n",
            " Episode return:61.0  Episode return:37.0 Mean reward:26.46938775510204  i:939, n batches:1 \n",
            " Episode return:73.0  Episode return:24.0 Mean reward:30.938144329896907  i:940, n batches:1 \n",
            " Episode return:31.0  Episode return:25.0 Mean reward:14.660714285714286  i:941, n batches:1 \n",
            " Episode return:21.0  Episode return:48.0 Mean reward:20.391304347826086  i:942, n batches:1 \n",
            " Episode return:25.0  Episode return:24.0 Mean reward:12.755102040816327  i:943, n batches:1 \n",
            " Episode return:28.0  Episode return:28.0 Mean reward:14.5  i:944, n batches:1 \n",
            " Episode return:22.0  Episode return:17.0 Mean reward:10.41025641025641  i:945, n batches:1 \n",
            " Episode return:29.0  Episode return:14.0 Mean reward:12.55813953488372  i:946, n batches:1 \n",
            " Episode return:135.0  Episode return:83.0 Mean reward:58.10091743119266  i:947, n batches:2 \n",
            " Episode return:54.0  Episode return:19.0 Mean reward:22.945205479452056  i:948, n batches:1 \n",
            " Episode return:55.0  Episode return:65.0 Mean reward:30.708333333333332  i:949, n batches:1 \n",
            " Episode return:19.0  Episode return:16.0 Mean reward:9.314285714285715  i:950, n batches:1 \n",
            " Episode return:19.0  Episode return:48.0 Mean reward:20.388059701492537  i:951, n batches:1 \n",
            " Episode return:58.0  Episode return:100.0 Mean reward:42.79113924050633  i:952, n batches:2 \n",
            " Episode return:47.0  Episode return:23.0 Mean reward:20.057142857142857  i:953, n batches:1 \n",
            " Episode return:60.0  Episode return:100.0 Mean reward:43.0  i:954, n batches:2 \n",
            " Episode return:76.0  Episode return:38.0 Mean reward:32.166666666666664  i:955, n batches:1 \n",
            " Episode return:42.0  Episode return:76.0 Mean reward:32.44915254237288  i:956, n batches:1 \n",
            " Episode return:49.0  Episode return:29.0 Mean reward:21.28205128205128  i:957, n batches:1 \n",
            " Episode return:22.0  Episode return:12.0 Mean reward:9.735294117647058  i:958, n batches:1 \n",
            " Episode return:25.0  Episode return:23.0 Mean reward:12.520833333333334  i:959, n batches:1 \n",
            " Episode return:22.0  Episode return:44.0 Mean reward:18.833333333333332  i:960, n batches:1 \n",
            " Episode return:69.0  Episode return:56.0 Mean reward:32.088  i:961, n batches:1 \n",
            " Episode return:23.0  Episode return:56.0 Mean reward:23.696202531645568  i:962, n batches:1 \n",
            " Episode return:32.0  Episode return:121.0 Mean reward:51.69281045751634  i:963, n batches:2 \n",
            " Episode return:19.0  Episode return:68.0 Mean reward:29.149425287356323  i:964, n batches:1 \n",
            " Episode return:30.0  Episode return:65.0 Mean reward:27.473684210526315  i:965, n batches:1 \n",
            " Episode return:135.0  Episode return:27.0 Mean reward:59.0  i:966, n batches:2 \n",
            " Episode return:18.0  Episode return:42.0 Mean reward:17.9  i:967, n batches:1 \n",
            " Episode return:32.0  Episode return:34.0 Mean reward:17.015151515151516  i:968, n batches:1 \n",
            " Episode return:11.0  Episode return:19.0 Mean reward:8.533333333333333  i:969, n batches:1 \n",
            " Episode return:78.0  Episode return:58.0 Mean reward:35.23529411764706  i:970, n batches:2 \n",
            " Episode return:27.0  Episode return:34.0 Mean reward:15.950819672131148  i:971, n batches:1 \n",
            " Episode return:25.0  Episode return:68.0 Mean reward:28.72043010752688  i:972, n batches:1 \n",
            " Episode return:94.0  Episode return:52.0 Mean reward:40.02054794520548  i:973, n batches:2 \n",
            " Episode return:41.0  Episode return:57.0 Mean reward:25.653061224489797  i:974, n batches:1 \n",
            " Episode return:81.0  Episode return:43.0 Mean reward:34.41129032258065  i:975, n batches:1 \n",
            " Episode return:29.0  Episode return:94.0 Mean reward:39.83739837398374  i:976, n batches:1 \n",
            " Episode return:73.0  Episode return:41.0 Mean reward:31.24561403508772  i:977, n batches:1 \n",
            " Episode return:31.0  Episode return:29.0 Mean reward:15.516666666666667  i:978, n batches:1 \n",
            " Episode return:24.0  Episode return:32.0 Mean reward:14.785714285714286  i:979, n batches:1 \n",
            " Episode return:14.0  Episode return:15.0 Mean reward:7.758620689655173  i:980, n batches:1 \n",
            " Episode return:30.0  Episode return:77.0 Mean reward:32.41121495327103  i:981, n batches:1 \n",
            " Episode return:33.0  Episode return:25.0 Mean reward:15.275862068965518  i:982, n batches:1 \n",
            " Episode return:25.0  Episode return:57.0 Mean reward:24.121951219512194  i:983, n batches:1 \n",
            " Episode return:58.0  Episode return:32.0 Mean reward:24.877777777777776  i:984, n batches:1 \n",
            " Episode return:65.0  Episode return:59.0 Mean reward:31.572580645161292  i:985, n batches:1 \n",
            " Episode return:165.0  Episode return:37.0 Mean reward:71.27722772277228  i:986, n batches:2 \n",
            " Episode return:233.0  Episode return:15.0 Mean reward:110.40725806451613  i:987, n batches:2 \n",
            " Episode return:28.0  Episode return:76.0 Mean reward:32.03846153846154  i:988, n batches:1 \n",
            " Episode return:16.0  Episode return:36.0 Mean reward:15.423076923076923  i:989, n batches:1 \n",
            " Episode return:37.0  Episode return:68.0 Mean reward:29.038095238095238  i:990, n batches:1 \n",
            " Episode return:45.0  Episode return:65.0 Mean reward:28.90909090909091  i:991, n batches:1 \n",
            " Episode return:17.0  Episode return:16.0 Mean reward:8.757575757575758  i:992, n batches:1 \n",
            " Episode return:32.0  Episode return:76.0 Mean reward:31.98148148148148  i:993, n batches:1 \n",
            " Episode return:49.0  Episode return:47.0 Mean reward:24.510416666666668  i:994, n batches:1 \n",
            " Episode return:32.0  Episode return:21.0 Mean reward:14.320754716981131  i:995, n batches:1 \n",
            " Episode return:55.0  Episode return:66.0 Mean reward:31.0  i:996, n batches:1 \n",
            " Episode return:114.0  Episode return:31.0 Mean reward:48.62758620689655  i:997, n batches:2 \n",
            " Episode return:68.0  Episode return:97.0 Mean reward:43.02424242424242  i:998, n batches:2 \n",
            " Episode return:55.0  Episode return:37.0 Mean reward:24.380434782608695  i:999, n batches:1 \n",
            " Episode return:35.0  Episode return:55.0 Mean reward:24.11111111111111  i:1000, n batches:1 \n",
            "loss:0.0024089098442345858\n",
            " Episode return:33.0  Episode return:14.0 Mean reward:14.170212765957446  i:1001, n batches:1 \n",
            " Episode return:20.0  Episode return:29.0 Mean reward:13.16326530612245  i:1002, n batches:1 \n",
            " Episode return:76.0  Episode return:41.0 Mean reward:32.36752136752137  i:1003, n batches:1 \n",
            " Episode return:11.0  Episode return:14.0 Mean reward:6.84  i:1004, n batches:1 \n",
            " Episode return:11.0  Episode return:20.0 Mean reward:8.903225806451612  i:1005, n batches:1 \n",
            " Episode return:32.0  Episode return:35.0 Mean reward:17.28358208955224  i:1006, n batches:1 \n",
            " Episode return:50.0  Episode return:34.0 Mean reward:22.261904761904763  i:1007, n batches:1 \n",
            " Episode return:25.0  Episode return:53.0 Mean reward:22.512820512820515  i:1008, n batches:1 \n",
            " Episode return:28.0  Episode return:66.0 Mean reward:27.840425531914892  i:1009, n batches:1 \n",
            " Episode return:79.0  Episode return:90.0 Mean reward:42.928994082840234  i:1010, n batches:2 \n",
            " Episode return:76.0  Episode return:11.0 Mean reward:34.39080459770115  i:1011, n batches:1 \n",
            " Episode return:54.0  Episode return:11.0 Mean reward:23.861538461538462  i:1012, n batches:1 \n",
            " Episode return:17.0  Episode return:22.0 Mean reward:10.41025641025641  i:1013, n batches:1 \n",
            " Episode return:42.0  Episode return:16.0 Mean reward:17.913793103448278  i:1014, n batches:1 \n",
            " Episode return:22.0  Episode return:37.0 Mean reward:16.203389830508474  i:1015, n batches:1 \n",
            " Episode return:34.0  Episode return:31.0 Mean reward:16.784615384615385  i:1016, n batches:1 \n",
            " Episode return:16.0  Episode return:48.0 Mean reward:20.5  i:1017, n batches:1 \n",
            " Episode return:61.0  Episode return:46.0 Mean reward:27.77570093457944  i:1018, n batches:1 \n",
            " Episode return:36.0  Episode return:34.0 Mean reward:18.014285714285716  i:1019, n batches:1 \n",
            " Episode return:16.0  Episode return:19.0 Mean reward:9.314285714285715  i:1020, n batches:1 \n",
            " Episode return:62.0  Episode return:113.0 Mean reward:47.965714285714284  i:1021, n batches:2 \n",
            " Episode return:23.0  Episode return:15.0 Mean reward:10.421052631578947  i:1022, n batches:1 \n",
            " Episode return:37.0  Episode return:17.0 Mean reward:15.851851851851851  i:1023, n batches:1 \n",
            " Episode return:21.0  Episode return:21.0 Mean reward:11.0  i:1024, n batches:1 \n",
            " Episode return:27.0  Episode return:65.0 Mean reward:27.42391304347826  i:1025, n batches:1 \n",
            " Episode return:61.0  Episode return:21.0 Mean reward:25.878048780487806  i:1026, n batches:1 \n",
            " Episode return:22.0  Episode return:74.0 Mean reward:31.541666666666668  i:1027, n batches:1 \n",
            " Episode return:26.0  Episode return:33.0 Mean reward:15.457627118644067  i:1028, n batches:1 \n",
            " Episode return:63.0  Episode return:21.0 Mean reward:26.75  i:1029, n batches:1 \n",
            " Episode return:97.0  Episode return:21.0 Mean reward:42.23728813559322  i:1030, n batches:1 \n",
            " Episode return:44.0  Episode return:58.0 Mean reward:26.480392156862745  i:1031, n batches:1 \n",
            " Episode return:32.0  Episode return:85.0 Mean reward:35.75213675213675  i:1032, n batches:1 \n",
            " Episode return:47.0  Episode return:71.0 Mean reward:31.220338983050848  i:1033, n batches:1 \n",
            " Episode return:39.0  Episode return:35.0 Mean reward:19.054054054054053  i:1034, n batches:1 \n",
            " Episode return:57.0  Episode return:193.0 Mean reward:81.496  i:1035, n batches:2 \n",
            " Episode return:78.0  Episode return:15.0 Mean reward:34.41935483870968  i:1036, n batches:1 \n",
            " Episode return:52.0  Episode return:20.0 Mean reward:22.055555555555557  i:1037, n batches:1 \n",
            " Episode return:91.0  Episode return:26.0 Mean reward:38.77777777777778  i:1038, n batches:1 \n",
            " Episode return:18.0  Episode return:132.0 Mean reward:59.66  i:1039, n batches:2 \n",
            " Episode return:16.0  Episode return:47.0 Mean reward:20.063492063492063  i:1040, n batches:1 \n",
            " Episode return:39.0  Episode return:68.0 Mean reward:29.214953271028037  i:1041, n batches:1 \n",
            " Episode return:37.0  Episode return:97.0 Mean reward:40.71641791044776  i:1042, n batches:2 \n",
            " Episode return:33.0  Episode return:34.0 Mean reward:17.253731343283583  i:1043, n batches:1 \n",
            " Episode return:30.0  Episode return:12.0 Mean reward:12.928571428571429  i:1044, n batches:1 \n",
            " Episode return:28.0  Episode return:31.0 Mean reward:15.288135593220339  i:1045, n batches:1 \n",
            " Episode return:74.0  Episode return:67.0 Mean reward:35.836879432624116  i:1046, n batches:2 \n",
            " Episode return:40.0  Episode return:32.0 Mean reward:18.72222222222222  i:1047, n batches:1 \n",
            " Episode return:41.0  Episode return:19.0 Mean reward:17.516666666666666  i:1048, n batches:1 \n",
            " Episode return:27.0  Episode return:99.0 Mean reward:42.285714285714285  i:1049, n batches:1 \n",
            " Episode return:54.0  Episode return:10.0 Mean reward:24.0625  i:1050, n batches:1 \n",
            " Episode return:20.0  Episode return:24.0 Mean reward:11.590909090909092  i:1051, n batches:1 \n",
            " Episode return:20.0  Episode return:36.0 Mean reward:15.642857142857142  i:1052, n batches:1 \n",
            " Episode return:38.0  Episode return:45.0 Mean reward:21.397590361445783  i:1053, n batches:1 \n",
            " Episode return:108.0  Episode return:13.0 Mean reward:49.396694214876035  i:1054, n batches:1 \n",
            " Episode return:39.0  Episode return:19.0 Mean reward:16.724137931034484  i:1055, n batches:1 \n",
            " Episode return:14.0  Episode return:53.0 Mean reward:22.925373134328357  i:1056, n batches:1 \n",
            " Episode return:132.0  Episode return:38.0 Mean reward:55.99411764705882  i:1057, n batches:2 \n",
            " Episode return:54.0  Episode return:43.0 Mean reward:25.061855670103093  i:1058, n batches:1 \n",
            " Episode return:112.0  Episode return:17.0 Mean reward:50.24031007751938  i:1059, n batches:2 \n",
            " Episode return:44.0  Episode return:79.0 Mean reward:33.739837398373986  i:1060, n batches:1 \n",
            " Episode return:28.0  Episode return:51.0 Mean reward:21.924050632911392  i:1061, n batches:1 \n",
            " Episode return:26.0  Episode return:23.0 Mean reward:12.795918367346939  i:1062, n batches:1 \n",
            " Episode return:67.0  Episode return:52.0 Mean reward:30.722689075630253  i:1063, n batches:1 \n",
            " Episode return:36.0  Episode return:54.0 Mean reward:23.9  i:1064, n batches:1 \n",
            " Episode return:75.0  Episode return:43.0 Mean reward:32.16949152542373  i:1065, n batches:1 \n",
            " Episode return:152.0  Episode return:38.0 Mean reward:65.1  i:1066, n batches:2 \n",
            " Episode return:41.0  Episode return:20.0 Mean reward:17.557377049180328  i:1067, n batches:1 \n",
            " Episode return:27.0  Episode return:39.0 Mean reward:17.545454545454547  i:1068, n batches:1 \n",
            " Episode return:74.0  Episode return:43.0 Mean reward:31.803418803418804  i:1069, n batches:1 \n",
            " Episode return:38.0  Episode return:21.0 Mean reward:16.47457627118644  i:1070, n batches:1 \n",
            " Episode return:154.0  Episode return:25.0 Mean reward:68.49162011173185  i:1071, n batches:2 \n",
            " Episode return:66.0  Episode return:13.0 Mean reward:29.139240506329113  i:1072, n batches:1 \n",
            " Episode return:18.0  Episode return:25.0 Mean reward:11.534883720930232  i:1073, n batches:1 \n",
            " Episode return:73.0  Episode return:44.0 Mean reward:31.54700854700855  i:1074, n batches:1 \n",
            " Episode return:41.0  Episode return:29.0 Mean reward:18.514285714285716  i:1075, n batches:1 \n",
            " Episode return:16.0  Episode return:21.0 Mean reward:9.91891891891892  i:1076, n batches:1 \n",
            " Episode return:48.0  Episode return:46.0 Mean reward:24.01063829787234  i:1077, n batches:1 \n",
            " Episode return:13.0  Episode return:68.0 Mean reward:30.08641975308642  i:1078, n batches:1 \n",
            " Episode return:51.0  Episode return:48.0 Mean reward:25.272727272727273  i:1079, n batches:1 \n",
            " Episode return:22.0  Episode return:18.0 Mean reward:10.6  i:1080, n batches:1 \n",
            " Episode return:21.0  Episode return:48.0 Mean reward:20.391304347826086  i:1081, n batches:1 \n",
            " Episode return:42.0  Episode return:40.0 Mean reward:21.01219512195122  i:1082, n batches:1 \n",
            " Episode return:90.0  Episode return:110.0 Mean reward:51.0  i:1083, n batches:2 \n",
            " Episode return:107.0  Episode return:67.0 Mean reward:46.298850574712645  i:1084, n batches:2 \n",
            " Episode return:93.0  Episode return:28.0 Mean reward:39.47933884297521  i:1085, n batches:1 \n",
            " Episode return:50.0  Episode return:72.0 Mean reward:31.991803278688526  i:1086, n batches:1 \n",
            " Episode return:66.0  Episode return:63.0 Mean reward:32.76744186046512  i:1087, n batches:2 \n",
            " Episode return:61.0  Episode return:32.0 Mean reward:26.010752688172044  i:1088, n batches:1 \n",
            " Episode return:52.0  Episode return:28.0 Mean reward:22.3  i:1089, n batches:1 \n",
            " Episode return:109.0  Episode return:14.0 Mean reward:49.59349593495935  i:1090, n batches:1 \n",
            " Episode return:46.0  Episode return:86.0 Mean reward:36.53030303030303  i:1091, n batches:2 \n",
            " Episode return:128.0  Episode return:32.0 Mean reward:54.9  i:1092, n batches:2 \n",
            " Episode return:9.0  Episode return:72.0 Mean reward:33.0  i:1093, n batches:1 \n",
            " Episode return:46.0  Episode return:40.0 Mean reward:22.1046511627907  i:1094, n batches:1 \n",
            " Episode return:41.0  Episode return:60.0 Mean reward:26.643564356435643  i:1095, n batches:1 \n",
            " Episode return:48.0  Episode return:44.0 Mean reward:23.543478260869566  i:1096, n batches:1 \n",
            " Episode return:13.0  Episode return:21.0 Mean reward:9.470588235294118  i:1097, n batches:1 \n",
            " Episode return:42.0  Episode return:50.0 Mean reward:23.67391304347826  i:1098, n batches:1 \n",
            " Episode return:58.0  Episode return:87.0 Mean reward:38.2  i:1099, n batches:2 \n",
            " Episode return:84.0  Episode return:57.0 Mean reward:37.04255319148936  i:1100, n batches:2 \n",
            "loss:-0.027755482122302055\n",
            "loss:-0.009524786844849586\n",
            " Episode return:31.0  Episode return:38.0 Mean reward:17.92753623188406  i:1101, n batches:1 \n",
            " Episode return:64.0  Episode return:18.0 Mean reward:27.451219512195124  i:1102, n batches:1 \n",
            " Episode return:20.0  Episode return:52.0 Mean reward:22.055555555555557  i:1103, n batches:1 \n",
            " Episode return:26.0  Episode return:39.0 Mean reward:17.4  i:1104, n batches:1 \n",
            " Episode return:41.0  Episode return:85.0 Mean reward:35.84126984126984  i:1105, n batches:1 \n",
            " Episode return:44.0  Episode return:52.0 Mean reward:24.666666666666668  i:1106, n batches:1 \n",
            " Episode return:20.0  Episode return:136.0 Mean reward:61.06410256410256  i:1107, n batches:2 \n",
            " Episode return:16.0  Episode return:41.0 Mean reward:17.49122807017544  i:1108, n batches:1 \n",
            " Episode return:15.0  Episode return:42.0 Mean reward:17.94736842105263  i:1109, n batches:1 \n",
            " Episode return:30.0  Episode return:68.0 Mean reward:28.683673469387756  i:1110, n batches:1 \n",
            " Episode return:12.0  Episode return:27.0 Mean reward:11.692307692307692  i:1111, n batches:1 \n",
            " Episode return:25.0  Episode return:66.0 Mean reward:27.86813186813187  i:1112, n batches:1 \n",
            " Episode return:24.0  Episode return:40.0 Mean reward:17.5  i:1113, n batches:1 \n",
            " Episode return:59.0  Episode return:15.0 Mean reward:25.54054054054054  i:1114, n batches:1 \n",
            " Episode return:13.0  Episode return:21.0 Mean reward:9.470588235294118  i:1115, n batches:1 \n",
            " Episode return:63.0  Episode return:99.0 Mean reward:43.0  i:1116, n batches:2 \n",
            " Episode return:38.0  Episode return:41.0 Mean reward:20.27848101265823  i:1117, n batches:1 \n",
            " Episode return:45.0  Episode return:30.0 Mean reward:20.0  i:1118, n batches:1 \n",
            " Episode return:20.0  Episode return:20.0 Mean reward:10.5  i:1119, n batches:1 \n",
            " Episode return:111.0  Episode return:61.0 Mean reward:47.133720930232556  i:1120, n batches:2 \n",
            " Episode return:27.0  Episode return:15.0 Mean reward:11.857142857142858  i:1121, n batches:1 \n",
            " Episode return:150.0  Episode return:29.0 Mean reward:65.69832402234637  i:1122, n batches:2 \n",
            " Episode return:39.0  Episode return:98.0 Mean reward:41.1021897810219  i:1123, n batches:2 \n",
            " Episode return:10.0  Episode return:43.0 Mean reward:18.88679245283019  i:1124, n batches:1 \n",
            " Episode return:31.0  Episode return:102.0 Mean reward:43.225563909774436  i:1125, n batches:2 \n",
            " Episode return:26.0  Episode return:56.0 Mean reward:23.74390243902439  i:1126, n batches:1 \n",
            " Episode return:68.0  Episode return:17.0 Mean reward:29.4  i:1127, n batches:1 \n",
            " Episode return:43.0  Episode return:17.0 Mean reward:18.316666666666666  i:1128, n batches:1 \n",
            " Episode return:41.0  Episode return:20.0 Mean reward:17.557377049180328  i:1129, n batches:1 \n",
            " Episode return:35.0  Episode return:16.0 Mean reward:15.019607843137255  i:1130, n batches:1 \n",
            " Episode return:36.0  Episode return:26.0 Mean reward:16.403225806451612  i:1131, n batches:1 \n",
            " Episode return:25.0  Episode return:43.0 Mean reward:18.691176470588236  i:1132, n batches:1 \n",
            " Episode return:38.0  Episode return:85.0 Mean reward:35.739837398373986  i:1133, n batches:1 \n",
            " Episode return:66.0  Episode return:38.0 Mean reward:28.384615384615383  i:1134, n batches:1 \n",
            " Episode return:20.0  Episode return:42.0 Mean reward:17.951612903225808  i:1135, n batches:1 \n",
            " Episode return:16.0  Episode return:17.0 Mean reward:8.757575757575758  i:1136, n batches:1 \n",
            " Episode return:18.0  Episode return:54.0 Mean reward:23.0  i:1137, n batches:1 \n",
            " Episode return:32.0  Episode return:53.0 Mean reward:23.04705882352941  i:1138, n batches:1 \n",
            " Episode return:34.0  Episode return:106.0 Mean reward:44.75714285714286  i:1139, n batches:2 \n",
            " Episode return:46.0  Episode return:15.0 Mean reward:19.688524590163933  i:1140, n batches:1 \n",
            " Episode return:92.0  Episode return:80.0 Mean reward:43.7093023255814  i:1141, n batches:2 \n",
            " Episode return:55.0  Episode return:50.0 Mean reward:26.80952380952381  i:1142, n batches:1 \n",
            " Episode return:43.0  Episode return:52.0 Mean reward:24.46315789473684  i:1143, n batches:1 \n",
            " Episode return:34.0  Episode return:23.0 Mean reward:15.280701754385966  i:1144, n batches:1 \n",
            " Episode return:26.0  Episode return:35.0 Mean reward:16.081967213114755  i:1145, n batches:1 \n",
            " Episode return:74.0  Episode return:34.0 Mean reward:31.203703703703702  i:1146, n batches:1 \n",
            " Episode return:19.0  Episode return:17.0 Mean reward:9.527777777777779  i:1147, n batches:1 \n",
            " Episode return:41.0  Episode return:37.0 Mean reward:20.05128205128205  i:1148, n batches:1 \n",
            " Episode return:42.0  Episode return:21.0 Mean reward:18.0  i:1149, n batches:1 \n",
            " Episode return:29.0  Episode return:131.0 Mean reward:56.75625  i:1150, n batches:2 \n",
            " Episode return:20.0  Episode return:76.0 Mean reward:32.666666666666664  i:1151, n batches:1 \n",
            " Episode return:28.0  Episode return:68.0 Mean reward:28.666666666666668  i:1152, n batches:1 \n",
            " Episode return:37.0  Episode return:76.0 Mean reward:32.11504424778761  i:1153, n batches:1 \n",
            " Episode return:77.0  Episode return:12.0 Mean reward:34.61797752808989  i:1154, n batches:1 \n",
            " Episode return:55.0  Episode return:68.0 Mean reward:31.59349593495935  i:1155, n batches:1 \n",
            " Episode return:61.0  Episode return:32.0 Mean reward:26.010752688172044  i:1156, n batches:1 \n",
            " Episode return:51.0  Episode return:71.0 Mean reward:31.81967213114754  i:1157, n batches:1 \n",
            " Episode return:103.0  Episode return:41.0 Mean reward:43.173611111111114  i:1158, n batches:2 \n",
            " Episode return:47.0  Episode return:27.0 Mean reward:20.35135135135135  i:1159, n batches:1 \n",
            " Episode return:55.0  Episode return:39.0 Mean reward:24.680851063829788  i:1160, n batches:1 \n",
            " Episode return:95.0  Episode return:24.0 Mean reward:40.84033613445378  i:1161, n batches:1 \n",
            " Episode return:30.0  Episode return:21.0 Mean reward:13.647058823529411  i:1162, n batches:1 \n",
            " Episode return:12.0  Episode return:33.0 Mean reward:14.2  i:1163, n batches:1 \n",
            " Episode return:43.0  Episode return:26.0 Mean reward:18.797101449275363  i:1164, n batches:1 \n",
            " Episode return:26.0  Episode return:33.0 Mean reward:15.457627118644067  i:1165, n batches:1 \n",
            " Episode return:44.0  Episode return:100.0 Mean reward:41.94444444444444  i:1166, n batches:2 \n",
            " Episode return:90.0  Episode return:52.0 Mean reward:38.54225352112676  i:1167, n batches:2 \n",
            " Episode return:64.0  Episode return:52.0 Mean reward:29.810344827586206  i:1168, n batches:1 \n",
            " Episode return:37.0  Episode return:79.0 Mean reward:33.30172413793103  i:1169, n batches:1 \n",
            " Episode return:47.0  Episode return:188.0 Mean reward:80.4  i:1170, n batches:2 \n",
            " Episode return:70.0  Episode return:39.0 Mean reward:29.954128440366972  i:1171, n batches:1 \n",
            " Episode return:67.0  Episode return:33.0 Mean reward:28.39  i:1172, n batches:1 \n",
            " Episode return:11.0  Episode return:15.0 Mean reward:7.153846153846154  i:1173, n batches:1 \n",
            " Episode return:23.0  Episode return:30.0 Mean reward:13.981132075471699  i:1174, n batches:1 \n",
            " Episode return:55.0  Episode return:38.0 Mean reward:24.526881720430108  i:1175, n batches:1 \n",
            " Episode return:77.0  Episode return:45.0 Mean reward:33.09836065573771  i:1176, n batches:1 \n",
            " Episode return:49.0  Episode return:68.0 Mean reward:30.521367521367523  i:1177, n batches:1 \n",
            " Episode return:28.0  Episode return:33.0 Mean reward:15.852459016393443  i:1178, n batches:1 \n",
            " Episode return:58.0  Episode return:47.0 Mean reward:27.038095238095238  i:1179, n batches:1 \n",
            " Episode return:48.0  Episode return:58.0 Mean reward:27.235849056603772  i:1180, n batches:1 \n",
            " Episode return:87.0  Episode return:20.0 Mean reward:37.73831775700935  i:1181, n batches:1 \n",
            " Episode return:18.0  Episode return:119.0 Mean reward:53.36496350364963  i:1182, n batches:2 \n",
            " Episode return:59.0  Episode return:54.0 Mean reward:28.805309734513273  i:1183, n batches:1 \n",
            " Episode return:121.0  Episode return:53.0 Mean reward:50.64367816091954  i:1184, n batches:2 \n",
            " Episode return:112.0  Episode return:21.0 Mean reward:49.31578947368421  i:1185, n batches:2 \n",
            " Episode return:126.0  Episode return:26.0 Mean reward:54.94736842105263  i:1186, n batches:2 \n",
            " Episode return:60.0  Episode return:38.0 Mean reward:26.23469387755102  i:1187, n batches:1 \n",
            " Episode return:144.0  Episode return:25.0 Mean reward:63.69822485207101  i:1188, n batches:2 \n",
            " Episode return:12.0  Episode return:47.0 Mean reward:20.440677966101696  i:1189, n batches:1 \n",
            " Episode return:111.0  Episode return:108.0 Mean reward:55.26027397260274  i:1190, n batches:2 \n",
            " Episode return:41.0  Episode return:15.0 Mean reward:17.517857142857142  i:1191, n batches:1 \n",
            " Episode return:95.0  Episode return:31.0 Mean reward:40.12698412698413  i:1192, n batches:1 \n",
            " Episode return:132.0  Episode return:32.0 Mean reward:56.74390243902439  i:1193, n batches:2 \n",
            " Episode return:86.0  Episode return:30.0 Mean reward:36.258620689655174  i:1194, n batches:1 \n",
            " Episode return:25.0  Episode return:53.0 Mean reward:22.512820512820515  i:1195, n batches:1 \n",
            " Episode return:69.0  Episode return:31.0 Mean reward:29.11  i:1196, n batches:1 \n",
            " Episode return:52.0  Episode return:86.0 Mean reward:37.094202898550726  i:1197, n batches:2 \n",
            " Episode return:86.0  Episode return:78.0 Mean reward:41.59756097560975  i:1198, n batches:2 \n",
            " Episode return:106.0  Episode return:113.0 Mean reward:55.305936073059364  i:1199, n batches:2 \n",
            " Episode return:14.0  Episode return:85.0 Mean reward:37.97979797979798  i:1200, n batches:1 \n",
            "loss:-0.03170263022184372\n",
            " Episode return:33.0  Episode return:30.0 Mean reward:16.285714285714285  i:1201, n batches:1 \n",
            " Episode return:21.0  Episode return:52.0 Mean reward:22.041095890410958  i:1202, n batches:1 \n",
            " Episode return:45.0  Episode return:20.0 Mean reward:19.153846153846153  i:1203, n batches:1 \n",
            " Episode return:48.0  Episode return:50.0 Mean reward:25.010204081632654  i:1204, n batches:1 \n",
            " Episode return:83.0  Episode return:57.0 Mean reward:36.707142857142856  i:1205, n batches:2 \n",
            " Episode return:31.0  Episode return:78.0 Mean reward:32.81651376146789  i:1206, n batches:1 \n",
            " Episode return:31.0  Episode return:47.0 Mean reward:20.82051282051282  i:1207, n batches:1 \n",
            " Episode return:48.0  Episode return:19.0 Mean reward:20.388059701492537  i:1208, n batches:1 \n",
            " Episode return:58.0  Episode return:78.0 Mean reward:35.23529411764706  i:1209, n batches:2 \n",
            " Episode return:82.0  Episode return:90.0 Mean reward:43.593023255813954  i:1210, n batches:2 \n",
            " Episode return:50.0  Episode return:36.0 Mean reward:22.569767441860463  i:1211, n batches:1 \n",
            " Episode return:11.0  Episode return:80.0 Mean reward:36.32967032967033  i:1212, n batches:1 \n",
            " Episode return:35.0  Episode return:20.0 Mean reward:15.272727272727273  i:1213, n batches:1 \n",
            " Episode return:30.0  Episode return:84.0 Mean reward:35.39473684210526  i:1214, n batches:1 \n",
            " Episode return:115.0  Episode return:16.0 Mean reward:51.954198473282446  i:1215, n batches:2 \n",
            " Episode return:16.0  Episode return:84.0 Mean reward:37.06  i:1216, n batches:1 \n",
            " Episode return:57.0  Episode return:125.0 Mean reward:52.35164835164835  i:1217, n batches:2 \n",
            " Episode return:115.0  Episode return:98.0 Mean reward:54.08920187793427  i:1218, n batches:2 \n",
            " Episode return:38.0  Episode return:103.0 Mean reward:43.241134751773046  i:1219, n batches:2 \n",
            " Episode return:20.0  Episode return:39.0 Mean reward:16.779661016949152  i:1220, n batches:1 \n",
            " Episode return:75.0  Episode return:73.0 Mean reward:37.50675675675676  i:1221, n batches:2 \n",
            " Episode return:56.0  Episode return:34.0 Mean reward:24.344444444444445  i:1222, n batches:1 \n",
            " Episode return:33.0  Episode return:59.0 Mean reward:25.33695652173913  i:1223, n batches:1 \n",
            " Episode return:12.0  Episode return:24.0 Mean reward:10.5  i:1224, n batches:1 \n",
            " Episode return:21.0  Episode return:139.0 Mean reward:62.25625  i:1225, n batches:2 \n",
            " Episode return:34.0  Episode return:99.0 Mean reward:41.69172932330827  i:1226, n batches:2 \n",
            " Episode return:65.0  Episode return:38.0 Mean reward:28.019417475728154  i:1227, n batches:1 \n",
            " Episode return:91.0  Episode return:30.0 Mean reward:38.43801652892562  i:1228, n batches:1 \n",
            " Episode return:30.0  Episode return:57.0 Mean reward:24.344827586206897  i:1229, n batches:1 \n",
            " Episode return:35.0  Episode return:26.0 Mean reward:16.081967213114755  i:1230, n batches:1 \n",
            " Episode return:17.0  Episode return:36.0 Mean reward:15.452830188679245  i:1231, n batches:1 \n",
            " Episode return:46.0  Episode return:64.0 Mean reward:28.736363636363638  i:1232, n batches:1 \n",
            " Episode return:147.0  Episode return:28.0 Mean reward:64.48  i:1233, n batches:2 \n",
            " Episode return:18.0  Episode return:46.0 Mean reward:19.5625  i:1234, n batches:1 \n",
            " Episode return:76.0  Episode return:17.0 Mean reward:33.10752688172043  i:1235, n batches:1 \n",
            " Episode return:30.0  Episode return:25.0 Mean reward:14.363636363636363  i:1236, n batches:1 \n",
            " Episode return:58.0  Episode return:30.0 Mean reward:24.727272727272727  i:1237, n batches:1 \n",
            " Episode return:80.0  Episode return:68.0 Mean reward:37.74324324324324  i:1238, n batches:2 \n",
            " Episode return:106.0  Episode return:24.0 Mean reward:45.93076923076923  i:1239, n batches:2 \n",
            " Episode return:10.0  Episode return:45.0 Mean reward:19.818181818181817  i:1240, n batches:1 \n",
            " Episode return:54.0  Episode return:160.0 Mean reward:67.12616822429906  i:1241, n batches:2 \n",
            " Episode return:9.0  Episode return:14.0 Mean reward:6.521739130434782  i:1242, n batches:1 \n",
            " Episode return:52.0  Episode return:35.0 Mean reward:23.080459770114942  i:1243, n batches:1 \n",
            " Episode return:38.0  Episode return:32.0 Mean reward:18.12857142857143  i:1244, n batches:1 \n",
            " Episode return:12.0  Episode return:72.0 Mean reward:32.214285714285715  i:1245, n batches:1 \n",
            " Episode return:28.0  Episode return:18.0 Mean reward:12.543478260869565  i:1246, n batches:1 \n",
            " Episode return:90.0  Episode return:52.0 Mean reward:38.54225352112676  i:1247, n batches:2 \n",
            " Episode return:83.0  Episode return:83.0 Mean reward:42.0  i:1248, n batches:2 \n",
            " Episode return:111.0  Episode return:97.0 Mean reward:52.73557692307692  i:1249, n batches:2 \n",
            " Episode return:81.0  Episode return:33.0 Mean reward:34.05263157894737  i:1250, n batches:1 \n",
            " Episode return:56.0  Episode return:90.0 Mean reward:38.97945205479452  i:1251, n batches:2 \n",
            " Episode return:47.0  Episode return:69.0 Mean reward:30.54310344827586  i:1252, n batches:1 \n",
            " Episode return:65.0  Episode return:64.0 Mean reward:32.751937984496124  i:1253, n batches:2 \n",
            " Episode return:80.0  Episode return:27.0 Mean reward:33.81308411214953  i:1254, n batches:1 \n",
            " Episode return:13.0  Episode return:55.0 Mean reward:23.985294117647058  i:1255, n batches:1 \n",
            " Episode return:13.0  Episode return:16.0 Mean reward:7.827586206896552  i:1256, n batches:1 \n",
            " Episode return:103.0  Episode return:43.0 Mean reward:43.16438356164384  i:1257, n batches:2 \n",
            " Episode return:35.0  Episode return:42.0 Mean reward:19.90909090909091  i:1258, n batches:1 \n",
            " Episode return:38.0  Episode return:43.0 Mean reward:20.82716049382716  i:1259, n batches:1 \n",
            " Episode return:77.0  Episode return:17.0 Mean reward:33.57446808510638  i:1260, n batches:1 \n",
            " Episode return:45.0  Episode return:35.0 Mean reward:20.8125  i:1261, n batches:1 \n",
            " Episode return:96.0  Episode return:61.0 Mean reward:41.70063694267516  i:1262, n batches:2 \n",
            " Episode return:30.0  Episode return:32.0 Mean reward:16.016129032258064  i:1263, n batches:1 \n",
            " Episode return:24.0  Episode return:53.0 Mean reward:22.48051948051948  i:1264, n batches:1 \n",
            " Episode return:26.0  Episode return:87.0 Mean reward:36.982300884955755  i:1265, n batches:1 \n",
            " Episode return:22.0  Episode return:30.0 Mean reward:13.807692307692308  i:1266, n batches:1 \n",
            " Episode return:67.0  Episode return:32.0 Mean reward:28.343434343434343  i:1267, n batches:1 \n",
            " Episode return:28.0  Episode return:22.0 Mean reward:13.18  i:1268, n batches:1 \n",
            " Episode return:32.0  Episode return:145.0 Mean reward:62.78531073446328  i:1269, n batches:2 \n",
            " Episode return:119.0  Episode return:87.0 Mean reward:53.24271844660194  i:1270, n batches:2 \n",
            " Episode return:72.0  Episode return:56.0 Mean reward:33.0  i:1271, n batches:1 \n",
            " Episode return:44.0  Episode return:64.0 Mean reward:28.425925925925927  i:1272, n batches:1 \n",
            " Episode return:33.0  Episode return:89.0 Mean reward:37.42622950819672  i:1273, n batches:1 \n",
            " Episode return:37.0  Episode return:26.0 Mean reward:16.73015873015873  i:1274, n batches:1 \n",
            " Episode return:79.0  Episode return:36.0 Mean reward:33.2695652173913  i:1275, n batches:1 \n",
            " Episode return:51.0  Episode return:113.0 Mean reward:47.359756097560975  i:1276, n batches:2 \n",
            " Episode return:108.0  Episode return:79.0 Mean reward:48.37433155080214  i:1277, n batches:2 \n",
            " Episode return:26.0  Episode return:39.0 Mean reward:17.4  i:1278, n batches:1 \n",
            " Episode return:70.0  Episode return:20.0 Mean reward:29.944444444444443  i:1279, n batches:1 \n",
            " Episode return:103.0  Episode return:28.0 Mean reward:43.98473282442748  i:1280, n batches:2 \n",
            " Episode return:20.0  Episode return:37.0 Mean reward:16.017543859649123  i:1281, n batches:1 \n",
            " Episode return:30.0  Episode return:62.0 Mean reward:26.282608695652176  i:1282, n batches:1 \n",
            " Episode return:34.0  Episode return:50.0 Mean reward:22.261904761904763  i:1283, n batches:1 \n",
            " Episode return:75.0  Episode return:24.0 Mean reward:31.818181818181817  i:1284, n batches:1 \n",
            " Episode return:102.0  Episode return:55.0 Mean reward:43.267515923566876  i:1285, n batches:2 \n",
            " Episode return:108.0  Episode return:122.0 Mean reward:58.21304347826087  i:1286, n batches:2 \n",
            " Episode return:32.0  Episode return:48.0 Mean reward:21.3  i:1287, n batches:1 \n",
            " Episode return:127.0  Episode return:10.0 Mean reward:59.72992700729927  i:1288, n batches:2 \n",
            " Episode return:25.0  Episode return:55.0 Mean reward:23.3125  i:1289, n batches:1 \n",
            " Episode return:36.0  Episode return:33.0 Mean reward:17.782608695652176  i:1290, n batches:1 \n",
            " Episode return:120.0  Episode return:118.0 Mean reward:60.00420168067227  i:1291, n batches:2 \n",
            " Episode return:29.0  Episode return:40.0 Mean reward:18.18840579710145  i:1292, n batches:1 \n",
            " Episode return:127.0  Episode return:38.0 Mean reward:53.75151515151515  i:1293, n batches:2 \n",
            " Episode return:64.0  Episode return:19.0 Mean reward:27.349397590361445  i:1294, n batches:1 \n",
            " Episode return:52.0  Episode return:52.0 Mean reward:26.5  i:1295, n batches:1 \n",
            " Episode return:30.0  Episode return:73.0 Mean reward:30.737864077669904  i:1296, n batches:1 \n",
            " Episode return:37.0  Episode return:43.0 Mean reward:20.6125  i:1297, n batches:1 \n",
            " Episode return:111.0  Episode return:65.0 Mean reward:47.50568181818182  i:1298, n batches:2 \n",
            " Episode return:18.0  Episode return:71.0 Mean reward:30.640449438202246  i:1299, n batches:1 \n",
            " Episode return:53.0  Episode return:46.0 Mean reward:25.373737373737374  i:1300, n batches:1 \n",
            "loss:0.014471188187599182\n",
            " Episode return:85.0  Episode return:59.0 Mean reward:37.673611111111114  i:1301, n batches:2 \n",
            " Episode return:74.0  Episode return:48.0 Mean reward:32.385245901639344  i:1302, n batches:1 \n",
            " Episode return:31.0  Episode return:30.0 Mean reward:15.754098360655737  i:1303, n batches:1 \n",
            " Episode return:36.0  Episode return:38.0 Mean reward:19.013513513513512  i:1304, n batches:1 \n",
            " Episode return:53.0  Episode return:55.0 Mean reward:27.50925925925926  i:1305, n batches:1 \n",
            " Episode return:54.0  Episode return:37.0 Mean reward:24.043956043956044  i:1306, n batches:1 \n",
            " Episode return:137.0  Episode return:31.0 Mean reward:59.220238095238095  i:1307, n batches:2 \n",
            " Episode return:98.0  Episode return:31.0 Mean reward:41.44961240310077  i:1308, n batches:2 \n",
            " Episode return:42.0  Episode return:44.0 Mean reward:22.011627906976745  i:1309, n batches:1 \n",
            " Episode return:147.0  Episode return:21.0 Mean reward:66.125  i:1310, n batches:2 \n",
            " Episode return:69.0  Episode return:44.0 Mean reward:30.13274336283186  i:1311, n batches:1 \n",
            " Episode return:182.0  Episode return:76.0 Mean reward:75.8875968992248  i:1312, n batches:3 \n",
            " Episode return:12.0  Episode return:28.0 Mean reward:12.1  i:1313, n batches:1 \n",
            " Episode return:37.0  Episode return:135.0 Mean reward:57.4593023255814  i:1314, n batches:2 \n",
            " Episode return:58.0  Episode return:55.0 Mean reward:28.76991150442478  i:1315, n batches:1 \n",
            " Episode return:19.0  Episode return:38.0 Mean reward:16.333333333333332  i:1316, n batches:1 \n",
            " Episode return:23.0  Episode return:53.0 Mean reward:22.460526315789473  i:1317, n batches:1 \n",
            " Episode return:41.0  Episode return:44.0 Mean reward:21.776470588235295  i:1318, n batches:1 \n",
            " Episode return:25.0  Episode return:72.0 Mean reward:30.443298969072163  i:1319, n batches:1 \n",
            " Episode return:20.0  Episode return:59.0 Mean reward:25.063291139240505  i:1320, n batches:1 \n",
            " Episode return:23.0  Episode return:43.0 Mean reward:18.515151515151516  i:1321, n batches:1 \n",
            " Episode return:21.0  Episode return:20.0 Mean reward:10.75609756097561  i:1322, n batches:1 \n",
            " Episode return:84.0  Episode return:57.0 Mean reward:37.04255319148936  i:1323, n batches:2 \n",
            " Episode return:25.0  Episode return:175.0 Mean reward:78.625  i:1324, n batches:2 \n",
            " Episode return:45.0  Episode return:67.0 Mean reward:29.580357142857142  i:1325, n batches:1 \n",
            " Episode return:101.0  Episode return:59.0 Mean reward:43.25625  i:1326, n batches:2 \n",
            " Episode return:157.0  Episode return:53.0 Mean reward:65.87619047619047  i:1327, n batches:2 \n",
            " Episode return:91.0  Episode return:144.0 Mean reward:62.238297872340425  i:1328, n batches:2 \n",
            " Episode return:106.0  Episode return:29.0 Mean reward:45.22962962962963  i:1329, n batches:2 \n",
            " Episode return:17.0  Episode return:132.0 Mean reward:59.939597315436245  i:1330, n batches:2 \n",
            " Episode return:43.0  Episode return:52.0 Mean reward:24.46315789473684  i:1331, n batches:1 \n",
            " Episode return:19.0  Episode return:28.0 Mean reward:12.680851063829786  i:1332, n batches:1 \n",
            " Episode return:41.0  Episode return:24.0 Mean reward:17.861538461538462  i:1333, n batches:1 \n",
            " Episode return:87.0  Episode return:45.0 Mean reward:36.84090909090909  i:1334, n batches:2 \n",
            " Episode return:57.0  Episode return:13.0 Mean reward:24.914285714285715  i:1335, n batches:1 \n",
            " Episode return:43.0  Episode return:68.0 Mean reward:29.65765765765766  i:1336, n batches:1 \n",
            " Episode return:43.0  Episode return:43.0 Mean reward:22.0  i:1337, n batches:1 \n",
            " Episode return:101.0  Episode return:42.0 Mean reward:42.33566433566433  i:1338, n batches:2 \n",
            " Episode return:10.0  Episode return:54.0 Mean reward:24.0625  i:1339, n batches:1 \n",
            " Episode return:79.0  Episode return:82.0 Mean reward:40.7639751552795  i:1340, n batches:2 \n",
            " Episode return:101.0  Episode return:18.0 Mean reward:44.72268907563025  i:1341, n batches:1 \n",
            " Episode return:101.0  Episode return:50.0 Mean reward:42.556291390728475  i:1342, n batches:2 \n",
            " Episode return:16.0  Episode return:48.0 Mean reward:20.5  i:1343, n batches:1 \n",
            " Episode return:35.0  Episode return:41.0 Mean reward:19.61842105263158  i:1344, n batches:1 \n",
            " Episode return:66.0  Episode return:61.0 Mean reward:32.2992125984252  i:1345, n batches:1 \n",
            " Episode return:104.0  Episode return:59.0 Mean reward:44.355828220858896  i:1346, n batches:2 \n",
            " Episode return:28.0  Episode return:31.0 Mean reward:15.288135593220339  i:1347, n batches:1 \n",
            " Episode return:57.0  Episode return:26.0 Mean reward:24.14457831325301  i:1348, n batches:1 \n",
            " Episode return:19.0  Episode return:27.0 Mean reward:12.347826086956522  i:1349, n batches:1 \n",
            " Episode return:46.0  Episode return:98.0 Mean reward:41.19444444444444  i:1350, n batches:2 \n",
            " Episode return:45.0  Episode return:70.0 Mean reward:30.608695652173914  i:1351, n batches:1 \n",
            " Episode return:68.0  Episode return:85.0 Mean reward:39.22222222222222  i:1352, n batches:2 \n",
            " Episode return:51.0  Episode return:58.0 Mean reward:27.862385321100916  i:1353, n batches:1 \n",
            " Episode return:119.0  Episode return:20.0 Mean reward:52.87769784172662  i:1354, n batches:2 \n",
            " Episode return:60.0  Episode return:44.0 Mean reward:27.115384615384617  i:1355, n batches:1 \n",
            " Episode return:18.0  Episode return:18.0 Mean reward:9.5  i:1356, n batches:1 \n",
            " Episode return:86.0  Episode return:76.0 Mean reward:41.15432098765432  i:1357, n batches:2 \n",
            " Episode return:107.0  Episode return:101.0 Mean reward:52.54326923076923  i:1358, n batches:2 \n",
            " Episode return:98.0  Episode return:38.0 Mean reward:41.11764705882353  i:1359, n batches:2 \n",
            " Episode return:32.0  Episode return:78.0 Mean reward:32.80909090909091  i:1360, n batches:1 \n",
            " Episode return:21.0  Episode return:74.0 Mean reward:31.642105263157895  i:1361, n batches:1 \n",
            " Episode return:36.0  Episode return:65.0 Mean reward:27.831683168316832  i:1362, n batches:1 \n",
            " Episode return:136.0  Episode return:34.0 Mean reward:58.3  i:1363, n batches:2 \n",
            " Episode return:103.0  Episode return:129.0 Mean reward:59.22844827586207  i:1364, n batches:2 \n",
            " Episode return:53.0  Episode return:62.0 Mean reward:29.42608695652174  i:1365, n batches:1 \n",
            " Episode return:39.0  Episode return:185.0 Mean reward:80.29017857142857  i:1366, n batches:2 \n",
            " Episode return:131.0  Episode return:71.0 Mean reward:55.45544554455446  i:1367, n batches:2 \n",
            " Episode return:68.0  Episode return:15.0 Mean reward:29.710843373493976  i:1368, n batches:1 \n",
            " Episode return:43.0  Episode return:25.0 Mean reward:18.691176470588236  i:1369, n batches:1 \n",
            " Episode return:33.0  Episode return:77.0 Mean reward:32.4  i:1370, n batches:1 \n",
            " Episode return:57.0  Episode return:33.0 Mean reward:24.6  i:1371, n batches:1 \n",
            " Episode return:55.0  Episode return:83.0 Mean reward:36.42028985507246  i:1372, n batches:2 \n",
            " Episode return:26.0  Episode return:44.0 Mean reward:19.15714285714286  i:1373, n batches:1 \n",
            " Episode return:39.0  Episode return:26.0 Mean reward:17.4  i:1374, n batches:1 \n",
            " Episode return:13.0  Episode return:50.0 Mean reward:21.682539682539684  i:1375, n batches:1 \n",
            " Episode return:41.0  Episode return:33.0 Mean reward:19.216216216216218  i:1376, n batches:1 \n",
            " Episode return:114.0  Episode return:73.0 Mean reward:49.49732620320856  i:1377, n batches:2 \n",
            " Episode return:46.0  Episode return:30.0 Mean reward:20.342105263157894  i:1378, n batches:1 \n",
            " Episode return:119.0  Episode return:35.0 Mean reward:50.45454545454545  i:1379, n batches:2 \n",
            " Episode return:56.0  Episode return:31.0 Mean reward:24.04597701149425  i:1380, n batches:1 \n",
            " Episode return:44.0  Episode return:32.0 Mean reward:19.973684210526315  i:1381, n batches:1 \n",
            " Episode return:14.0  Episode return:84.0 Mean reward:37.5  i:1382, n batches:1 \n",
            " Episode return:49.0  Episode return:59.0 Mean reward:27.73148148148148  i:1383, n batches:1 \n",
            " Episode return:100.0  Episode return:30.0 Mean reward:42.42307692307692  i:1384, n batches:2 \n",
            " Episode return:75.0  Episode return:58.0 Mean reward:34.29323308270677  i:1385, n batches:2 \n",
            " Episode return:170.0  Episode return:177.0 Mean reward:87.28530259365995  i:1386, n batches:3 \n",
            " Episode return:73.0  Episode return:40.0 Mean reward:31.15929203539823  i:1387, n batches:1 \n",
            " Episode return:44.0  Episode return:87.0 Mean reward:36.778625954198475  i:1388, n batches:2 \n",
            " Episode return:27.0  Episode return:83.0 Mean reward:35.127272727272725  i:1389, n batches:1 \n",
            " Episode return:24.0  Episode return:52.0 Mean reward:22.07894736842105  i:1390, n batches:1 \n",
            " Episode return:74.0  Episode return:34.0 Mean reward:31.203703703703702  i:1391, n batches:1 \n",
            " Episode return:313.0  Episode return:56.0 Mean reward:137.49864498644988  i:1392, n batches:3 \n",
            " Episode return:15.0  Episode return:18.0 Mean reward:8.818181818181818  i:1393, n batches:1 \n",
            " Episode return:77.0  Episode return:74.0 Mean reward:38.264900662251655  i:1394, n batches:2 \n",
            " Episode return:33.0  Episode return:13.0 Mean reward:14.173913043478262  i:1395, n batches:1 \n",
            " Episode return:24.0  Episode return:45.0 Mean reward:19.347826086956523  i:1396, n batches:1 \n",
            " Episode return:32.0  Episode return:37.0 Mean reward:17.840579710144926  i:1397, n batches:1 \n",
            " Episode return:46.0  Episode return:17.0 Mean reward:19.58730158730159  i:1398, n batches:1 \n",
            " Episode return:24.0  Episode return:44.0 Mean reward:18.970588235294116  i:1399, n batches:1 \n",
            " Episode return:84.0  Episode return:211.0 Mean reward:87.9186440677966  i:1400, n batches:3 \n",
            "loss:0.07086369395256042\n",
            "loss:0.0434773750603199\n",
            "loss:-0.07170092314481735\n",
            " Episode return:102.0  Episode return:68.0 Mean reward:44.7  i:1401, n batches:2 \n",
            " Episode return:61.0  Episode return:83.0 Mean reward:37.34027777777778  i:1402, n batches:2 \n",
            " Episode return:49.0  Episode return:14.0 Mean reward:21.11111111111111  i:1403, n batches:1 \n",
            " Episode return:81.0  Episode return:98.0 Mean reward:45.6536312849162  i:1404, n batches:2 \n",
            " Episode return:59.0  Episode return:91.0 Mean reward:39.70666666666666  i:1405, n batches:2 \n",
            " Episode return:48.0  Episode return:78.0 Mean reward:33.785714285714285  i:1406, n batches:1 \n",
            " Episode return:27.0  Episode return:70.0 Mean reward:29.515463917525775  i:1407, n batches:1 \n",
            " Episode return:30.0  Episode return:35.0 Mean reward:16.846153846153847  i:1408, n batches:1 \n",
            " Episode return:141.0  Episode return:43.0 Mean reward:59.54891304347826  i:1409, n batches:2 \n",
            " Episode return:40.0  Episode return:14.0 Mean reward:17.12962962962963  i:1410, n batches:1 \n",
            " Episode return:40.0  Episode return:88.0 Mean reward:37.0  i:1411, n batches:1 \n",
            " Episode return:58.0  Episode return:33.0 Mean reward:24.967032967032967  i:1412, n batches:1 \n",
            " Episode return:65.0  Episode return:155.0 Mean reward:64.70454545454545  i:1413, n batches:2 \n",
            " Episode return:23.0  Episode return:66.0 Mean reward:27.9438202247191  i:1414, n batches:1 \n",
            " Episode return:17.0  Episode return:48.0 Mean reward:20.446153846153845  i:1415, n batches:1 \n",
            " Episode return:25.0  Episode return:40.0 Mean reward:17.615384615384617  i:1416, n batches:1 \n",
            " Episode return:76.0  Episode return:30.0 Mean reward:31.99056603773585  i:1417, n batches:1 \n",
            " Episode return:45.0  Episode return:59.0 Mean reward:26.971153846153847  i:1418, n batches:1 \n",
            " Episode return:183.0  Episode return:52.0 Mean reward:77.50638297872341  i:1419, n batches:2 \n",
            " Episode return:48.0  Episode return:59.0 Mean reward:27.53271028037383  i:1420, n batches:1 \n",
            " Episode return:77.0  Episode return:18.0 Mean reward:33.410526315789475  i:1421, n batches:1 \n",
            " Episode return:33.0  Episode return:32.0 Mean reward:16.753846153846155  i:1422, n batches:1 \n",
            " Episode return:73.0  Episode return:18.0 Mean reward:31.560439560439562  i:1423, n batches:1 \n",
            " Episode return:55.0  Episode return:28.0 Mean reward:23.44578313253012  i:1424, n batches:1 \n",
            " Episode return:84.0  Episode return:70.0 Mean reward:39.31818181818182  i:1425, n batches:2 \n",
            " Episode return:50.0  Episode return:110.0 Mean reward:46.125  i:1426, n batches:2 \n",
            " Episode return:53.0  Episode return:27.0 Mean reward:22.6125  i:1427, n batches:1 \n",
            " Episode return:32.0  Episode return:85.0 Mean reward:35.75213675213675  i:1428, n batches:1 \n",
            " Episode return:48.0  Episode return:34.0 Mean reward:21.597560975609756  i:1429, n batches:1 \n",
            " Episode return:64.0  Episode return:98.0 Mean reward:42.78395061728395  i:1430, n batches:2 \n",
            " Episode return:23.0  Episode return:28.0 Mean reward:13.372549019607844  i:1431, n batches:1 \n",
            " Episode return:20.0  Episode return:25.0 Mean reward:11.88888888888889  i:1432, n batches:1 \n",
            " Episode return:10.0  Episode return:60.0 Mean reward:26.928571428571427  i:1433, n batches:1 \n",
            " Episode return:44.0  Episode return:105.0 Mean reward:43.993288590604024  i:1434, n batches:2 \n",
            " Episode return:22.0  Episode return:27.0 Mean reward:12.877551020408163  i:1435, n batches:1 \n",
            " Episode return:41.0  Episode return:50.0 Mean reward:23.47252747252747  i:1436, n batches:1 \n",
            " Episode return:90.0  Episode return:166.0 Mean reward:70.140625  i:1437, n batches:2 \n",
            " Episode return:48.0  Episode return:62.0 Mean reward:28.445454545454545  i:1438, n batches:1 \n",
            " Episode return:46.0  Episode return:65.0 Mean reward:29.063063063063062  i:1439, n batches:1 \n",
            " Episode return:64.0  Episode return:58.0 Mean reward:31.07377049180328  i:1440, n batches:1 \n",
            " Episode return:31.0  Episode return:50.0 Mean reward:21.864197530864196  i:1441, n batches:1 \n",
            " Episode return:87.0  Episode return:9.0 Mean reward:40.34375  i:1442, n batches:1 \n",
            " Episode return:29.0  Episode return:52.0 Mean reward:22.382716049382715  i:1443, n batches:1 \n",
            " Episode return:31.0  Episode return:27.0 Mean reward:15.068965517241379  i:1444, n batches:1 \n",
            " Episode return:119.0  Episode return:47.0 Mean reward:49.80722891566265  i:1445, n batches:2 \n",
            " Episode return:69.0  Episode return:55.0 Mean reward:31.89516129032258  i:1446, n batches:1 \n",
            " Episode return:46.0  Episode return:36.0 Mean reward:21.304878048780488  i:1447, n batches:1 \n",
            " Episode return:63.0  Episode return:73.0 Mean reward:34.68382352941177  i:1448, n batches:2 \n",
            " Episode return:10.0  Episode return:59.0 Mean reward:26.44927536231884  i:1449, n batches:1 \n",
            " Episode return:89.0  Episode return:71.0 Mean reward:41.00625  i:1450, n batches:2 \n",
            " Episode return:39.0  Episode return:25.0 Mean reward:17.265625  i:1451, n batches:1 \n",
            " Episode return:58.0  Episode return:81.0 Mean reward:36.201438848920866  i:1452, n batches:2 \n",
            " Episode return:132.0  Episode return:20.0 Mean reward:59.13157894736842  i:1453, n batches:2 \n",
            " Episode return:82.0  Episode return:112.0 Mean reward:50.15979381443299  i:1454, n batches:2 \n",
            " Episode return:32.0  Episode return:47.0 Mean reward:20.962025316455698  i:1455, n batches:1 \n",
            " Episode return:84.0  Episode return:155.0 Mean reward:65.52301255230125  i:1456, n batches:2 \n",
            " Episode return:73.0  Episode return:60.0 Mean reward:34.067669172932334  i:1457, n batches:2 \n",
            " Episode return:60.0  Episode return:38.0 Mean reward:26.23469387755102  i:1458, n batches:1 \n",
            " Episode return:60.0  Episode return:64.0 Mean reward:31.532258064516128  i:1459, n batches:1 \n",
            " Episode return:58.0  Episode return:55.0 Mean reward:28.76991150442478  i:1460, n batches:1 \n",
            " Episode return:60.0  Episode return:73.0 Mean reward:34.067669172932334  i:1461, n batches:2 \n",
            " Episode return:131.0  Episode return:76.0 Mean reward:55.90338164251208  i:1462, n batches:2 \n",
            " Episode return:93.0  Episode return:36.0 Mean reward:39.04651162790697  i:1463, n batches:2 \n",
            " Episode return:83.0  Episode return:46.0 Mean reward:35.4031007751938  i:1464, n batches:2 \n",
            " Episode return:46.0  Episode return:107.0 Mean reward:44.830065359477125  i:1465, n batches:2 \n",
            " Episode return:134.0  Episode return:55.0 Mean reward:56.00529100529101  i:1466, n batches:2 \n",
            " Episode return:35.0  Episode return:67.0 Mean reward:28.50980392156863  i:1467, n batches:1 \n",
            " Episode return:42.0  Episode return:30.0 Mean reward:19.0  i:1468, n batches:1 \n",
            " Episode return:85.0  Episode return:114.0 Mean reward:51.30653266331658  i:1469, n batches:2 \n",
            " Episode return:108.0  Episode return:140.0 Mean reward:63.53225806451613  i:1470, n batches:2 \n",
            " Episode return:38.0  Episode return:55.0 Mean reward:24.526881720430108  i:1471, n batches:1 \n",
            " Episode return:37.0  Episode return:133.0 Mean reward:56.55294117647059  i:1472, n batches:2 \n",
            " Episode return:118.0  Episode return:25.0 Mean reward:51.37062937062937  i:1473, n batches:2 \n",
            " Episode return:117.0  Episode return:38.0 Mean reward:49.31612903225806  i:1474, n batches:2 \n",
            " Episode return:51.0  Episode return:49.0 Mean reward:25.51  i:1475, n batches:1 \n",
            " Episode return:78.0  Episode return:111.0 Mean reward:49.19047619047619  i:1476, n batches:2 \n",
            " Episode return:91.0  Episode return:119.0 Mean reward:53.93333333333333  i:1477, n batches:2 \n",
            " Episode return:23.0  Episode return:100.0 Mean reward:43.300813008130085  i:1478, n batches:1 \n",
            " Episode return:77.0  Episode return:103.0 Mean reward:46.43888888888889  i:1479, n batches:2 \n",
            " Episode return:77.0  Episode return:39.0 Mean reward:32.61206896551724  i:1480, n batches:1 \n",
            " Episode return:91.0  Episode return:41.0 Mean reward:38.234848484848484  i:1481, n batches:2 \n",
            " Episode return:97.0  Episode return:19.0 Mean reward:42.61206896551724  i:1482, n batches:1 \n",
            " Episode return:76.0  Episode return:16.0 Mean reward:33.28260869565217  i:1483, n batches:1 \n",
            " Episode return:110.0  Episode return:155.0 Mean reward:68.66037735849056  i:1484, n batches:3 \n",
            " Episode return:93.0  Episode return:58.0 Mean reward:40.27814569536424  i:1485, n batches:2 \n",
            " Episode return:20.0  Episode return:66.0 Mean reward:28.151162790697676  i:1486, n batches:1 \n",
            " Episode return:51.0  Episode return:25.0 Mean reward:21.723684210526315  i:1487, n batches:1 \n",
            " Episode return:45.0  Episode return:15.0 Mean reward:19.25  i:1488, n batches:1 \n",
            " Episode return:41.0  Episode return:23.0 Mean reward:17.765625  i:1489, n batches:1 \n",
            " Episode return:42.0  Episode return:29.0 Mean reward:18.845070422535212  i:1490, n batches:1 \n",
            " Episode return:132.0  Episode return:57.0 Mean reward:55.19047619047619  i:1491, n batches:2 \n",
            " Episode return:45.0  Episode return:126.0 Mean reward:52.8421052631579  i:1492, n batches:2 \n",
            " Episode return:44.0  Episode return:86.0 Mean reward:36.39230769230769  i:1493, n batches:2 \n",
            " Episode return:22.0  Episode return:58.0 Mean reward:24.55  i:1494, n batches:1 \n",
            " Episode return:51.0  Episode return:73.0 Mean reward:32.475806451612904  i:1495, n batches:1 \n",
            " Episode return:35.0  Episode return:37.0 Mean reward:18.51388888888889  i:1496, n batches:1 \n",
            " Episode return:137.0  Episode return:77.0 Mean reward:58.205607476635514  i:1497, n batches:2 \n",
            " Episode return:34.0  Episode return:63.0 Mean reward:26.917525773195877  i:1498, n batches:1 \n",
            " Episode return:46.0  Episode return:94.0 Mean reward:39.614285714285714  i:1499, n batches:2 \n",
            " Episode return:68.0  Episode return:66.0 Mean reward:34.007462686567166  i:1500, n batches:2 \n",
            "loss:0.17374126613140106\n",
            "loss:-0.032435450702905655\n",
            " Episode return:62.0  Episode return:74.0 Mean reward:34.76470588235294  i:1501, n batches:2 \n",
            " Episode return:44.0  Episode return:27.0 Mean reward:19.267605633802816  i:1502, n batches:1 \n",
            " Episode return:25.0  Episode return:135.0 Mean reward:59.40625  i:1503, n batches:2 \n",
            " Episode return:96.0  Episode return:71.0 Mean reward:43.18562874251497  i:1504, n batches:2 \n",
            " Episode return:45.0  Episode return:47.0 Mean reward:23.51086956521739  i:1505, n batches:1 \n",
            " Episode return:114.0  Episode return:24.0 Mean reward:49.67391304347826  i:1506, n batches:2 \n",
            " Episode return:35.0  Episode return:28.0 Mean reward:16.444444444444443  i:1507, n batches:1 \n",
            " Episode return:53.0  Episode return:68.0 Mean reward:31.214876033057852  i:1508, n batches:1 \n",
            " Episode return:66.0  Episode return:38.0 Mean reward:28.384615384615383  i:1509, n batches:1 \n",
            " Episode return:26.0  Episode return:31.0 Mean reward:14.859649122807017  i:1510, n batches:1 \n",
            " Episode return:13.0  Episode return:22.0 Mean reward:9.82857142857143  i:1511, n batches:1 \n",
            " Episode return:39.0  Episode return:66.0 Mean reward:28.485714285714284  i:1512, n batches:1 \n",
            " Episode return:80.0  Episode return:50.0 Mean reward:34.73076923076923  i:1513, n batches:2 \n",
            " Episode return:84.0  Episode return:87.0 Mean reward:43.26315789473684  i:1514, n batches:2 \n",
            " Episode return:103.0  Episode return:45.0 Mean reward:43.182432432432435  i:1515, n batches:2 \n",
            " Episode return:67.0  Episode return:21.0 Mean reward:28.511363636363637  i:1516, n batches:1 \n",
            " Episode return:35.0  Episode return:65.0 Mean reward:27.75  i:1517, n batches:1 \n",
            " Episode return:67.0  Episode return:30.0 Mean reward:28.278350515463917  i:1518, n batches:1 \n",
            " Episode return:41.0  Episode return:157.0 Mean reward:66.98989898989899  i:1519, n batches:2 \n",
            " Episode return:65.0  Episode return:115.0 Mean reward:48.97222222222222  i:1520, n batches:2 \n",
            " Episode return:36.0  Episode return:27.0 Mean reward:16.571428571428573  i:1521, n batches:1 \n",
            " Episode return:48.0  Episode return:12.0 Mean reward:20.9  i:1522, n batches:1 \n",
            " Episode return:35.0  Episode return:124.0 Mean reward:52.704402515723274  i:1523, n batches:2 \n",
            " Episode return:30.0  Episode return:105.0 Mean reward:44.666666666666664  i:1524, n batches:2 \n",
            " Episode return:56.0  Episode return:44.0 Mean reward:25.86  i:1525, n batches:1 \n",
            " Episode return:31.0  Episode return:48.0 Mean reward:21.164556962025316  i:1526, n batches:1 \n",
            " Episode return:45.0  Episode return:98.0 Mean reward:41.16083916083916  i:1527, n batches:2 \n",
            " Episode return:56.0  Episode return:54.0 Mean reward:28.009090909090908  i:1528, n batches:1 \n",
            " Episode return:90.0  Episode return:43.0 Mean reward:37.902255639097746  i:1529, n batches:2 \n",
            " Episode return:222.0  Episode return:72.0 Mean reward:93.13265306122449  i:1530, n batches:3 \n",
            " Episode return:167.0  Episode return:25.0 Mean reward:74.75520833333333  i:1531, n batches:2 \n",
            " Episode return:23.0  Episode return:94.0 Mean reward:40.52136752136752  i:1532, n batches:1 \n",
            " Episode return:44.0  Episode return:108.0 Mean reward:45.23684210526316  i:1533, n batches:2 \n",
            " Episode return:79.0  Episode return:85.0 Mean reward:41.55487804878049  i:1534, n batches:2 \n",
            " Episode return:54.0  Episode return:42.0 Mean reward:24.875  i:1535, n batches:1 \n",
            " Episode return:56.0  Episode return:67.0 Mean reward:31.495934959349594  i:1536, n batches:1 \n",
            " Episode return:50.0  Episode return:62.0 Mean reward:28.821428571428573  i:1537, n batches:1 \n",
            " Episode return:24.0  Episode return:76.0 Mean reward:32.26  i:1538, n batches:1 \n",
            " Episode return:62.0  Episode return:37.0 Mean reward:26.828282828282827  i:1539, n batches:1 \n",
            " Episode return:114.0  Episode return:67.0 Mean reward:48.80110497237569  i:1540, n batches:2 \n",
            " Episode return:51.0  Episode return:38.0 Mean reward:23.224719101123597  i:1541, n batches:1 \n",
            " Episode return:75.0  Episode return:51.0 Mean reward:33.142857142857146  i:1542, n batches:1 \n",
            " Episode return:25.0  Episode return:30.0 Mean reward:14.363636363636363  i:1543, n batches:1 \n",
            " Episode return:73.0  Episode return:125.0 Mean reward:53.41414141414141  i:1544, n batches:2 \n",
            " Episode return:33.0  Episode return:39.0 Mean reward:18.625  i:1545, n batches:1 \n",
            " Episode return:52.0  Episode return:44.0 Mean reward:24.666666666666668  i:1546, n batches:1 \n",
            " Episode return:50.0  Episode return:76.0 Mean reward:33.34126984126984  i:1547, n batches:1 \n",
            " Episode return:24.0  Episode return:65.0 Mean reward:27.471910112359552  i:1548, n batches:1 \n",
            " Episode return:46.0  Episode return:68.0 Mean reward:30.06140350877193  i:1549, n batches:1 \n",
            " Episode return:83.0  Episode return:74.0 Mean reward:39.87898089171974  i:1550, n batches:2 \n",
            " Episode return:26.0  Episode return:47.0 Mean reward:20.26027397260274  i:1551, n batches:1 \n",
            " Episode return:60.0  Episode return:24.0 Mean reward:25.357142857142858  i:1552, n batches:1 \n",
            " Episode return:29.0  Episode return:31.0 Mean reward:15.516666666666667  i:1553, n batches:1 \n",
            " Episode return:35.0  Episode return:37.0 Mean reward:18.51388888888889  i:1554, n batches:1 \n",
            " Episode return:65.0  Episode return:45.0 Mean reward:28.90909090909091  i:1555, n batches:1 \n",
            " Episode return:70.0  Episode return:33.0 Mean reward:29.57281553398058  i:1556, n batches:1 \n",
            " Episode return:53.0  Episode return:11.0 Mean reward:23.390625  i:1557, n batches:1 \n",
            " Episode return:30.0  Episode return:154.0 Mean reward:67.3913043478261  i:1558, n batches:2 \n",
            " Episode return:64.0  Episode return:42.0 Mean reward:28.141509433962263  i:1559, n batches:1 \n",
            " Episode return:24.0  Episode return:32.0 Mean reward:14.785714285714286  i:1560, n batches:1 \n",
            " Episode return:53.0  Episode return:74.0 Mean reward:33.118110236220474  i:1561, n batches:1 \n",
            " Episode return:96.0  Episode return:99.0 Mean reward:49.261538461538464  i:1562, n batches:2 \n",
            " Episode return:95.0  Episode return:105.0 Mean reward:50.625  i:1563, n batches:2 \n",
            " Episode return:47.0  Episode return:59.0 Mean reward:27.339622641509433  i:1564, n batches:1 \n",
            " Episode return:34.0  Episode return:66.0 Mean reward:28.06  i:1565, n batches:1 \n",
            " Episode return:46.0  Episode return:62.0 Mean reward:28.09259259259259  i:1566, n batches:1 \n",
            " Episode return:112.0  Episode return:101.0 Mean reward:53.89201877934272  i:1567, n batches:2 \n",
            " Episode return:33.0  Episode return:76.0 Mean reward:31.990825688073393  i:1568, n batches:1 \n",
            " Episode return:42.0  Episode return:20.0 Mean reward:17.951612903225808  i:1569, n batches:1 \n",
            " Episode return:94.0  Episode return:26.0 Mean reward:40.13333333333333  i:1570, n batches:1 \n",
            " Episode return:87.0  Episode return:20.0 Mean reward:37.73831775700935  i:1571, n batches:1 \n",
            " Episode return:120.0  Episode return:55.0 Mean reward:50.285714285714285  i:1572, n batches:2 \n",
            " Episode return:66.0  Episode return:65.0 Mean reward:33.25190839694657  i:1573, n batches:2 \n",
            " Episode return:23.0  Episode return:12.0 Mean reward:10.114285714285714  i:1574, n batches:1 \n",
            " Episode return:51.0  Episode return:69.0 Mean reward:31.175  i:1575, n batches:1 \n",
            " Episode return:62.0  Episode return:83.0 Mean reward:37.51034482758621  i:1576, n batches:2 \n",
            " Episode return:127.0  Episode return:56.0 Mean reward:53.13661202185792  i:1577, n batches:2 \n",
            " Episode return:59.0  Episode return:48.0 Mean reward:27.53271028037383  i:1578, n batches:1 \n",
            " Episode return:91.0  Episode return:87.0 Mean reward:45.02247191011236  i:1579, n batches:2 \n",
            " Episode return:51.0  Episode return:29.0 Mean reward:22.0125  i:1580, n batches:1 \n",
            " Episode return:40.0  Episode return:112.0 Mean reward:47.026315789473685  i:1581, n batches:2 \n",
            " Episode return:118.0  Episode return:35.0 Mean reward:50.00653594771242  i:1582, n batches:2 \n",
            " Episode return:103.0  Episode return:54.0 Mean reward:43.57324840764331  i:1583, n batches:2 \n",
            " Episode return:73.0  Episode return:72.0 Mean reward:36.751724137931035  i:1584, n batches:2 \n",
            " Episode return:60.0  Episode return:133.0 Mean reward:55.652849740932645  i:1585, n batches:2 \n",
            " Episode return:60.0  Episode return:52.0 Mean reward:28.642857142857142  i:1586, n batches:1 \n",
            " Episode return:32.0  Episode return:66.0 Mean reward:27.948979591836736  i:1587, n batches:1 \n",
            " Episode return:120.0  Episode return:37.0 Mean reward:50.71974522292994  i:1588, n batches:2 \n",
            " Episode return:143.0  Episode return:74.0 Mean reward:60.235023041474655  i:1589, n batches:2 \n",
            " Episode return:103.0  Episode return:129.0 Mean reward:59.22844827586207  i:1590, n batches:2 \n",
            " Episode return:120.0  Episode return:34.0 Mean reward:51.006493506493506  i:1591, n batches:2 \n",
            " Episode return:63.0  Episode return:37.0 Mean reward:27.19  i:1592, n batches:1 \n",
            " Episode return:92.0  Episode return:124.0 Mean reward:55.68518518518518  i:1593, n batches:2 \n",
            " Episode return:40.0  Episode return:31.0 Mean reward:18.535211267605632  i:1594, n batches:1 \n",
            " Episode return:52.0  Episode return:35.0 Mean reward:23.080459770114942  i:1595, n batches:1 \n",
            " Episode return:137.0  Episode return:57.0 Mean reward:57.24742268041237  i:1596, n batches:2 \n",
            " Episode return:82.0  Episode return:53.0 Mean reward:35.80740740740741  i:1597, n batches:2 \n",
            " Episode return:55.0  Episode return:180.0 Mean reward:75.87234042553192  i:1598, n batches:2 \n",
            " Episode return:64.0  Episode return:88.0 Mean reward:39.44736842105263  i:1599, n batches:2 \n",
            " Episode return:18.0  Episode return:47.0 Mean reward:19.984615384615385  i:1600, n batches:1 \n",
            "loss:-0.10079006850719452\n",
            " Episode return:48.0  Episode return:151.0 Mean reward:63.57788944723618  i:1601, n batches:2 \n",
            " Episode return:101.0  Episode return:48.0 Mean reward:42.46308724832215  i:1602, n batches:2 \n",
            " Episode return:37.0  Episode return:105.0 Mean reward:44.140845070422536  i:1603, n batches:2 \n",
            " Episode return:105.0  Episode return:56.0 Mean reward:44.47826086956522  i:1604, n batches:2 \n",
            " Episode return:56.0  Episode return:43.0 Mean reward:25.67676767676768  i:1605, n batches:1 \n",
            " Episode return:37.0  Episode return:100.0 Mean reward:41.99270072992701  i:1606, n batches:2 \n",
            " Episode return:27.0  Episode return:71.0 Mean reward:29.93877551020408  i:1607, n batches:1 \n",
            " Episode return:60.0  Episode return:86.0 Mean reward:38.157534246575345  i:1608, n batches:2 \n",
            " Episode return:20.0  Episode return:70.0 Mean reward:29.944444444444443  i:1609, n batches:1 \n",
            " Episode return:27.0  Episode return:50.0 Mean reward:21.467532467532468  i:1610, n batches:1 \n",
            " Episode return:78.0  Episode return:70.0 Mean reward:37.608108108108105  i:1611, n batches:2 \n",
            " Episode return:70.0  Episode return:86.0 Mean reward:39.91025641025641  i:1612, n batches:2 \n",
            " Episode return:46.0  Episode return:57.0 Mean reward:26.54368932038835  i:1613, n batches:1 \n",
            " Episode return:112.0  Episode return:57.0 Mean reward:47.22485207100592  i:1614, n batches:2 \n",
            " Episode return:83.0  Episode return:67.0 Mean reward:38.42666666666667  i:1615, n batches:2 \n",
            " Episode return:30.0  Episode return:48.0 Mean reward:21.03846153846154  i:1616, n batches:1 \n",
            " Episode return:106.0  Episode return:62.0 Mean reward:45.38095238095238  i:1617, n batches:2 \n",
            " Episode return:36.0  Episode return:52.0 Mean reward:23.227272727272727  i:1618, n batches:1 \n",
            " Episode return:34.0  Episode return:39.0 Mean reward:18.835616438356166  i:1619, n batches:1 \n",
            " Episode return:39.0  Episode return:35.0 Mean reward:19.054054054054053  i:1620, n batches:1 \n",
            " Episode return:35.0  Episode return:53.0 Mean reward:23.420454545454547  i:1621, n batches:1 \n",
            " Episode return:27.0  Episode return:87.0 Mean reward:36.89473684210526  i:1622, n batches:1 \n",
            " Episode return:147.0  Episode return:49.0 Mean reward:61.75  i:1623, n batches:2 \n",
            " Episode return:26.0  Episode return:99.0 Mean reward:42.408  i:1624, n batches:1 \n",
            " Episode return:53.0  Episode return:49.0 Mean reward:26.03921568627451  i:1625, n batches:1 \n",
            " Episode return:63.0  Episode return:52.0 Mean reward:29.51304347826087  i:1626, n batches:1 \n",
            " Episode return:18.0  Episode return:155.0 Mean reward:70.8728323699422  i:1627, n batches:2 \n",
            " Episode return:78.0  Episode return:155.0 Mean reward:65.11158798283262  i:1628, n batches:2 \n",
            " Episode return:100.0  Episode return:67.0 Mean reward:43.880239520958085  i:1629, n batches:2 \n",
            " Episode return:114.0  Episode return:44.0 Mean reward:47.75316455696203  i:1630, n batches:2 \n",
            " Episode return:51.0  Episode return:32.0 Mean reward:22.337349397590362  i:1631, n batches:1 \n",
            " Episode return:60.0  Episode return:46.0 Mean reward:27.462264150943398  i:1632, n batches:1 \n",
            " Episode return:93.0  Episode return:42.0 Mean reward:39.06666666666667  i:1633, n batches:2 \n",
            " Episode return:75.0  Episode return:42.0 Mean reward:32.07692307692308  i:1634, n batches:1 \n",
            " Episode return:33.0  Episode return:43.0 Mean reward:19.82894736842105  i:1635, n batches:1 \n",
            " Episode return:117.0  Episode return:91.0 Mean reward:53.3125  i:1636, n batches:2 \n",
            " Episode return:87.0  Episode return:46.0 Mean reward:36.909774436090224  i:1637, n batches:2 \n",
            " Episode return:47.0  Episode return:60.0 Mean reward:27.64485981308411  i:1638, n batches:1 \n",
            " Episode return:39.0  Episode return:72.0 Mean reward:30.7027027027027  i:1639, n batches:1 \n",
            " Episode return:128.0  Episode return:33.0 Mean reward:54.7639751552795  i:1640, n batches:2 \n",
            " Episode return:22.0  Episode return:131.0 Mean reward:58.16339869281046  i:1641, n batches:2 \n",
            " Episode return:37.0  Episode return:62.0 Mean reward:26.828282828282827  i:1642, n batches:1 \n",
            " Episode return:55.0  Episode return:53.0 Mean reward:27.50925925925926  i:1643, n batches:1 \n",
            " Episode return:44.0  Episode return:103.0 Mean reward:43.17006802721088  i:1644, n batches:2 \n",
            " Episode return:31.0  Episode return:10.0 Mean reward:13.439024390243903  i:1645, n batches:1 \n",
            " Episode return:27.0  Episode return:114.0 Mean reward:49.170212765957444  i:1646, n batches:2 \n",
            " Episode return:35.0  Episode return:117.0 Mean reward:49.55921052631579  i:1647, n batches:2 \n",
            " Episode return:51.0  Episode return:59.0 Mean reward:28.145454545454545  i:1648, n batches:1 \n",
            " Episode return:31.0  Episode return:142.0 Mean reward:61.554913294797686  i:1649, n batches:2 \n",
            " Episode return:53.0  Episode return:102.0 Mean reward:43.12258064516129  i:1650, n batches:2 \n",
            " Episode return:54.0  Episode return:219.0 Mean reward:93.68131868131869  i:1651, n batches:3 \n",
            " Episode return:55.0  Episode return:51.0 Mean reward:27.037735849056602  i:1652, n batches:1 \n",
            " Episode return:20.0  Episode return:53.0 Mean reward:22.47945205479452  i:1653, n batches:1 \n",
            " Episode return:100.0  Episode return:75.0 Mean reward:45.142857142857146  i:1654, n batches:2 \n",
            " Episode return:59.0  Episode return:50.0 Mean reward:27.93577981651376  i:1655, n batches:1 \n",
            " Episode return:26.0  Episode return:49.0 Mean reward:21.013333333333332  i:1656, n batches:1 \n",
            " Episode return:115.0  Episode return:128.0 Mean reward:61.4238683127572  i:1657, n batches:2 \n",
            " Episode return:171.0  Episode return:50.0 Mean reward:72.31221719457014  i:1658, n batches:2 \n",
            " Episode return:93.0  Episode return:141.0 Mean reward:61.46153846153846  i:1659, n batches:2 \n",
            " Episode return:28.0  Episode return:24.0 Mean reward:13.576923076923077  i:1660, n batches:1 \n",
            " Episode return:32.0  Episode return:85.0 Mean reward:35.75213675213675  i:1661, n batches:1 \n",
            " Episode return:84.0  Episode return:70.0 Mean reward:39.31818181818182  i:1662, n batches:2 \n",
            " Episode return:59.0  Episode return:57.0 Mean reward:29.50862068965517  i:1663, n batches:1 \n",
            " Episode return:65.0  Episode return:114.0 Mean reward:48.60335195530726  i:1664, n batches:2 \n",
            " Episode return:62.0  Episode return:22.0 Mean reward:26.261904761904763  i:1665, n batches:1 \n",
            " Episode return:39.0  Episode return:193.0 Mean reward:84.05603448275862  i:1666, n batches:2 \n",
            " Episode return:102.0  Episode return:19.0 Mean reward:44.98347107438016  i:1667, n batches:1 \n",
            " Episode return:44.0  Episode return:111.0 Mean reward:46.49032258064516  i:1668, n batches:2 \n",
            " Episode return:71.0  Episode return:53.0 Mean reward:32.153225806451616  i:1669, n batches:1 \n",
            " Episode return:44.0  Episode return:65.0 Mean reward:28.761467889908257  i:1670, n batches:1 \n",
            " Episode return:31.0  Episode return:161.0 Mean reward:70.50520833333333  i:1671, n batches:2 \n",
            " Episode return:28.0  Episode return:25.0 Mean reward:13.79245283018868  i:1672, n batches:1 \n",
            " Episode return:114.0  Episode return:64.0 Mean reward:48.51123595505618  i:1673, n batches:2 \n",
            " Episode return:68.0  Episode return:91.0 Mean reward:41.081761006289305  i:1674, n batches:2 \n",
            " Episode return:32.0  Episode return:28.0 Mean reward:15.566666666666666  i:1675, n batches:1 \n",
            " Episode return:121.0  Episode return:78.0 Mean reward:52.57286432160804  i:1676, n batches:2 \n",
            " Episode return:33.0  Episode return:44.0 Mean reward:20.142857142857142  i:1677, n batches:1 \n",
            " Episode return:94.0  Episode return:40.0 Mean reward:39.440298507462686  i:1678, n batches:2 \n",
            " Episode return:80.0  Episode return:49.0 Mean reward:34.6124031007752  i:1679, n batches:2 \n",
            " Episode return:44.0  Episode return:50.0 Mean reward:24.095744680851062  i:1680, n batches:1 \n",
            " Episode return:68.0  Episode return:47.0 Mean reward:30.208695652173912  i:1681, n batches:1 \n",
            " Episode return:24.0  Episode return:82.0 Mean reward:34.93396226415094  i:1682, n batches:1 \n",
            " Episode return:85.0  Episode return:79.0 Mean reward:41.55487804878049  i:1683, n batches:2 \n",
            " Episode return:16.0  Episode return:65.0 Mean reward:28.160493827160494  i:1684, n batches:1 \n",
            " Episode return:85.0  Episode return:45.0 Mean reward:36.07692307692308  i:1685, n batches:2 \n",
            " Episode return:76.0  Episode return:33.0 Mean reward:31.990825688073393  i:1686, n batches:1 \n",
            " Episode return:157.0  Episode return:63.0 Mean reward:65.5409090909091  i:1687, n batches:2 \n",
            " Episode return:45.0  Episode return:122.0 Mean reward:51.125748502994014  i:1688, n batches:2 \n",
            " Episode return:112.0  Episode return:42.0 Mean reward:46.95454545454545  i:1689, n batches:2 \n",
            " Episode return:34.0  Episode return:41.0 Mean reward:19.413333333333334  i:1690, n batches:1 \n",
            " Episode return:44.0  Episode return:22.0 Mean reward:18.833333333333332  i:1691, n batches:1 \n",
            " Episode return:14.0  Episode return:90.0 Mean reward:40.38461538461539  i:1692, n batches:1 \n",
            " Episode return:122.0  Episode return:60.0 Mean reward:51.28021978021978  i:1693, n batches:2 \n",
            " Episode return:49.0  Episode return:143.0 Mean reward:60.005208333333336  i:1694, n batches:2 \n",
            " Episode return:35.0  Episode return:61.0 Mean reward:26.260416666666668  i:1695, n batches:1 \n",
            " Episode return:20.0  Episode return:84.0 Mean reward:36.34615384615385  i:1696, n batches:1 \n",
            " Episode return:172.0  Episode return:142.0 Mean reward:79.71656050955414  i:1697, n batches:3 \n",
            " Episode return:78.0  Episode return:51.0 Mean reward:34.16279069767442  i:1698, n batches:2 \n",
            " Episode return:65.0  Episode return:162.0 Mean reward:67.61233480176212  i:1699, n batches:2 \n",
            " Episode return:59.0  Episode return:66.0 Mean reward:31.848  i:1700, n batches:1 \n",
            "loss:-0.036623746156692505\n",
            " Episode return:53.0  Episode return:68.0 Mean reward:31.214876033057852  i:1701, n batches:1 \n",
            " Episode return:75.0  Episode return:22.0 Mean reward:31.989690721649485  i:1702, n batches:1 \n",
            " Episode return:143.0  Episode return:115.0 Mean reward:65.75968992248062  i:1703, n batches:3 \n",
            " Episode return:75.0  Episode return:70.0 Mean reward:36.793103448275865  i:1704, n batches:2 \n",
            " Episode return:52.0  Episode return:64.0 Mean reward:29.810344827586206  i:1705, n batches:1 \n",
            " Episode return:118.0  Episode return:21.0 Mean reward:52.172661870503596  i:1706, n batches:2 \n",
            " Episode return:102.0  Episode return:85.0 Mean reward:47.63636363636363  i:1707, n batches:2 \n",
            " Episode return:44.0  Episode return:33.0 Mean reward:20.142857142857142  i:1708, n batches:1 \n",
            " Episode return:18.0  Episode return:97.0 Mean reward:42.81739130434783  i:1709, n batches:1 \n",
            " Episode return:30.0  Episode return:35.0 Mean reward:16.846153846153847  i:1710, n batches:1 \n",
            " Episode return:74.0  Episode return:60.0 Mean reward:34.365671641791046  i:1711, n batches:2 \n",
            " Episode return:38.0  Episode return:36.0 Mean reward:19.013513513513512  i:1712, n batches:1 \n",
            " Episode return:60.0  Episode return:27.0 Mean reward:25.379310344827587  i:1713, n batches:1 \n",
            " Episode return:51.0  Episode return:53.0 Mean reward:26.509615384615383  i:1714, n batches:1 \n",
            " Episode return:61.0  Episode return:49.0 Mean reward:28.327272727272728  i:1715, n batches:1 \n",
            " Episode return:150.0  Episode return:117.0 Mean reward:68.26966292134831  i:1716, n batches:3 \n",
            " Episode return:56.0  Episode return:57.0 Mean reward:28.75221238938053  i:1717, n batches:1 \n",
            " Episode return:29.0  Episode return:30.0 Mean reward:15.254237288135593  i:1718, n batches:1 \n",
            " Episode return:146.0  Episode return:28.0 Mean reward:64.00574712643679  i:1719, n batches:2 \n",
            " Episode return:142.0  Episode return:38.0 Mean reward:60.522222222222226  i:1720, n batches:2 \n",
            " Episode return:138.0  Episode return:90.0 Mean reward:60.026315789473685  i:1721, n batches:2 \n",
            " Episode return:16.0  Episode return:152.0 Mean reward:70.02380952380952  i:1722, n batches:2 \n",
            " Episode return:90.0  Episode return:62.0 Mean reward:39.78947368421053  i:1723, n batches:2 \n",
            " Episode return:89.0  Episode return:18.0 Mean reward:39.02803738317757  i:1724, n batches:1 \n",
            " Episode return:180.0  Episode return:74.0 Mean reward:75.05905511811024  i:1725, n batches:2 \n",
            " Episode return:150.0  Episode return:56.0 Mean reward:62.72330097087379  i:1726, n batches:2 \n",
            " Episode return:36.0  Episode return:138.0 Mean reward:58.94827586206897  i:1727, n batches:2 \n",
            " Episode return:42.0  Episode return:23.0 Mean reward:18.138461538461538  i:1728, n batches:1 \n",
            " Episode return:83.0  Episode return:14.0 Mean reward:37.02061855670103  i:1729, n batches:1 \n",
            " Episode return:61.0  Episode return:75.0 Mean reward:34.86029411764706  i:1730, n batches:2 \n",
            " Episode return:100.0  Episode return:64.0 Mean reward:43.47560975609756  i:1731, n batches:2 \n",
            " Episode return:194.0  Episode return:143.0 Mean reward:86.67952522255193  i:1732, n batches:3 \n",
            " Episode return:167.0  Episode return:42.0 Mean reward:71.4401913875598  i:1733, n batches:2 \n",
            " Episode return:56.0  Episode return:76.0 Mean reward:34.25757575757576  i:1734, n batches:2 \n",
            " Episode return:105.0  Episode return:25.0 Mean reward:45.30769230769231  i:1735, n batches:2 \n",
            " Episode return:109.0  Episode return:110.0 Mean reward:55.25114155251141  i:1736, n batches:2 \n",
            " Episode return:52.0  Episode return:62.0 Mean reward:29.219298245614034  i:1737, n batches:1 \n",
            " Episode return:72.0  Episode return:133.0 Mean reward:56.28780487804878  i:1738, n batches:2 \n",
            " Episode return:65.0  Episode return:163.0 Mean reward:68.03070175438596  i:1739, n batches:2 \n",
            " Episode return:66.0  Episode return:70.0 Mean reward:34.529411764705884  i:1740, n batches:2 \n",
            " Episode return:22.0  Episode return:142.0 Mean reward:63.451219512195124  i:1741, n batches:2 \n",
            " Episode return:67.0  Episode return:73.0 Mean reward:35.56428571428572  i:1742, n batches:2 \n",
            " Episode return:22.0  Episode return:93.0 Mean reward:40.208695652173915  i:1743, n batches:1 \n",
            " Episode return:31.0  Episode return:161.0 Mean reward:70.50520833333333  i:1744, n batches:2 \n",
            " Episode return:87.0  Episode return:144.0 Mean reward:61.76623376623377  i:1745, n batches:2 \n",
            " Episode return:82.0  Episode return:132.0 Mean reward:56.92056074766355  i:1746, n batches:2 \n",
            " Episode return:43.0  Episode return:44.0 Mean reward:22.25287356321839  i:1747, n batches:1 \n",
            " Episode return:55.0  Episode return:34.0 Mean reward:23.98876404494382  i:1748, n batches:1 \n",
            " Episode return:56.0  Episode return:31.0 Mean reward:24.04597701149425  i:1749, n batches:1 \n",
            " Episode return:50.0  Episode return:128.0 Mean reward:53.54494382022472  i:1750, n batches:2 \n",
            " Episode return:45.0  Episode return:92.0 Mean reward:38.78102189781022  i:1751, n batches:2 \n",
            " Episode return:15.0  Episode return:31.0 Mean reward:13.391304347826088  i:1752, n batches:1 \n",
            " Episode return:26.0  Episode return:87.0 Mean reward:36.982300884955755  i:1753, n batches:1 \n",
            " Episode return:29.0  Episode return:31.0 Mean reward:15.516666666666667  i:1754, n batches:1 \n",
            " Episode return:72.0  Episode return:98.0 Mean reward:43.99411764705882  i:1755, n batches:2 \n",
            " Episode return:21.0  Episode return:50.0 Mean reward:21.211267605633804  i:1756, n batches:1 \n",
            " Episode return:97.0  Episode return:46.0 Mean reward:40.7972027972028  i:1757, n batches:2 \n",
            " Episode return:170.0  Episode return:34.0 Mean reward:74.16666666666667  i:1758, n batches:2 \n",
            " Episode return:96.0  Episode return:56.0 Mean reward:41.13157894736842  i:1759, n batches:2 \n",
            " Episode return:105.0  Episode return:39.0 Mean reward:44.0625  i:1760, n batches:2 \n",
            " Episode return:90.0  Episode return:47.0 Mean reward:38.12408759124087  i:1761, n batches:2 \n",
            " Episode return:64.0  Episode return:14.0 Mean reward:28.012820512820515  i:1762, n batches:1 \n",
            " Episode return:25.0  Episode return:70.0 Mean reward:29.57894736842105  i:1763, n batches:1 \n",
            " Episode return:91.0  Episode return:51.0 Mean reward:38.816901408450704  i:1764, n batches:2 \n",
            " Episode return:20.0  Episode return:64.0 Mean reward:27.261904761904763  i:1765, n batches:1 \n",
            " Episode return:24.0  Episode return:49.0 Mean reward:20.89041095890411  i:1766, n batches:1 \n",
            " Episode return:56.0  Episode return:32.0 Mean reward:24.136363636363637  i:1767, n batches:1 \n",
            " Episode return:14.0  Episode return:97.0 Mean reward:43.765765765765764  i:1768, n batches:1 \n",
            " Episode return:103.0  Episode return:61.0 Mean reward:44.1890243902439  i:1769, n batches:2 \n",
            " Episode return:94.0  Episode return:85.0 Mean reward:45.36312849162011  i:1770, n batches:2 \n",
            " Episode return:85.0  Episode return:120.0 Mean reward:53.24390243902439  i:1771, n batches:2 \n",
            " Episode return:46.0  Episode return:68.0 Mean reward:30.06140350877193  i:1772, n batches:1 \n",
            " Episode return:153.0  Episode return:45.0 Mean reward:64.72727272727273  i:1773, n batches:2 \n",
            " Episode return:51.0  Episode return:16.0 Mean reward:21.82089552238806  i:1774, n batches:1 \n",
            " Episode return:91.0  Episode return:66.0 Mean reward:40.745222929936304  i:1775, n batches:2 \n",
            " Episode return:64.0  Episode return:30.0 Mean reward:27.074468085106382  i:1776, n batches:1 \n",
            " Episode return:74.0  Episode return:56.0 Mean reward:33.62307692307692  i:1777, n batches:2 \n",
            " Episode return:94.0  Episode return:106.0 Mean reward:50.68  i:1778, n batches:2 \n",
            " Episode return:48.0  Episode return:75.0 Mean reward:32.73170731707317  i:1779, n batches:1 \n",
            " Episode return:13.0  Episode return:42.0 Mean reward:18.072727272727274  i:1780, n batches:1 \n",
            " Episode return:178.0  Episode return:105.0 Mean reward:75.95759717314488  i:1781, n batches:3 \n",
            " Episode return:84.0  Episode return:91.0 Mean reward:44.32  i:1782, n batches:2 \n",
            " Episode return:44.0  Episode return:72.0 Mean reward:31.189655172413794  i:1783, n batches:1 \n",
            " Episode return:45.0  Episode return:23.0 Mean reward:19.279411764705884  i:1784, n batches:1 \n",
            " Episode return:96.0  Episode return:66.0 Mean reward:42.388888888888886  i:1785, n batches:2 \n",
            " Episode return:112.0  Episode return:65.0 Mean reward:47.87005649717514  i:1786, n batches:2 \n",
            " Episode return:23.0  Episode return:18.0 Mean reward:10.902439024390244  i:1787, n batches:1 \n",
            " Episode return:71.0  Episode return:63.0 Mean reward:34.11940298507463  i:1788, n batches:2 \n",
            " Episode return:36.0  Episode return:86.0 Mean reward:36.122950819672134  i:1789, n batches:1 \n",
            " Episode return:37.0  Episode return:82.0 Mean reward:34.50420168067227  i:1790, n batches:1 \n",
            " Episode return:15.0  Episode return:179.0 Mean reward:83.65979381443299  i:1791, n batches:2 \n",
            " Episode return:64.0  Episode return:60.0 Mean reward:31.532258064516128  i:1792, n batches:1 \n",
            " Episode return:59.0  Episode return:59.0 Mean reward:30.0  i:1793, n batches:1 \n",
            " Episode return:142.0  Episode return:50.0 Mean reward:59.520833333333336  i:1794, n batches:2 \n",
            " Episode return:57.0  Episode return:127.0 Mean reward:53.15760869565217  i:1795, n batches:2 \n",
            " Episode return:99.0  Episode return:24.0 Mean reward:42.68292682926829  i:1796, n batches:1 \n",
            " Episode return:104.0  Episode return:53.0 Mean reward:43.89171974522293  i:1797, n batches:2 \n",
            " Episode return:66.0  Episode return:68.0 Mean reward:34.007462686567166  i:1798, n batches:2 \n",
            " Episode return:98.0  Episode return:46.0 Mean reward:41.19444444444444  i:1799, n batches:2 \n",
            " Episode return:26.0  Episode return:115.0 Mean reward:49.794326241134755  i:1800, n batches:2 \n",
            "loss:0.06210407614707947\n",
            "loss:-0.0682283341884613\n",
            " Episode return:67.0  Episode return:83.0 Mean reward:38.42666666666667  i:1801, n batches:2 \n",
            " Episode return:29.0  Episode return:43.0 Mean reward:19.180555555555557  i:1802, n batches:1 \n",
            " Episode return:108.0  Episode return:21.0 Mean reward:47.41860465116279  i:1803, n batches:2 \n",
            " Episode return:69.0  Episode return:80.0 Mean reward:37.95302013422819  i:1804, n batches:2 \n",
            " Episode return:56.0  Episode return:40.0 Mean reward:25.166666666666668  i:1805, n batches:1 \n",
            " Episode return:111.0  Episode return:18.0 Mean reward:49.51162790697674  i:1806, n batches:2 \n",
            " Episode return:128.0  Episode return:80.0 Mean reward:55.26923076923077  i:1807, n batches:2 \n",
            " Episode return:97.0  Episode return:104.0 Mean reward:50.81094527363184  i:1808, n batches:2 \n",
            " Episode return:88.0  Episode return:226.0 Mean reward:94.1624203821656  i:1809, n batches:3 \n",
            " Episode return:86.0  Episode return:102.0 Mean reward:47.840425531914896  i:1810, n batches:2 \n",
            " Episode return:137.0  Episode return:74.0 Mean reward:57.95260663507109  i:1811, n batches:2 \n",
            " Episode return:45.0  Episode return:41.0 Mean reward:22.046511627906977  i:1812, n batches:1 \n",
            " Episode return:70.0  Episode return:39.0 Mean reward:29.954128440366972  i:1813, n batches:1 \n",
            " Episode return:56.0  Episode return:24.0 Mean reward:23.7  i:1814, n batches:1 \n",
            " Episode return:22.0  Episode return:112.0 Mean reward:49.11194029850746  i:1815, n batches:2 \n",
            " Episode return:53.0  Episode return:124.0 Mean reward:51.87005649717514  i:1816, n batches:2 \n",
            " Episode return:93.0  Episode return:43.0 Mean reward:39.095588235294116  i:1817, n batches:2 \n",
            " Episode return:122.0  Episode return:68.0 Mean reward:51.83684210526316  i:1818, n batches:2 \n",
            " Episode return:56.0  Episode return:34.0 Mean reward:24.344444444444445  i:1819, n batches:1 \n",
            " Episode return:26.0  Episode return:96.0 Mean reward:41.040983606557376  i:1820, n batches:1 \n",
            " Episode return:66.0  Episode return:85.0 Mean reward:38.847682119205295  i:1821, n batches:2 \n",
            " Episode return:169.0  Episode return:49.0 Mean reward:71.5137614678899  i:1822, n batches:2 \n",
            " Episode return:151.0  Episode return:78.0 Mean reward:63.56768558951965  i:1823, n batches:2 \n",
            " Episode return:24.0  Episode return:83.0 Mean reward:35.38317757009346  i:1824, n batches:1 \n",
            " Episode return:32.0  Episode return:83.0 Mean reward:34.904347826086955  i:1825, n batches:1 \n",
            " Episode return:61.0  Episode return:39.0 Mean reward:26.71  i:1826, n batches:1 \n",
            " Episode return:105.0  Episode return:75.0 Mean reward:46.75  i:1827, n batches:2 \n",
            " Episode return:32.0  Episode return:53.0 Mean reward:23.04705882352941  i:1828, n batches:1 \n",
            " Episode return:35.0  Episode return:74.0 Mean reward:31.238532110091743  i:1829, n batches:1 \n",
            " Episode return:88.0  Episode return:121.0 Mean reward:54.05263157894737  i:1830, n batches:2 \n",
            " Episode return:52.0  Episode return:71.0 Mean reward:31.983739837398375  i:1831, n batches:1 \n",
            " Episode return:40.0  Episode return:116.0 Mean reward:48.756410256410255  i:1832, n batches:2 \n",
            " Episode return:75.0  Episode return:133.0 Mean reward:56.54326923076923  i:1833, n batches:2 \n",
            " Episode return:111.0  Episode return:90.0 Mean reward:51.298507462686565  i:1834, n batches:2 \n",
            " Episode return:28.0  Episode return:79.0 Mean reward:33.32710280373832  i:1835, n batches:1 \n",
            " Episode return:53.0  Episode return:44.0 Mean reward:24.95876288659794  i:1836, n batches:1 \n",
            " Episode return:33.0  Episode return:82.0 Mean reward:34.469565217391306  i:1837, n batches:1 \n",
            " Episode return:22.0  Episode return:14.0 Mean reward:9.944444444444445  i:1838, n batches:1 \n",
            " Episode return:37.0  Episode return:58.0 Mean reward:25.410526315789475  i:1839, n batches:1 \n",
            " Episode return:68.0  Episode return:63.0 Mean reward:33.29770992366412  i:1840, n batches:2 \n",
            " Episode return:164.0  Episode return:51.0 Mean reward:69.09767441860465  i:1841, n batches:2 \n",
            " Episode return:229.0  Episode return:62.0 Mean reward:97.20962199312714  i:1842, n batches:3 \n",
            " Episode return:73.0  Episode return:102.0 Mean reward:45.45142857142857  i:1843, n batches:2 \n",
            " Episode return:44.0  Episode return:52.0 Mean reward:24.666666666666668  i:1844, n batches:1 \n",
            " Episode return:90.0  Episode return:129.0 Mean reward:56.986301369863014  i:1845, n batches:2 \n",
            " Episode return:147.0  Episode return:63.0 Mean reward:61.4  i:1846, n batches:2 \n",
            " Episode return:83.0  Episode return:92.0 Mean reward:44.36571428571428  i:1847, n batches:2 \n",
            " Episode return:43.0  Episode return:60.0 Mean reward:26.95145631067961  i:1848, n batches:1 \n",
            " Episode return:43.0  Episode return:65.0 Mean reward:28.62037037037037  i:1849, n batches:1 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a988a962ed73>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_episodes_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mobs_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobs_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs_episode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maction_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction_episode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d64a61a7c251>\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, env, n_episodes)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mpolicy_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0maction_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# has to convert the tensor to int since the environment accepts the action as int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0maction_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d64a61a7c251>\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0maction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpolicy_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpolicy_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d64a61a7c251>\u001b[0m in \u001b[0;36m_action\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mit\u001b[0m \u001b[0membeds\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msampled\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPolicyStep\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         '''\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdistribution_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d64a61a7c251>\u001b[0m in \u001b[0;36m_distribution\u001b[0;34m(self, time_step)\u001b[0m\n\u001b[1;32m     43\u001b[0m         '''\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mpolicy_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b6486c5211b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "n_steps = 2000\n",
        "n_episodes_per_step=2\n",
        "\n",
        "for i in range(n_steps):\n",
        "    obs, action, reward  = agent1.collect(env, n_episodes=n_episodes_per_step)\n",
        "    obs_merged = [x for obs_episode in obs for x in obs_episode]\n",
        "    action_merged = [x for action_episode in action for x in action_episode]\n",
        "    reward_merged = [x for reward_episode in reward for x in reward_episode]\n",
        "    list_batched_obs, list_batched_actions, list_batched_rewards = create_batches(obs_merged,action_merged,reward_merged,batch_size)\n",
        "\n",
        "    # print(reward_merged)\n",
        "    # average_reward = np.mean(reward_merged)\n",
        "\n",
        "    n_batches = len(list_batched_obs)\n",
        "    print(f' i:{i}, n batches:{n_batches} ')\n",
        "    while len(list_batched_obs) != 0:\n",
        "        batched_obs = list_batched_obs.pop()\n",
        "        batched_action = list_batched_actions.pop()\n",
        "        batched_reward = list_batched_rewards.pop()\n",
        "\n",
        "        batched_action = batched_action.reshape(-1)\n",
        "\n",
        "        # if j == 0:\n",
        "        #     print(f'batch_obs shape:{batched_obs.shape}')\n",
        "        #     print(f'batch_action shape:{batched_action.shape}')\n",
        "        #     print(f'batch_reward shape:{batched_reward.shape}')\n",
        "        loss = agent1.train(optimizer,batched_obs,batched_action,batched_reward)\n",
        "\n",
        "        if i%100 == 0:\n",
        "            print(f'loss:{loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(obs[0])\n",
        "print(reward[0])"
      ],
      "metadata": {
        "id": "eXeMkp_57G-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ea4d43-dbbd-4dcb-ffcf-d2b4cce88d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0.00370961, 0.02219852, 0.02089172, 0.04088289]], dtype=float32), array([[ 0.00415358, -0.17321669,  0.02170938,  0.34008345]],\n",
            "      dtype=float32), array([[ 0.00068924, -0.3686407 ,  0.02851105,  0.63953245]],\n",
            "      dtype=float32), array([[-0.00668357, -0.17392762,  0.0413017 ,  0.35596263]],\n",
            "      dtype=float32), array([[-0.01016212, -0.3696117 ,  0.04842095,  0.6613777 ]],\n",
            "      dtype=float32), array([[-0.01755436, -0.56537277,  0.0616485 ,  0.9689053 ]],\n",
            "      dtype=float32), array([[-0.02886181, -0.37113026,  0.08102661,  0.69620824]],\n",
            "      dtype=float32), array([[-0.03628442, -0.17721994,  0.09495077,  0.4300928 ]],\n",
            "      dtype=float32), array([[-0.03982881, -0.37354922,  0.10355263,  0.7511338 ]],\n",
            "      dtype=float32), array([[-0.0472998 , -0.17999619,  0.1185753 ,  0.49274957]],\n",
            "      dtype=float32), array([[-0.05089973,  0.01327123,  0.12843029,  0.23966359]],\n",
            "      dtype=float32), array([[-0.0506343 , -0.18342914,  0.13322356,  0.56993896]],\n",
            "      dtype=float32), array([[-0.05430288, -0.38014314,  0.14462236,  0.90144724]],\n",
            "      dtype=float32), array([[-0.06190575, -0.5768971 ,  0.1626513 ,  1.2358681 ]],\n",
            "      dtype=float32), array([[-0.07344369, -0.7736919 ,  0.18736866,  1.5747731 ]],\n",
            "      dtype=float32)]\n",
            "[ 1.38707673  1.17264941  0.95822209  0.74379477  0.52936745  0.31494013\n",
            "  0.10051281 -0.11391451 -0.32834184 -0.54276916 -0.75719648 -0.9716238\n",
            " -1.18605112 -1.40047844 -1.61490576]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(obs[0][24])\n",
        "print(action[0][24])\n",
        "print(reward[0][24])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "HXwD6XNZXQjo",
        "outputId": "2fa20d0f-66e4-4a24-aa42-218b141e8c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f278cfee53b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNtKT1zf6L5m"
      },
      "outputs": [],
      "source": [
        "def get_frames_single_episode(env,agent):\n",
        "    frames = []\n",
        "    total_reward_raw = 0\n",
        "    t = 0\n",
        "\n",
        "    obs, info = env.reset()\n",
        "    obs = obs.reshape(1,-1)\n",
        "    obs_tensor = torch.from_numpy(obs).cuda()\n",
        "    reward = np.asarray(0, dtype= np.float32)\n",
        "    step_type = np.asarray(0, dtype= np.float32) # step type with content value of 0 means a FIRST step type\n",
        "    discount_factor = 1\n",
        "\n",
        "    time_step = TimeStep(obs_tensor,reward,step_type,discount_factor)\n",
        "    total_reward_raw += reward\n",
        "\n",
        "    frames.append(env.render())\n",
        "\n",
        "    done, truncate = False, False\n",
        "    while not (done or truncate):\n",
        "        policy_step = agent.policy.action(time_step)\n",
        "        action_int = policy_step.action.reshape(-1).item() # has to convert the tensor to int since the environment accepts the action as int\n",
        "        action_int = int(action_int)\n",
        "        # print(f\"step:{t},total_reward:{total_reward_raw},action:{action_int}\")\n",
        "\n",
        "        obs, reward, done, truncate, info = env.step(action_int)\n",
        "        obs = obs.reshape(1,-1)\n",
        "        obs_tensor = torch.from_numpy(obs).cuda()\n",
        "\n",
        "        if done or truncate:\n",
        "            step_type = np.asarray(2,dtype=np.int32) # step type with content value of 2 means a LAST step type\n",
        "        else:\n",
        "            step_type = np.asarray(1,dtype=np.int32) # step type with content value of 1 means a MID step type\n",
        "\n",
        "        time_step = TimeStep(obs_tensor,reward,step_type,discount_factor)\n",
        "        frames.append(env.render())\n",
        "        total_reward_raw += reward\n",
        "\n",
        "    print(f\"total reward:{total_reward_raw}\")\n",
        "    print(f\"last reward:{reward}\")\n",
        "\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGDXIRm6_NBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e86540-8abd-4705-ac0e-f383d924807b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total reward:254.0\n",
            "last reward:1.0\n"
          ]
        }
      ],
      "source": [
        "frames = get_frames_single_episode(env=env,agent=agent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG0sshsP_pew"
      },
      "outputs": [],
      "source": [
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# extra code – this cell displays an animation of one episode\n",
        "\n",
        "def update_scene(num, frames, patch):\n",
        "    patch.set_data(frames[num])\n",
        "    return patch,\n",
        "\n",
        "def plot_animation(frames, repeat=False, interval=40):\n",
        "    fig = plt.figure()\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "    anim = matplotlib.animation.FuncAnimation(\n",
        "        fig, update_scene, fargs=(frames, patch),\n",
        "        frames=len(frames), repeat=repeat, interval=interval)\n",
        "    plt.close()\n",
        "    return anim\n",
        "\n",
        "\n",
        "anime = plot_animation(frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t514solBKVB"
      },
      "outputs": [],
      "source": [
        "Writer = animation.writers['ffmpeg']\n",
        "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
        "\n",
        "anime.save('trial5.mp4', writer=writer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}